{
  try {
    Context ctx=driverContext.getCtx();
    String hiveJar=conf.getJar();
    String hadoopExec=conf.getVar(HiveConf.ConfVars.HADOOPBIN);
    conf.setVar(ConfVars.HIVEADDEDJARS,Utilities.getResourceFiles(conf,SessionState.ResourceType.JAR));
    Path planPath=new Path(ctx.getLocalTmpPath(),"plan.xml");
    MapredLocalWork plan=getWork();
    LOG.info("Generating plan file " + planPath.toString());
    OutputStream out=null;
    try {
      out=FileSystem.getLocal(conf).create(planPath);
      SerializationUtilities.serializePlan(plan,out);
      out.close();
      out=null;
    }
  finally {
      IOUtils.closeQuietly(out);
    }
    String isSilent="true".equalsIgnoreCase(System.getProperty("test.silent")) ? "-nolog" : "";
    String jarCmd;
    jarCmd=hiveJar + " " + ExecDriver.class.getName();
    String hiveConfArgs=ExecDriver.generateCmdLine(conf,ctx);
    String cmdLine=hadoopExec + " jar " + jarCmd+ " -localtask -plan "+ planPath.toString()+ " "+ isSilent+ " "+ hiveConfArgs;
    String workDir=(new File(".")).getCanonicalPath();
    String files=Utilities.getResourceFiles(conf,SessionState.ResourceType.FILE);
    if (!files.isEmpty()) {
      cmdLine=cmdLine + " -files " + files;
      workDir=ctx.getLocalTmpPath().toUri().getPath();
      if (!(new File(workDir)).mkdir()) {
        throw new IOException("Cannot create tmp working dir: " + workDir);
      }
      for (      String f : StringUtils.split(files,',')) {
        Path p=new Path(f);
        String target=p.toUri().getPath();
        String link=workDir + Path.SEPARATOR + p.getName();
        if (FileUtil.symLink(target,link) != 0) {
          throw new IOException("Cannot link to added file: " + target + " from: "+ link);
        }
      }
    }
    String hadoopOpts;
    StringBuilder sb=new StringBuilder();
    Properties p=System.getProperties();
    for (    String element : HIVE_SYS_PROP) {
      if (p.containsKey(element)) {
        sb.append(" -D" + element + "="+ p.getProperty(element));
      }
    }
    hadoopOpts=sb.toString();
    String[] env;
    Map<String,String> variables=new HashMap<String,String>(System.getenv());
    int hadoopMem=conf.getIntVar(HiveConf.ConfVars.HIVEHADOOPMAXMEM);
    if (hadoopMem == 0) {
      variables.remove(HADOOP_MEM_KEY);
    }
 else {
      console.printInfo(" set heap size\t" + hadoopMem + "MB");
      variables.put(HADOOP_MEM_KEY,String.valueOf(hadoopMem));
    }
    String endUserName=Utils.getUGI().getShortUserName();
    LOG.debug("setting HADOOP_USER_NAME\t" + endUserName);
    variables.put("HADOOP_USER_NAME",endUserName);
    if (variables.containsKey(HADOOP_OPTS_KEY)) {
      variables.put(HADOOP_OPTS_KEY,variables.get(HADOOP_OPTS_KEY) + hadoopOpts);
    }
 else {
      variables.put(HADOOP_OPTS_KEY,hadoopOpts);
    }
    if (HiveConf.getVar(conf,HiveConf.ConfVars.HIVE_HADOOP_CLASSPATH) != null) {
      if (variables.containsKey("HADOOP_CLASSPATH")) {
        variables.put("HADOOP_CLASSPATH",variables.get("HADOOP_CLASSPATH") + ";" + HiveConf.getVar(conf,HiveConf.ConfVars.HIVE_HADOOP_CLASSPATH));
      }
 else {
        variables.put("HADOOP_CLASSPATH",HiveConf.getVar(conf,HiveConf.ConfVars.HIVE_HADOOP_CLASSPATH));
      }
    }
    if (variables.containsKey(MapRedTask.HIVE_DEBUG_RECURSIVE)) {
      MapRedTask.configureDebugVariablesForChildJVM(variables);
    }
    if (UserGroupInformation.isSecurityEnabled() && UserGroupInformation.isLoginKeytabBased()) {
      secureDoAs=new SecureCmdDoAs(conf);
      secureDoAs.addEnv(variables);
    }
    if (variables.containsKey(HIVE_LOCAL_TASK_CHILD_OPTS_KEY)) {
      String childOpts=variables.get(HIVE_LOCAL_TASK_CHILD_OPTS_KEY);
      if (childOpts == null) {
        childOpts="";
      }
      String clientOpts=variables.put(HADOOP_CLIENT_OPTS,childOpts);
      String tmp=variables.get(HADOOP_OPTS_KEY);
      if (tmp != null && !StringUtils.isBlank(clientOpts)) {
        tmp=tmp.replace(clientOpts,childOpts);
        variables.put(HADOOP_OPTS_KEY,tmp);
      }
    }
    env=new String[variables.size()];
    int pos=0;
    for (    Map.Entry<String,String> entry : variables.entrySet()) {
      String name=entry.getKey();
      String value=entry.getValue();
      env[pos++]=name + "=" + value;
      LOG.debug("Setting env: " + name + "="+ Utilities.maskIfPassword(name,value));
    }
    LOG.info("Executing: " + cmdLine);
    executor=Runtime.getRuntime().exec(cmdLine,env,new File(workDir));
    CachingPrintStream errPrintStream=new CachingPrintStream(System.err);
    StreamPrinter outPrinter;
    StreamPrinter errPrinter;
    OperationLog operationLog=OperationLog.getCurrentOperationLog();
    if (operationLog != null) {
      outPrinter=new StreamPrinter(executor.getInputStream(),null,System.out,operationLog.getPrintStream());
      errPrinter=new StreamPrinter(executor.getErrorStream(),null,errPrintStream,operationLog.getPrintStream());
    }
 else {
      outPrinter=new StreamPrinter(executor.getInputStream(),null,System.out);
      errPrinter=new StreamPrinter(executor.getErrorStream(),null,errPrintStream);
    }
    outPrinter.start();
    errPrinter.start();
    int exitVal=jobExecHelper.progressLocal(executor,getId());
    outPrinter.join();
    errPrinter.join();
    if (exitVal != 0) {
      LOG.error("Execution failed with exit status: " + exitVal);
      if (SessionState.get() != null) {
        SessionState.get().addLocalMapRedErrors(getId(),errPrintStream.getOutput());
      }
    }
 else {
      LOG.info("Execution completed successfully");
    }
    return exitVal;
  }
 catch (  Exception e) {
    LOG.error("Exception: ",e);
    return (1);
  }
 finally {
    if (secureDoAs != null) {
      secureDoAs.close();
    }
  }
}
