{
  boolean extended=false;
  boolean formatted=false;
  boolean dependency=false;
  boolean logical=false;
  boolean authorize=false;
  for (int i=1; i < ast.getChildCount(); i++) {
    int explainOptions=ast.getChild(i).getType();
    if (explainOptions == HiveParser.KW_FORMATTED) {
      formatted=true;
    }
 else     if (explainOptions == HiveParser.KW_EXTENDED) {
      extended=true;
    }
 else     if (explainOptions == HiveParser.KW_DEPENDENCY) {
      dependency=true;
    }
 else     if (explainOptions == HiveParser.KW_LOGICAL) {
      logical=true;
    }
 else     if (explainOptions == HiveParser.KW_AUTHORIZATION) {
      authorize=true;
    }
  }
  ctx.setExplain(true);
  ctx.setExplainLogical(logical);
  ASTNode input=(ASTNode)ast.getChild(0);
  BaseSemanticAnalyzer sem=SemanticAnalyzerFactory.get(conf,input);
  sem.analyze(input,ctx);
  sem.validate();
  ctx.setResFile(ctx.getLocalTmpPath());
  List<Task<? extends Serializable>> tasks=sem.getAllRootTasks();
  if (tasks == null) {
    tasks=Collections.emptyList();
  }
  FetchTask fetchTask=sem.getFetchTask();
  if (fetchTask != null) {
    fetchTask.getWork().initializeForFetch(ctx.getOpContext());
  }
  ParseContext pCtx=null;
  if (sem instanceof SemanticAnalyzer) {
    pCtx=((SemanticAnalyzer)sem).getParseContext();
  }
  boolean userLevelExplain=!extended && !formatted && !dependency&& !logical&& !authorize&& (HiveConf.getBoolVar(ctx.getConf(),HiveConf.ConfVars.HIVE_EXPLAIN_USER) && HiveConf.getVar(conf,HiveConf.ConfVars.HIVE_EXECUTION_ENGINE).equals("tez"));
  ExplainWork work=new ExplainWork(ctx.getResFile(),pCtx,tasks,fetchTask,input,sem,extended,formatted,dependency,logical,authorize,userLevelExplain,ctx.getCboInfo());
  work.setAppendTaskType(HiveConf.getBoolVar(conf,HiveConf.ConfVars.HIVEEXPLAINDEPENDENCYAPPENDTASKTYPES));
  ExplainTask explTask=(ExplainTask)TaskFactory.get(work,conf);
  fieldList=explTask.getResultSchema();
  rootTasks.add(explTask);
}
