{
  int akkaThreads=toInt(conf.get("spark.akka.threads"),4);
  int akkaBatchSize=toInt(conf.get("spark.akka.batchSize"),15);
  int akkaTimeout=toInt(conf.get("spark.akka.timeout"),100);
  int akkaFrameSize=toInt(conf.get("spark.akka.frameSize"),10) * 1024 * 1024;
  String lifecycleEvents=toBoolean(conf.get("spark.akka.logLifecycleEvents")) ? "on" : "off";
  String logAkkaConfig=toBoolean(conf.get("spark.akka.logAkkaConfig")) ? "on" : "off";
  int akkaHeartBeatPauses=toInt(conf.get("spark.akka.heartbeat.pauses"),600);
  double akkaFailureDetector=toDouble(conf.get("spark.akka.failure-detector.threshold"),300.0);
  int akkaHeartBeatInterval=toInt(conf.get("spark.akka.heartbeat.interval"),100);
  String akkaSerializer="java";
  String host=findLocalIpAddress();
  String secret=conf.get(CONF_KEY_SECRET);
  Preconditions.checkArgument(secret != null,"%s not set.",CONF_KEY_SECRET);
  Map<String,String> sparkConf=Maps.newHashMap();
  for (  Map.Entry<String,String> e : sparkConf.entrySet()) {
    if (e.getKey().startsWith("akka.")) {
      sparkConf.put(e.getKey(),e.getValue());
    }
  }
  Config fallback=ConfigFactory.parseString("" + "akka.daemonic = on\n" + "akka.loggers = [ \"akka.event.slf4j.Slf4jLogger\" ]\n"+ "akka.stdout-loglevel = \"ERROR\"\n"+ "akka.jvm-exit-on-fatal-error = off\n"+ "akka.actor.default-dispatcher.throughput = " + akkaBatchSize + "\n"+ "akka.actor.serializers.java = \"akka.serialization.JavaSerializer\"\n"+ String.format("akka.actor.serialization-bindings = { \"java.io.Serializable\" = \"%s\" }\n",akkaSerializer)+ "akka.log-config-on-start = "+ logAkkaConfig+ "\n"+ "akka.log-dead-letters = "+ lifecycleEvents+ "\n"+ "akka.log-dead-letters-during-shutdown = "+ lifecycleEvents+ "\n"+ "akka.actor.provider = \"akka.remote.RemoteActorRefProvider\"\n"+ "akka.remote.log-remote-lifecycle-events = "+ lifecycleEvents+ "\n"+ String.format("akka.remote.netty.tcp.connection-timeout = %d s\n",akkaTimeout)+ "akka.remote.netty.tcp.execution-pool-size = "+ akkaThreads+ "\n"+ "akka.remote.netty.tcp.hostname = \""+ host+ "\"\n"+ String.format("akka.remote.netty.tcp.maximum-frame-size = %d B\n",akkaFrameSize)+ "akka.remote.netty.tcp.port = 0\n"+ "akka.remote.netty.tcp.tcp-nodelay = on\n"+ "akka.remote.netty.tcp.transport-class = \"akka.remote.transport.netty.NettyTransport\"\n"+ "akka.remote.require-cookie = on\n"+ "akka.remote.secure-cookie = \""+ secret+ "\"\n"+ String.format("akka.remote.transport-failure-detector.acceptable-heartbeat-pause = %d s\n",akkaHeartBeatPauses)+ String.format("akka.remote.transport-failure-detector.heartbeat-interval = %d s\n",akkaHeartBeatInterval)+ "akka.remote.transport-failure-detector.threshold = "+ String.valueOf(akkaFailureDetector)+ "\n");
  String name=randomName();
  Config akkaConf=ConfigFactory.parseMap(sparkConf).withFallback(fallback);
  ActorSystem actorSystem=ActorSystem.create(name,akkaConf);
  ExtendedActorSystem extActorSystem=(ExtendedActorSystem)actorSystem;
  int boundPort=((Integer)extActorSystem.provider().getDefaultAddress().port().get()).intValue();
  return new ActorSystemInfo(actorSystem,String.format("akka.tcp://%s@%s:%d/user",name,host,boundPort));
}
