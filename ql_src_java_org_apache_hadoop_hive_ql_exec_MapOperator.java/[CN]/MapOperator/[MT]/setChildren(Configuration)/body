{
  Path fpath=new Path(HiveConf.getVar(hconf,HiveConf.ConfVars.HADOOPMAPFILENAME));
  boolean schemeless=fpath.toUri().getScheme() == null;
  List<Operator<? extends OperatorDesc>> children=new ArrayList<Operator<? extends OperatorDesc>>();
  Map<TableDesc,StructObjectInspector> convertedOI=getConvertedOI(hconf);
  try {
    for (    Map.Entry<String,ArrayList<String>> entry : conf.getPathToAliases().entrySet()) {
      String onefile=entry.getKey();
      List<String> aliases=entry.getValue();
      Path onepath=new Path(onefile);
      if (schemeless) {
        onepath=new Path(onepath.toUri().getPath());
      }
      PartitionDesc partDesc=conf.getPathToPartitionInfo().get(onefile);
      for (      String onealias : aliases) {
        Operator<? extends OperatorDesc> op=conf.getAliasToWork().get(onealias);
        LOG.info("Adding alias " + onealias + " to work list for file "+ onefile);
        MapInputPath inp=new MapInputPath(onefile,onealias,op,partDesc);
        if (opCtxMap.containsKey(inp)) {
          continue;
        }
        MapOpCtx opCtx=initObjectInspector(hconf,inp,convertedOI);
        opCtxMap.put(inp,opCtx);
        op.setParentOperators(new ArrayList<Operator<? extends OperatorDesc>>());
        op.getParentOperators().add(this);
        if (!onepath.toUri().relativize(fpath.toUri()).equals(fpath.toUri())) {
          children.add(op);
          childrenOpToOpCtxMap.put(op,opCtx);
          LOG.info("dump " + op.getName() + " "+ opCtxMap.get(inp).rowObjectInspector.getTypeName());
        }
        current=opCtx;
      }
    }
    if (children.size() == 0) {
      LOG.error("Configuration does not have any alias for path: " + fpath.toUri());
      throw new HiveException("Configuration and input path are inconsistent");
    }
    setChildOperators(children);
  }
 catch (  Exception e) {
    throw new HiveException(e);
  }
}
