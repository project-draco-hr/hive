{
  super.initialize(hconf);
  Path fpath=new Path((new Path(HiveConf.getVar(hconf,HiveConf.ConfVars.HADOOPMAPFILENAME))).toUri().getPath());
  ArrayList<Operator<? extends Serializable>> todo=new ArrayList<Operator<? extends Serializable>>();
  statsMap.put(Counter.DESERIALIZE_ERRORS,deserialize_error_count);
  for (  String onefile : conf.getPathToAliases().keySet()) {
    Path onepath=new Path(new Path(onefile).toUri().getPath());
    if (!onepath.toUri().relativize(fpath.toUri()).equals(fpath.toUri())) {
      List<String> aliases=conf.getPathToAliases().get(onefile);
      for (      String onealias : aliases) {
        l4j.info("Adding alias " + onealias + " to work list for file "+ fpath.toUri().getPath());
        todo.add(conf.getAliasToWork().get(onealias));
      }
      if (decoder != null) {
        continue;
      }
      partitionDesc pd=conf.getPathToPartitionInfo().get(onefile);
      LinkedHashMap<String,String> partSpec=pd.getPartSpec();
      tableDesc td=pd.getTableDesc();
      Properties p=td.getProperties();
      HiveConf.setVar(hconf,HiveConf.ConfVars.HIVETABLENAME,String.valueOf(p.getProperty("name")));
      HiveConf.setVar(hconf,HiveConf.ConfVars.HIVEPARTITIONNAME,String.valueOf(partSpec));
      try {
        Class sdclass=td.getSerdeClass();
        if (sdclass == null) {
          String className=td.getSerdeClassName();
          if ((className == "") || (className == null)) {
            throw new HiveException("SerDe class or the SerDe class name is not set for table: " + td.getProperties().getProperty("name"));
          }
          sdclass=MapOperator.class.getClassLoader().loadClass(className);
        }
        decoder=(SerDe)sdclass.newInstance();
        decoder.initialize(hconf,p);
        String pcols=p.getProperty(org.apache.hadoop.hive.metastore.api.Constants.META_TABLE_PARTITION_COLUMNS);
        if (pcols != null && pcols.length() > 0) {
          partCols=new ArrayList<String>();
          partFields=new ArrayList<SerDeField>();
          String[] part_keys=pcols.trim().split("/");
          for (          String key : part_keys) {
            partCols.add(key);
            partFields.add(new ConstantTypedSerDeField(key,partSpec.get(key)));
          }
        }
 else {
          partCols=null;
          partFields=null;
        }
        l4j.info("Got partitions: " + pcols);
      }
 catch (      SerDeException e) {
        e.printStackTrace();
        throw new HiveException(e);
      }
catch (      InstantiationException e) {
        throw new HiveException(e);
      }
catch (      IllegalAccessException e) {
        throw new HiveException(e);
      }
catch (      ClassNotFoundException e) {
        throw new HiveException(e);
      }
    }
  }
  if (todo.size() == 0) {
    l4j.error("Configuration does not have any alias for path: " + fpath.toUri().getPath());
    throw new HiveException("Configuration and input path are inconsistent");
  }
  this.setChildOperators(todo);
  this.setMapredWork(conf);
  this.setOutputCollector(out);
  for (  Operator op : todo) {
    op.initialize(hconf);
  }
}
