{
  String indexCols=MetaStoreUtils.getColumnNamesFromFieldSchema(indexField);
  StringBuilder command=new StringBuilder();
  LinkedHashMap<String,String> partSpec=indexTblPartDesc.getPartSpec();
  command.append("INSERT OVERWRITE TABLE " + indexTableName);
  if (partitioned && indexTblPartDesc != null) {
    command.append(" PARTITION ( ");
    List<String> ret=getPartKVPairStringArray(partSpec);
    for (int i=0; i < ret.size(); i++) {
      String partKV=ret.get(i);
      command.append(partKV);
      if (i < ret.size() - 1)       command.append(",");
    }
    command.append(" ) ");
  }
  command.append(" SELECT ");
  command.append(indexCols);
  command.append(",");
  command.append(VirtualColumn.FILENAME.getName());
  command.append(",");
  command.append(" collect_set (");
  command.append(VirtualColumn.BLOCKOFFSET.getName());
  command.append(") ");
  command.append(" FROM " + baseTableName);
  LinkedHashMap<String,String> basePartSpec=baseTablePartDesc.getPartSpec();
  if (basePartSpec != null) {
    command.append(" WHERE ");
    List<String> pkv=getPartKVPairStringArray(basePartSpec);
    for (int i=0; i < pkv.size(); i++) {
      String partKV=pkv.get(i);
      command.append(partKV);
      if (i < pkv.size() - 1)       command.append(" AND ");
    }
  }
  command.append(" GROUP BY ");
  command.append(indexCols + ", " + VirtualColumn.FILENAME.getName());
  Driver driver=new Driver(new HiveConf(getConf(),CompactIndexHandler.class));
  driver.compile(command.toString());
  Task<?> rootTask=driver.getPlan().getRootTasks().get(0);
  inputs.addAll(driver.getPlan().getInputs());
  outputs.addAll(driver.getPlan().getOutputs());
  IndexMetadataChangeWork indexMetaChange=new IndexMetadataChangeWork(partSpec,indexTableName,dbName);
  IndexMetadataChangeTask indexMetaChangeTsk=new IndexMetadataChangeTask();
  indexMetaChangeTsk.setWork(indexMetaChange);
  rootTask.addDependentTask(indexMetaChangeTsk);
  return rootTask;
}
