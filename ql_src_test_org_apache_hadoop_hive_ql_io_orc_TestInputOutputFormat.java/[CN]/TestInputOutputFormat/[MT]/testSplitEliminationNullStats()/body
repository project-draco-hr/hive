{
  Properties properties=new Properties();
  StructObjectInspector inspector;
synchronized (TestOrcFile.class) {
    inspector=(StructObjectInspector)ObjectInspectorFactory.getReflectionObjectInspector(SimpleRow.class,ObjectInspectorFactory.ObjectInspectorOptions.JAVA);
  }
  SerDe serde=new OrcSerde();
  OutputFormat<?,?> outFormat=new OrcOutputFormat();
  conf.setInt("mapred.max.split.size",50);
  RecordWriter writer=outFormat.getRecordWriter(fs,conf,testFilePath.toString(),Reporter.NULL);
  writer.write(NullWritable.get(),serde.serialize(new SimpleRow(null),inspector));
  writer.write(NullWritable.get(),serde.serialize(new SimpleRow(null),inspector));
  writer.write(NullWritable.get(),serde.serialize(new SimpleRow(null),inspector));
  writer.close(Reporter.NULL);
  serde=new OrcSerde();
  SearchArgument sarg=SearchArgumentFactory.newBuilder().startAnd().lessThan("z",PredicateLeaf.Type.STRING,new String("foo")).end().build();
  conf.set("sarg.pushdown",sarg.toKryo());
  conf.set("hive.io.file.readcolumn.names","z");
  properties.setProperty("columns","z");
  properties.setProperty("columns.types","string");
  SerDeUtils.initializeSerDe(serde,conf,properties,null);
  inspector=(StructObjectInspector)serde.getObjectInspector();
  InputFormat<?,?> in=new OrcInputFormat();
  FileInputFormat.setInputPaths(conf,testFilePath.toString());
  InputSplit[] splits=in.getSplits(conf,1);
  assertEquals(0,splits.length);
}
