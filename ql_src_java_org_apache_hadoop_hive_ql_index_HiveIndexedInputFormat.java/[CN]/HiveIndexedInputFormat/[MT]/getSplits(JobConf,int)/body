{
  String indexFileStr=job.get(indexFile);
  l4j.info("index_file is " + indexFileStr);
  List<String> indexFiles=getIndexFiles(indexFileStr);
  HiveIndexResult hiveIndexResult=null;
  if (indexFiles != null) {
    boolean first=true;
    StringBuilder newInputPaths=new StringBuilder();
    try {
      hiveIndexResult=new HiveIndexResult(indexFiles,job);
    }
 catch (    HiveException e) {
      l4j.error("Unable to read index..");
      throw new IOException(e);
    }
    Set<String> inputFiles=hiveIndexResult.buckets.keySet();
    if (inputFiles == null || inputFiles.size() <= 0) {
      return new InputSplit[0];
    }
    Iterator<String> iter=inputFiles.iterator();
    while (iter.hasNext()) {
      String path=iter.next();
      if (path.trim().equalsIgnoreCase("")) {
        continue;
      }
      if (!first) {
        newInputPaths.append(",");
      }
 else {
        first=false;
      }
      newInputPaths.append(path);
    }
    FileInputFormat.setInputPaths(job,newInputPaths.toString());
  }
 else {
    return super.getSplits(job,numSplits);
  }
  HiveInputSplit[] splits=(HiveInputSplit[])this.doGetSplits(job,numSplits);
  ArrayList<HiveInputSplit> newSplits=new ArrayList<HiveInputSplit>(numSplits);
  long maxInputSize=HiveConf.getLongVar(job,ConfVars.HIVE_INDEX_COMPACT_QUERY_MAX_SIZE);
  if (maxInputSize < 0) {
    maxInputSize=Long.MAX_VALUE;
  }
  long sumSplitLengths=0;
  for (  HiveInputSplit split : splits) {
    l4j.info("split start : " + split.getStart());
    l4j.info("split end : " + (split.getStart() + split.getLength()));
    try {
      if (hiveIndexResult.contains(split)) {
        HiveInputSplit newSplit=split;
        if (split.inputFormatClassName().contains("RCFile") || split.inputFormatClassName().contains("SequenceFile")) {
          if (split.getStart() > SequenceFile.SYNC_INTERVAL) {
            newSplit=new HiveInputSplit(new FileSplit(split.getPath(),split.getStart() - SequenceFile.SYNC_INTERVAL,split.getLength() + SequenceFile.SYNC_INTERVAL,split.getLocations()),split.inputFormatClassName());
          }
        }
        sumSplitLengths+=newSplit.getLength();
        if (sumSplitLengths > maxInputSize) {
          throw new IOException("Size of data to read during a compact-index-based query exceeded the maximum of " + maxInputSize + " set in "+ ConfVars.HIVE_INDEX_COMPACT_QUERY_MAX_SIZE.varname);
        }
        newSplits.add(newSplit);
      }
    }
 catch (    HiveException e) {
      throw new RuntimeException("Unable to get metadata for input table split" + split.getPath());
    }
  }
  InputSplit retA[]=newSplits.toArray((new FileSplit[newSplits.size()]));
  l4j.info("Number of input splits: " + splits.length + " new input splits: "+ retA.length+ ", sum of split lengths: "+ sumSplitLengths);
  return retA;
}
