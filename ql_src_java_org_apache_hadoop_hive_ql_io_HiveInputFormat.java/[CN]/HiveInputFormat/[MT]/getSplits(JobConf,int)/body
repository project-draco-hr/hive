{
  init(job);
  Path[] dirs=FileInputFormat.getInputPaths(job);
  if (dirs.length == 0) {
    throw new IOException("No input paths specified in job");
  }
  JobConf newjob=new JobConf(job);
  ArrayList<InputSplit> result=new ArrayList<InputSplit>();
  for (  Path dir : dirs) {
    PartitionDesc part=getPartitionDescFromPath(pathToPartitionInfo,dir);
    Class inputFormatClass=part.getInputFileFormatClass();
    InputFormat inputFormat=getInputFormatFromCache(inputFormatClass,job);
    Utilities.copyTableJobPropertiesToConf(part.getTableDesc(),newjob);
    ArrayList<String> aliases=mrwork.getPathToAliases().get(dir.toUri().toString());
    if ((aliases != null) && (aliases.size() == 1)) {
      Operator op=mrwork.getAliasToWork().get(aliases.get(0));
      if ((op != null) && (op instanceof TableScanOperator)) {
        TableScanOperator tableScan=(TableScanOperator)op;
        pushFilters(newjob,tableScan);
      }
    }
    FileInputFormat.setInputPaths(newjob,dir);
    newjob.setInputFormat(inputFormat.getClass());
    InputSplit[] iss=inputFormat.getSplits(newjob,numSplits / dirs.length);
    for (    InputSplit is : iss) {
      result.add(new HiveInputSplit(is,inputFormatClass.getName()));
    }
  }
  LOG.info("number of splits " + result.size());
  return result.toArray(new HiveInputSplit[result.size()]);
}
