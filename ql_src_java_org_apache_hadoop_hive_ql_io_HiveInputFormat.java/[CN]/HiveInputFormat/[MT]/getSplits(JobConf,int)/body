{
  PerfLogger perfLogger=PerfLogger.getPerfLogger();
  perfLogger.PerfLogBegin(CLASS_NAME,PerfLogger.GET_SPLITS);
  init(job);
  Path[] dirs=FileInputFormat.getInputPaths(job);
  if (dirs.length == 0) {
    throw new IOException("No input paths specified in job");
  }
  JobConf newjob=new JobConf(job);
  ArrayList<InputSplit> result=new ArrayList<InputSplit>();
  for (  Path dir : dirs) {
    PartitionDesc part=getPartitionDescFromPath(pathToPartitionInfo,dir);
    Class inputFormatClass=part.getInputFileFormatClass();
    InputFormat inputFormat=getInputFormatFromCache(inputFormatClass,job);
    Utilities.copyTableJobPropertiesToConf(part.getTableDesc(),newjob);
    ArrayList<String> aliases=mrwork.getPathToAliases().get(dir.toUri().toString());
    if ((aliases != null) && (aliases.size() == 1)) {
      Operator op=mrwork.getAliasToWork().get(aliases.get(0));
      if ((op != null) && (op instanceof TableScanOperator)) {
        TableScanOperator tableScan=(TableScanOperator)op;
        ColumnProjectionUtils.appendReadColumns(newjob,tableScan.getNeededColumnIDs(),tableScan.getNeededColumns());
        pushFilters(newjob,tableScan);
      }
    }
    FileInputFormat.setInputPaths(newjob,dir);
    newjob.setInputFormat(inputFormat.getClass());
    TableDesc tableDesc=part.getTableDesc();
    int headerCount=0;
    int footerCount=0;
    if (tableDesc != null) {
      headerCount=Utilities.getHeaderCount(tableDesc);
      footerCount=Utilities.getFooterCount(tableDesc,newjob);
      if (headerCount != 0 || footerCount != 0) {
        newjob.setLong("mapred.min.split.size",Long.MAX_VALUE);
      }
    }
    InputSplit[] iss=inputFormat.getSplits(newjob,numSplits / dirs.length);
    for (    InputSplit is : iss) {
      result.add(new HiveInputSplit(is,inputFormatClass.getName()));
    }
  }
  LOG.info("number of splits " + result.size());
  perfLogger.PerfLogEnd(CLASS_NAME,PerfLogger.GET_SPLITS);
  return result.toArray(new HiveInputSplit[result.size()]);
}
