{
  PerfLogger perfLogger=PerfLogger.getPerfLogger();
  perfLogger.PerfLogBegin(CLASS_NAME,PerfLogger.GET_SPLITS);
  init(job);
  Path[] dirs=FileInputFormat.getInputPaths(job);
  if (dirs.length == 0) {
    if (HiveConf.getVar(job,HiveConf.ConfVars.HIVE_EXECUTION_ENGINE).equals("tez")) {
      try {
        List<Path> paths=Utilities.getInputPathsTez(job,mrwork);
        dirs=paths.toArray(new Path[paths.size()]);
        if (dirs.length == 0) {
          throw new IOException("No input paths specified in job");
        }
      }
 catch (      Exception e) {
        throw new IOException("Could not create input files",e);
      }
    }
 else {
      throw new IOException("No input paths specified in job");
    }
  }
  JobConf newjob=new JobConf(job);
  List<InputSplit> result=new ArrayList<InputSplit>();
  List<Path> currentDirs=new ArrayList<Path>();
  Class<? extends InputFormat> currentInputFormatClass=null;
  TableDesc currentTable=null;
  TableScanOperator currentTableScan=null;
  for (  Path dir : dirs) {
    PartitionDesc part=getPartitionDescFromPath(pathToPartitionInfo,dir);
    Class<? extends InputFormat> inputFormatClass=part.getInputFileFormatClass();
    TableDesc table=part.getTableDesc();
    TableScanOperator tableScan=null;
    List<String> aliases=mrwork.getPathToAliases().get(dir.toUri().toString());
    if ((aliases != null) && (aliases.size() == 1)) {
      Operator op=mrwork.getAliasToWork().get(aliases.get(0));
      if ((op != null) && (op instanceof TableScanOperator)) {
        tableScan=(TableScanOperator)op;
        ColumnProjectionUtils.appendReadColumns(newjob,tableScan.getNeededColumnIDs(),tableScan.getNeededColumns());
        pushFilters(newjob,tableScan);
      }
    }
    if (!currentDirs.isEmpty() && inputFormatClass.equals(currentInputFormatClass) && table.equals(currentTable)&& tableScan == currentTableScan) {
      currentDirs.add(dir);
      continue;
    }
    if (!currentDirs.isEmpty()) {
      LOG.info("Generating splits");
      addSplitsForGroup(currentDirs,currentTableScan,newjob,getInputFormatFromCache(currentInputFormatClass,job),currentInputFormatClass,currentDirs.size() * (numSplits / dirs.length),currentTable,result);
    }
    currentDirs.clear();
    currentDirs.add(dir);
    currentTableScan=tableScan;
    currentTable=table;
    currentInputFormatClass=inputFormatClass;
  }
  LOG.info("Generating splits");
  addSplitsForGroup(currentDirs,currentTableScan,newjob,getInputFormatFromCache(currentInputFormatClass,job),currentInputFormatClass,currentDirs.size() * (numSplits / dirs.length),currentTable,result);
  LOG.info("number of splits " + result.size());
  perfLogger.PerfLogEnd(CLASS_NAME,PerfLogger.GET_SPLITS);
  return result.toArray(new HiveInputSplit[result.size()]);
}
