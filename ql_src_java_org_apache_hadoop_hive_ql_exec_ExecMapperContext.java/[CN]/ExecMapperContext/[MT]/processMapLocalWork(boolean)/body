{
  if (fetchOperators != null) {
    try {
      int fetchOpNum=0;
      for (      Map.Entry<String,FetchOperator> entry : fetchOperators.entrySet()) {
        int fetchOpRows=0;
        String alias=entry.getKey();
        FetchOperator fetchOp=entry.getValue();
        if (inputFileChangeSenstive) {
          fetchOp.clearFetchContext();
          setUpFetchOpContext(fetchOp,alias);
        }
        Operator<? extends Serializable> forwardOp=localWork.getAliasToWork().get(alias);
        while (true) {
          InspectableObject row=fetchOp.getNextRow();
          if (row == null) {
            forwardOp.close(false);
            break;
          }
          fetchOpRows++;
          forwardOp.process(row.o,0);
          if (forwardOp.getDone()) {
            ExecMapper.setDone(true);
            break;
          }
        }
        if (l4j.isInfoEnabled()) {
          l4j.info("fetch " + fetchOpNum++ + " processed "+ fetchOpRows+ " used mem: "+ ExecMapper.memoryMXBean.getHeapMemoryUsage().getUsed());
        }
      }
    }
 catch (    Throwable e) {
      if (e instanceof OutOfMemoryError) {
        throw (OutOfMemoryError)e;
      }
 else {
        throw new HiveException("Hive Runtime Error: Map local work failed",e);
      }
    }
  }
}
