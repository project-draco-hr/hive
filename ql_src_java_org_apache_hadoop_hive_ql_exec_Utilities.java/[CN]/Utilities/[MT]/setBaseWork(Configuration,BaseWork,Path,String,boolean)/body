{
  Kryo kryo=SerializationUtilities.borrowKryo();
  try {
    setPlanPath(conf,hiveScratchDir);
    Path planPath=getPlanPath(conf,name);
    OutputStream out=null;
    if (HiveConf.getBoolVar(conf,ConfVars.HIVE_RPC_QUERY_PLAN)) {
      ByteArrayOutputStream byteOut=new ByteArrayOutputStream();
      try {
        out=new DeflaterOutputStream(byteOut,new Deflater(Deflater.BEST_SPEED));
        SerializationUtilities.serializePlan(kryo,w,out);
        out.close();
        out=null;
      }
  finally {
        IOUtils.closeStream(out);
      }
      LOG.info("Setting plan: " + planPath.toUri().getPath());
      conf.set(planPath.toUri().getPath(),Base64.encodeBase64String(byteOut.toByteArray()));
    }
 else {
      FileSystem fs=planPath.getFileSystem(conf);
      try {
        out=fs.create(planPath);
        SerializationUtilities.serializePlan(kryo,w,out);
        out.close();
        out=null;
      }
  finally {
        IOUtils.closeStream(out);
      }
      if (useCache && !ShimLoader.getHadoopShims().isLocalMode(conf)) {
        if (!DistributedCache.getSymlink(conf)) {
          DistributedCache.createSymlink(conf);
        }
        String uriWithLink=planPath.toUri().toString() + "#" + name;
        DistributedCache.addCacheFile(new URI(uriWithLink),conf);
        short replication=(short)conf.getInt("mapred.submit.replication",10);
        fs.setReplication(planPath,replication);
      }
    }
    gWorkMap.get(conf).put(planPath,w);
    return planPath;
  }
 catch (  Exception e) {
    String msg="Error caching " + name + ": "+ e;
    LOG.error(msg,e);
    throw new RuntimeException(msg,e);
  }
 finally {
    SerializationUtilities.releaseKryo(kryo);
  }
}
