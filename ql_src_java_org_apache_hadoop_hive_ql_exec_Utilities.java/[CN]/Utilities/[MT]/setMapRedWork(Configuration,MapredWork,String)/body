{
  try {
    String jobID=UUID.randomUUID().toString();
    Path planPath=new Path(hiveScratchDir,jobID);
    HiveConf.setVar(job,HiveConf.ConfVars.PLAN,planPath.toUri().toString());
    if (!HiveConf.getVar(job,HiveConf.ConfVars.HADOOPJT).equals("local")) {
      FileSystem fs=planPath.getFileSystem(job);
      FSDataOutputStream out=fs.create(planPath);
      serializeMapRedWork(w,out);
      DistributedCache.createSymlink(job);
      String uriWithLink=planPath.toUri().toString() + "#HIVE_PLAN" + jobID;
      DistributedCache.addCacheFile(new URI(uriWithLink),job);
      short replication=(short)job.getInt("mapred.submit.replication",10);
      fs.setReplication(planPath,replication);
    }
    w.initialize();
    gWorkMap.put(jobID,w);
  }
 catch (  Exception e) {
    e.printStackTrace();
    throw new RuntimeException(e);
  }
}
