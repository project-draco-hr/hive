{
  Path path=null;
  InputStream in=null;
  Kryo kryo=SerializationUtilities.borrowKryo();
  try {
    String engine=HiveConf.getVar(conf,ConfVars.HIVE_EXECUTION_ENGINE);
    if (engine.equals("spark")) {
      String addedJars=conf.get(HIVE_ADDED_JARS);
      if (addedJars != null && !addedJars.isEmpty()) {
        ClassLoader loader=Thread.currentThread().getContextClassLoader();
        ClassLoader newLoader=addToClassPath(loader,addedJars.split(";"));
        Thread.currentThread().setContextClassLoader(newLoader);
        kryo.setClassLoader(newLoader);
      }
    }
    path=getPlanPath(conf,name);
    LOG.info("PLAN PATH = " + path);
    if (path == null) {
      return null;
    }
    BaseWork gWork=gWorkMap.get(conf).get(path);
    if (gWork == null) {
      Path localPath=path;
      LOG.debug("local path = " + localPath);
      if (HiveConf.getBoolVar(conf,ConfVars.HIVE_RPC_QUERY_PLAN)) {
        LOG.debug("Loading plan from string: " + path.toUri().getPath());
        String planString=conf.getRaw(path.toUri().getPath());
        if (planString == null) {
          LOG.info("Could not find plan string in conf");
          return null;
        }
        byte[] planBytes=Base64.decodeBase64(planString);
        in=new ByteArrayInputStream(planBytes);
        in=new InflaterInputStream(in);
      }
 else {
        LOG.debug("Open file to read in plan: " + localPath);
        in=localPath.getFileSystem(conf).open(localPath);
      }
      if (MAP_PLAN_NAME.equals(name)) {
        if (ExecMapper.class.getName().equals(conf.get(MAPRED_MAPPER_CLASS))) {
          gWork=SerializationUtilities.deserializePlan(kryo,in,MapWork.class);
        }
 else         if (MergeFileMapper.class.getName().equals(conf.get(MAPRED_MAPPER_CLASS))) {
          gWork=SerializationUtilities.deserializePlan(kryo,in,MergeFileWork.class);
        }
 else         if (ColumnTruncateMapper.class.getName().equals(conf.get(MAPRED_MAPPER_CLASS))) {
          gWork=SerializationUtilities.deserializePlan(kryo,in,ColumnTruncateWork.class);
        }
 else         if (PartialScanMapper.class.getName().equals(conf.get(MAPRED_MAPPER_CLASS))) {
          gWork=SerializationUtilities.deserializePlan(kryo,in,PartialScanWork.class);
        }
 else {
          throw new RuntimeException("unable to determine work from configuration ." + MAPRED_MAPPER_CLASS + " was "+ conf.get(MAPRED_MAPPER_CLASS));
        }
      }
 else       if (REDUCE_PLAN_NAME.equals(name)) {
        if (ExecReducer.class.getName().equals(conf.get(MAPRED_REDUCER_CLASS))) {
          gWork=SerializationUtilities.deserializePlan(kryo,in,ReduceWork.class);
        }
 else {
          throw new RuntimeException("unable to determine work from configuration ." + MAPRED_REDUCER_CLASS + " was "+ conf.get(MAPRED_REDUCER_CLASS));
        }
      }
 else       if (name.contains(MERGE_PLAN_NAME)) {
        if (name.startsWith(MAPNAME)) {
          gWork=SerializationUtilities.deserializePlan(kryo,in,MapWork.class);
        }
 else         if (name.startsWith(REDUCENAME)) {
          gWork=SerializationUtilities.deserializePlan(kryo,in,ReduceWork.class);
        }
 else {
          throw new RuntimeException("Unknown work type: " + name);
        }
      }
      gWorkMap.get(conf).put(path,gWork);
    }
 else     if (LOG.isDebugEnabled()) {
      LOG.debug("Found plan in cache for name: " + name);
    }
    return gWork;
  }
 catch (  FileNotFoundException fnf) {
    LOG.debug("No plan file found: " + path,fnf);
    return null;
  }
catch (  Exception e) {
    String msg="Failed to load plan: " + path;
    LOG.error("Failed to load plan: " + path,e);
    throw new RuntimeException(msg,e);
  }
 finally {
    SerializationUtilities.releaseKryo(kryo);
    if (in != null) {
      try {
        in.close();
      }
 catch (      IOException cantBlameMeForTrying) {
      }
    }
  }
}
