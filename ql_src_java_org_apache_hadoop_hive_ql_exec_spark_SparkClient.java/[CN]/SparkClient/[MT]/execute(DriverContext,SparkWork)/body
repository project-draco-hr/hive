{
  Context ctx=driverContext.getCtx();
  HiveConf hiveConf=(HiveConf)ctx.getConf();
  refreshLocalResources(sparkWork,hiveConf);
  JobConf jobConf=new JobConf(hiveConf);
  Path emptyScratchDir;
  emptyScratchDir=ctx.getMRTmpPath();
  FileSystem fs=emptyScratchDir.getFileSystem(jobConf);
  fs.mkdirs(emptyScratchDir);
  SparkCounters sparkCounters=new SparkCounters(sc,hiveConf);
  List<String> prefixes=sparkWork.getRequiredCounterPrefix();
  if (prefixes != null) {
    for (    String prefix : prefixes) {
      sparkCounters.createCounter(prefix,StatsSetupConst.ROW_COUNT);
      sparkCounters.createCounter(prefix,StatsSetupConst.RAW_DATA_SIZE);
    }
  }
  SparkReporter sparkReporter=new SparkReporter(sparkCounters);
  SparkPlanGenerator gen=new SparkPlanGenerator(sc,ctx,jobConf,emptyScratchDir,sparkReporter);
  SparkPlan plan=gen.generate(sparkWork);
  JavaPairRDD<HiveKey,BytesWritable> finalRDD=plan.generateGraph();
  JavaFutureAction<Void> future=finalRDD.foreachAsync(HiveVoidFunction.getInstance());
  int jobId=future.jobIds().get(0);
  SimpleSparkJobStatus sparkJobStatus=new SimpleSparkJobStatus(jobId,jobStateListener,jobProgressListener,sparkCounters);
  return new SparkJobRef(jobId,sparkJobStatus);
}
