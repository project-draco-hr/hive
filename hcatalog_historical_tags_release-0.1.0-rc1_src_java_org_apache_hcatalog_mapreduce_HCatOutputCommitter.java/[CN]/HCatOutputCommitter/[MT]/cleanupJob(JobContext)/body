{
  OutputJobInfo jobInfo=HCatOutputFormat.getJobInfo(context);
  Configuration conf=context.getConfiguration();
  Table table=jobInfo.getTable();
  StorageDescriptor tblSD=table.getSd();
  Path tblPath=new Path(tblSD.getLocation());
  FileSystem fs=tblPath.getFileSystem(conf);
  if (table.getPartitionKeys().size() == 0) {
    if (baseCommitter != null) {
      baseCommitter.cleanupJob(context);
    }
    Path src=new Path(jobInfo.getLocation());
    moveTaskOutputs(fs,src,src,tblPath);
    fs.delete(src,true);
    return;
  }
  HiveMetaStoreClient client=null;
  List<String> values=null;
  boolean partitionAdded=false;
  HCatTableInfo tableInfo=jobInfo.getTableInfo();
  try {
    client=HCatOutputFormat.createHiveClient(tableInfo.getServerUri(),conf);
    StorerInfo storer=InitializeInput.extractStorerInfo(table.getSd(),table.getParameters());
    Partition partition=new Partition();
    partition.setDbName(tableInfo.getDatabaseName());
    partition.setTableName(tableInfo.getTableName());
    partition.setSd(new StorageDescriptor(tblSD));
    partition.getSd().setLocation(jobInfo.getLocation());
    updateTableSchema(client,table,jobInfo.getOutputSchema());
    List<FieldSchema> fields=new ArrayList<FieldSchema>();
    for (    HCatFieldSchema fieldSchema : jobInfo.getOutputSchema().getFields()) {
      fields.add(HCatSchemaUtils.getFieldSchema(fieldSchema));
    }
    partition.getSd().setCols(fields);
    Map<String,String> partKVs=tableInfo.getPartitionValues();
    partition.setValues(getPartitionValueList(table,partKVs));
    Map<String,String> params=new HashMap<String,String>();
    params.put(HCatConstants.HCAT_ISD_CLASS,storer.getInputSDClass());
    params.put(HCatConstants.HCAT_OSD_CLASS,storer.getOutputSDClass());
    for (    Map.Entry<Object,Object> entry : storer.getProperties().entrySet()) {
      params.put(entry.getKey().toString(),entry.getValue().toString());
    }
    partition.setParameters(params);
    FileStatus tblStat=fs.getFileStatus(tblPath);
    String grpName=tblStat.getGroup();
    FsPermission perms=tblStat.getPermission();
    Path partPath=tblPath;
    for (    FieldSchema partKey : table.getPartitionKeys()) {
      partPath=constructPartialPartPath(partPath,partKey.getName().toLowerCase(),partKVs);
      fs.setPermission(partPath,perms);
      try {
        fs.setOwner(partPath,null,grpName);
      }
 catch (      AccessControlException ace) {
      }
    }
    client.add_partition(partition);
    partitionAdded=true;
    if (baseCommitter != null) {
      baseCommitter.cleanupJob(context);
    }
    String tokenStrForm=client.getTokenStrForm();
    if (tokenStrForm != null && context.getConfiguration().get(HCatConstants.HCAT_KEY_TOKEN_SIGNATURE) != null) {
      client.cancelDelegationToken(tokenStrForm);
    }
  }
 catch (  Exception e) {
    if (partitionAdded) {
      try {
        client.dropPartition(tableInfo.getDatabaseName(),tableInfo.getTableName(),values);
      }
 catch (      Exception te) {
        throw new HCatException(ErrorType.ERROR_PUBLISHING_PARTITION,e);
      }
    }
    if (e instanceof HCatException) {
      throw (HCatException)e;
    }
 else {
      throw new HCatException(ErrorType.ERROR_PUBLISHING_PARTITION,e);
    }
  }
 finally {
    if (client != null) {
      client.close();
    }
  }
}
