{
  if (!setupHasRun) {
    setupHasRun=true;
  }
 else {
    return;
  }
  HiveConf hiveConf=new HiveConf(this.getClass());
  hiveConf.set(HiveConf.ConfVars.PREEXECHOOKS.varname,"");
  hiveConf.set(HiveConf.ConfVars.POSTEXECHOOKS.varname,"");
  hiveConf.set(HiveConf.ConfVars.HIVE_SUPPORT_CONCURRENCY.varname,"false");
  driver=new Driver(hiveConf);
  SessionState.start(new CliSessionState(hiveConf));
  props=new Properties();
  props.setProperty("fs.default.name",cluster.getProperties().getProperty("fs.default.name"));
  fullFileNameBasic=cluster.getProperties().getProperty("fs.default.name") + basicFile;
  fullFileNameComplex=cluster.getProperties().getProperty("fs.default.name") + complexFile;
  cleanup();
  createTable(BASIC_TABLE,"a int, b string");
  createTable(COMPLEX_TABLE,"name string, studentid int, " + "contact struct<phno:string,email:string>, " + "currently_registered_courses array<string>, "+ "current_grades map<string,string>, "+ "phnos array<struct<phno:string,type:string>>");
  createTable(PARTITIONED_TABLE,"a int, b string","bkt string");
  int LOOP_SIZE=3;
  String[] input=new String[LOOP_SIZE * LOOP_SIZE];
  basicInputData=new HashMap<Integer,Pair<Integer,String>>();
  int k=0;
  for (int i=1; i <= LOOP_SIZE; i++) {
    String si=i + "";
    for (int j=1; j <= LOOP_SIZE; j++) {
      String sj="S" + j + "S";
      input[k]=si + "\t" + sj;
      basicInputData.put(k,new Pair<Integer,String>(i,sj));
      k++;
    }
  }
  MiniCluster.createInputFile(cluster,basicFile,input);
  MiniCluster.createInputFile(cluster,complexFile,new String[]{});
  PigServer server=new PigServer(ExecType.LOCAL,props);
  UDFContext.getUDFContext().setClientSystemProps();
  server.setBatchOn();
  server.registerQuery("A = load '" + fullFileNameBasic + "' as (a:int, b:chararray);");
  server.registerQuery("store A into '" + BASIC_TABLE + "' using org.apache.hcatalog.pig.HCatStorer();");
  server.registerQuery("B = foreach A generate a,b;");
  server.registerQuery("B2 = filter B by a < 2;");
  server.registerQuery("store B2 into '" + PARTITIONED_TABLE + "' using org.apache.hcatalog.pig.HCatStorer('bkt=0');");
  server.registerQuery("C = foreach A generate a,b;");
  server.registerQuery("C2 = filter C by a >= 2;");
  server.registerQuery("store C2 into '" + PARTITIONED_TABLE + "' using org.apache.hcatalog.pig.HCatStorer('bkt=1');");
  server.registerQuery("D = load '" + fullFileNameComplex + "' as (name:chararray, studentid:int, contact:tuple(phno:chararray,email:chararray), currently_registered_courses:bag{innertup:tuple(course:chararray)}, current_grades:map[ ] , phnos :bag{innertup:tuple(phno:chararray,type:chararray)});");
  server.registerQuery("store D into '" + COMPLEX_TABLE + "' using org.apache.hcatalog.pig.HCatStorer();");
  server.executeBatch();
}
