{
  Path tblDataLocationPath=tbl.getDataLocation();
  try {
    Partition oldPart=getPartition(tbl,partSpec,false);
    Path oldPartPath=null;
    if (oldPart != null) {
      oldPartPath=oldPart.getDataLocation();
    }
    Path newPartPath=null;
    if (inheritTableSpecs) {
      Path partPath=new Path(tbl.getDataLocation(),Warehouse.makePartPath(partSpec));
      newPartPath=new Path(tblDataLocationPath.toUri().getScheme(),tblDataLocationPath.toUri().getAuthority(),partPath.toUri().getPath());
      if (oldPart != null) {
        FileSystem oldPartPathFS=oldPartPath.getFileSystem(getConf());
        FileSystem loadPathFS=loadPath.getFileSystem(getConf());
        if (FileUtils.equalsFileSystem(oldPartPathFS,loadPathFS)) {
          newPartPath=oldPartPath;
        }
      }
    }
 else {
      newPartPath=oldPartPath;
    }
    List<Path> newFiles=null;
    if (replace || (oldPart == null && !isAcid)) {
      Hive.replaceFiles(tbl.getPath(),loadPath,newPartPath,oldPartPath,getConf(),isSrcLocal);
    }
 else {
      if (conf.getBoolVar(ConfVars.FIRE_EVENTS_FOR_DML) && !tbl.isTemporary() && oldPart != null) {
        newFiles=Collections.synchronizedList(new ArrayList<Path>());
      }
      FileSystem fs=tbl.getDataLocation().getFileSystem(conf);
      Hive.copyFiles(conf,loadPath,newPartPath,fs,isSrcLocal,isAcid,newFiles);
    }
    Partition newTPart=oldPart != null ? oldPart : new Partition(tbl,partSpec,newPartPath);
    alterPartitionSpecInMemory(tbl,partSpec,newTPart.getTPartition(),inheritTableSpecs,newPartPath.toString());
    validatePartition(newTPart);
    if (null != newFiles) {
      fireInsertEvent(tbl,partSpec,newFiles);
    }
    StatsSetupConst.clearColumnStatsState(newTPart.getParameters());
    if (isSkewedStoreAsSubdir) {
      org.apache.hadoop.hive.metastore.api.Partition newCreatedTpart=newTPart.getTPartition();
      SkewedInfo skewedInfo=newCreatedTpart.getSd().getSkewedInfo();
      Map<List<String>,String> skewedColValueLocationMaps=constructListBucketingLocationMap(newPartPath,skewedInfo);
      skewedInfo.setSkewedColValueLocationMaps(skewedColValueLocationMaps);
      newCreatedTpart.getSd().setSkewedInfo(skewedInfo);
    }
    if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {
      StatsSetupConst.setBasicStatsState(newTPart.getParameters(),StatsSetupConst.FALSE);
    }
    if (oldPart == null) {
      newTPart.getTPartition().setParameters(new HashMap<String,String>());
      if (this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {
        StatsSetupConst.setBasicStatsStateForCreateTable(newTPart.getParameters(),StatsSetupConst.TRUE);
      }
      MetaStoreUtils.populateQuickStats(HiveStatsUtils.getFileStatusRecurse(newPartPath,-1,newPartPath.getFileSystem(conf)),newTPart.getParameters());
      getMSC().add_partition(newTPart.getTPartition());
    }
 else {
      EnvironmentContext environmentContext=null;
      if (hasFollowingStatsTask) {
        environmentContext=new EnvironmentContext();
        environmentContext.putToProperties(StatsSetupConst.DO_NOT_UPDATE_STATS,StatsSetupConst.TRUE);
      }
      alterPartition(tbl.getDbName(),tbl.getTableName(),new Partition(tbl,newTPart.getTPartition()),environmentContext);
    }
    return newTPart;
  }
 catch (  IOException e) {
    LOG.error(StringUtils.stringifyException(e));
    throw new HiveException(e);
  }
catch (  MetaException e) {
    LOG.error(StringUtils.stringifyException(e));
    throw new HiveException(e);
  }
catch (  InvalidOperationException e) {
    LOG.error(StringUtils.stringifyException(e));
    throw new HiveException(e);
  }
catch (  TException e) {
    LOG.error(StringUtils.stringifyException(e));
    throw new HiveException(e);
  }
}
