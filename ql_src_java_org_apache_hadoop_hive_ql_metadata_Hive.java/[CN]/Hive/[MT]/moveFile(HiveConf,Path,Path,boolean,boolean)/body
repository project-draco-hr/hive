{
  boolean success=false;
  final FileSystem srcFs, destFs;
  try {
    destFs=destf.getFileSystem(conf);
  }
 catch (  IOException e) {
    LOG.error("Failed to get dest fs",e);
    throw new HiveException(e.getMessage(),e);
  }
  try {
    srcFs=srcf.getFileSystem(conf);
  }
 catch (  IOException e) {
    LOG.error("Failed to get dest fs",e);
    throw new HiveException(e.getMessage(),e);
  }
  boolean inheritPerms=HiveConf.getBoolVar(conf,HiveConf.ConfVars.HIVE_WAREHOUSE_SUBDIR_INHERIT_PERMS);
  HadoopShims shims=ShimLoader.getHadoopShims();
  HadoopShims.HdfsFileStatus destStatus=null;
  boolean destIsSubDir=isSubDir(srcf,destf,srcFs,destFs,isSrcLocal);
  try {
    if (inheritPerms || replace) {
      try {
        destStatus=shims.getFullFileStatus(conf,destFs,destf);
        if (replace && !destIsSubDir) {
          LOG.debug("The path " + destf.toString() + " is deleted");
          destFs.delete(destf,true);
        }
      }
 catch (      FileNotFoundException ignore) {
        if (inheritPerms) {
          destStatus=shims.getFullFileStatus(conf,destFs,destf.getParent());
        }
      }
    }
    if (isSrcLocal) {
      destFs.copyFromLocalFile(srcf,destf);
      success=true;
    }
 else {
      if (needToCopy(srcf,destf,srcFs,destFs)) {
        LOG.info("Copying source " + srcf + " to "+ destf+ " because HDFS encryption zones are different.");
        success=FileUtils.copy(srcf.getFileSystem(conf),srcf,destf.getFileSystem(conf),destf,true,replace,conf);
      }
 else {
        if (destIsSubDir) {
          FileStatus[] srcs=destFs.listStatus(srcf,FileUtils.HIDDEN_FILES_PATH_FILTER);
          if (srcs.length == 0) {
            success=true;
          }
 else {
            List<Future<Boolean>> futures=new LinkedList<>();
            final ExecutorService pool=Executors.newFixedThreadPool(conf.getIntVar(ConfVars.HIVE_MOVE_FILES_THREAD_COUNT),new ThreadFactoryBuilder().setDaemon(true).setNameFormat("MoveDir-Thread-%d").build());
            for (            final FileStatus status : srcs) {
              futures.add(pool.submit(new Callable<Boolean>(){
                @Override public Boolean call() throws Exception {
                  return destFs.rename(status.getPath(),destf);
                }
              }
));
            }
            pool.shutdown();
            boolean allFutures=true;
            for (            Future<Boolean> future : futures) {
              try {
                Boolean result=future.get();
                allFutures&=result;
                if (!result) {
                  LOG.debug("Failed to rename.");
                  pool.shutdownNow();
                }
              }
 catch (              Exception e) {
                LOG.debug("Failed to rename.",e.getMessage());
                pool.shutdownNow();
                throw new HiveException(e.getCause());
              }
            }
            success=allFutures;
          }
        }
 else {
          success=destFs.rename(srcf,destf);
        }
      }
    }
    LOG.info((replace ? "Replacing src:" : "Renaming src: ") + srcf.toString() + ", dest: "+ destf.toString()+ ", Status:"+ success);
  }
 catch (  IOException ioe) {
    throw new HiveException("Unable to move source " + srcf + " to destination "+ destf,ioe);
  }
  if (success && inheritPerms) {
    try {
      ShimLoader.getHadoopShims().setFullFileStatus(conf,destStatus,destFs,destf);
    }
 catch (    IOException e) {
      LOG.warn("Error setting permission of file " + destf + ": "+ e.getMessage(),e);
    }
  }
  return success;
}
