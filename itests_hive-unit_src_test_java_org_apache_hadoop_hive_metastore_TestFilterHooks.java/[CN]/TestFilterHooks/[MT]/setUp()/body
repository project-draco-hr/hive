{
  DummyMetaStoreFilterHookImpl.blockResults=false;
  hiveConf=new HiveConf(TestFilterHooks.class);
  hiveConf.setIntVar(HiveConf.ConfVars.METASTORETHRIFTCONNECTIONRETRIES,3);
  hiveConf.set(HiveConf.ConfVars.PREEXECHOOKS.varname,"");
  hiveConf.set(HiveConf.ConfVars.POSTEXECHOOKS.varname,"");
  hiveConf.set(HiveConf.ConfVars.HIVE_SUPPORT_CONCURRENCY.varname,"false");
  hiveConf.setVar(ConfVars.METASTORE_FILTER_HOOK,DummyMetaStoreFilterHookImpl.class.getName());
  UtilsForTest.setNewDerbyDbLocation(hiveConf,TestFilterHooks.class.getSimpleName());
  int port=MetaStoreUtils.findFreePort();
  hiveConf.setVar(HiveConf.ConfVars.METASTOREURIS,"thrift://localhost:" + port);
  MetaStoreUtils.startMetaStore(port,ShimLoader.getHadoopThriftAuthBridge(),hiveConf);
  SessionState.start(new CliSessionState(hiveConf));
  msc=new HiveMetaStoreClient(hiveConf,null);
  driver=new Driver(hiveConf);
  driver.run("drop database if exists " + DBNAME1 + " cascade");
  driver.run("drop database if exists " + DBNAME2 + " cascade");
  driver.run("create database " + DBNAME1);
  driver.run("create database " + DBNAME2);
  driver.run("use " + DBNAME1);
  driver.run("create table " + DBNAME1 + "."+ TAB1+ " (id int, name string)");
  driver.run("create table " + TAB2 + " (id int) partitioned by (name string)");
  driver.run("ALTER TABLE " + TAB2 + " ADD PARTITION (name='value1')");
  driver.run("ALTER TABLE " + TAB2 + " ADD PARTITION (name='value2')");
  driver.run("CREATE INDEX " + INDEX1 + " on table "+ TAB1+ "(id) AS 'COMPACT' WITH DEFERRED REBUILD");
}
