{
  Table t=new Table();
  t.setSd(new StorageDescriptor());
  t.setTableName(schema.getProperty(org.apache.hadoop.hive.metastore.api.Constants.META_TABLE_NAME));
  t.getSd().setLocation(schema.getProperty(org.apache.hadoop.hive.metastore.api.Constants.META_TABLE_LOCATION));
  t.getSd().setInputFormat(schema.getProperty(org.apache.hadoop.hive.metastore.api.Constants.FILE_INPUT_FORMAT,org.apache.hadoop.mapred.SequenceFileInputFormat.class.getName()));
  t.getSd().setOutputFormat(schema.getProperty(org.apache.hadoop.hive.metastore.api.Constants.FILE_OUTPUT_FORMAT,org.apache.hadoop.mapred.SequenceFileOutputFormat.class.getName()));
  t.setPartitionKeys(new ArrayList<FieldSchema>());
  t.setDatabase(MetaStoreUtils.DEFAULT_DATABASE_NAME);
  String part_cols_str=schema.getProperty(org.apache.hadoop.hive.metastore.api.Constants.META_TABLE_PARTITION_COLUMNS);
  if (part_cols_str != null && (part_cols_str.trim().length() != 0)) {
    String[] part_keys=part_cols_str.trim().split("/");
    for (    String key : part_keys) {
      FieldSchema part=new FieldSchema();
      part.setName(key);
      part.setType(Constants.STRING_TYPE_NAME);
      t.getPartitionKeys().add(part);
    }
  }
  t.getSd().setNumBuckets(Integer.parseInt(schema.getProperty(org.apache.hadoop.hive.metastore.api.Constants.BUCKET_COUNT,"-1")));
  String bucketFieldName=schema.getProperty(org.apache.hadoop.hive.metastore.api.Constants.BUCKET_FIELD_NAME);
  if ((bucketFieldName != null) && (bucketFieldName.trim().length() != 0)) {
    t.getSd().setBucketCols(new ArrayList<String>(1));
    t.getSd().getBucketCols().add(bucketFieldName);
  }
  t.getSd().setSerdeInfo(new SerDeInfo());
  t.getSd().getSerdeInfo().setName(t.getTableName());
  t.getSd().getSerdeInfo().setSerializationClass(schema.getProperty(org.apache.hadoop.hive.serde.Constants.SERIALIZATION_CLASS));
  t.getSd().getSerdeInfo().setSerializationFormat(schema.getProperty(org.apache.hadoop.hive.serde.Constants.SERIALIZATION_FORMAT));
  t.getSd().getSerdeInfo().setSerializationLib(schema.getProperty(org.apache.hadoop.hive.serde.Constants.SERIALIZATION_LIB));
  if (t.getSd().getSerdeInfo().getSerializationClass() == null || (t.getSd().getSerdeInfo().getSerializationClass().length() == 0)) {
    t.getSd().getSerdeInfo().setSerializationClass(schema.getProperty(org.apache.hadoop.hive.metastore.api.Constants.META_TABLE_SERDE));
  }
  String colstr=schema.getProperty(org.apache.hadoop.hive.metastore.api.Constants.META_TABLE_COLUMNS);
  List<FieldSchema> fields=new ArrayList<FieldSchema>();
  t.getSd().setCols(fields);
  if (colstr != null) {
    String[] cols=colstr.split(",");
    for (    String colName : cols) {
      FieldSchema col=new FieldSchema(colName,Constants.STRING_TYPE_NAME,"default string type");
      fields.add(col);
    }
  }
  if (fields.size() == 0) {
    fields.add(new FieldSchema("__SERDE__",t.getSd().getSerdeInfo().getSerializationLib(),""));
  }
  try {
    this.createTable(t);
  }
 catch (  Exception e) {
    MetaStoreUtils.logAndThrowMetaException(e);
  }
}
