{
  reset();
  QB qb=new QB(null,null,false);
  this.qb=qb;
  this.ast=ast;
  ASTNode child=ast;
  LOG.info("Starting Semantic Analysis");
  if (ast.getToken().getType() == HiveParser.TOK_CREATETABLE) {
    if ((child=analyzeCreateTable(ast,qb)) == null) {
      return;
    }
  }
 else {
    SessionState.get().setCommandType(HiveOperation.QUERY);
  }
  if (ast.getToken().getType() == HiveParser.TOK_CREATEVIEW) {
    child=analyzeCreateView(ast,qb);
    SessionState.get().setCommandType(HiveOperation.CREATEVIEW);
    if (child == null) {
      return;
    }
    viewSelect=child;
  }
  doPhase1(child,qb,initPhase1Ctx());
  LOG.info("Completed phase 1 of Semantic Analysis");
  getMetaData(qb);
  LOG.info("Completed getting MetaData in Semantic Analysis");
  Operator sinkOp=genPlan(qb);
  resultSchema=convertRowSchemaToViewSchema(opParseCtx.get(sinkOp).getRowResolver());
  if (createVwDesc != null) {
    saveViewDefinition();
    ctx.setResDir(null);
    ctx.setResFile(null);
    return;
  }
  ParseContext pCtx=new ParseContext(conf,qb,child,opToPartPruner,opToPartList,topOps,topSelOps,opParseCtx,joinContext,topToTable,loadTableWork,loadFileWork,ctx,idToTableNameMap,destTableId,uCtx,listMapJoinOpsNoReducer,groupOpToInputTables,prunedPartitions,opToSamplePruner,globalLimitCtx,nameToSplitSample);
  Optimizer optm=new Optimizer();
  optm.setPctx(pCtx);
  optm.initialize(conf);
  pCtx=optm.optimize();
  init(pCtx);
  qb=pCtx.getQB();
  genMapRedTasks(qb);
  LOG.info("Completed plan generation");
  return;
}
