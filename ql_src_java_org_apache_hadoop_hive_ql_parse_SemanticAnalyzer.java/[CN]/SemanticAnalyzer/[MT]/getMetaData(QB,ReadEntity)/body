{
  try {
    LOG.info("Get metadata for source tables");
    List<String> tabAliases=new ArrayList<String>(qb.getTabAliases());
    Map<String,ObjectPair<String,ReadEntity>> aliasToViewInfo=new HashMap<String,ObjectPair<String,ReadEntity>>();
    for (    String alias : tabAliases) {
      String tab_name=qb.getTabNameForAlias(alias);
      Table tab=null;
      try {
        tab=db.getTable(tab_name);
      }
 catch (      InvalidTableException ite) {
        throw new SemanticException(ErrorMsg.INVALID_TABLE.getMsg(qb.getParseInfo().getSrcForAlias(alias)));
      }
      if (qb.getParseInfo().isInsertIntoTable(tab.getDbName(),tab.getTableName()) && tab.getNumBuckets() > 0) {
        throw new SemanticException(ErrorMsg.INSERT_INTO_BUCKETIZED_TABLE.getMsg("Table: " + tab_name));
      }
      if (tab.isOffline()) {
        throw new SemanticException(ErrorMsg.OFFLINE_TABLE_OR_PARTITION.getMsg("Table " + getUnescapedName(qb.getParseInfo().getSrcForAlias(alias))));
      }
      if (tab.isView()) {
        if (qb.getParseInfo().isAnalyzeCommand()) {
          throw new SemanticException(ErrorMsg.ANALYZE_VIEW.getMsg());
        }
        String fullViewName=tab.getDbName() + "." + tab.getTableName();
        if (viewsExpanded.contains(fullViewName)) {
          throw new SemanticException("Recursive view " + fullViewName + " detected (cycle: "+ StringUtils.join(viewsExpanded," -> ")+ " -> "+ fullViewName+ ").");
        }
        replaceViewReferenceWithDefinition(qb,tab,tab_name,alias);
        ReadEntity viewInput=new ReadEntity(tab,parentInput);
        viewInput=PlanUtils.addInput(inputs,viewInput);
        aliasToViewInfo.put(alias,new ObjectPair<String,ReadEntity>(fullViewName,viewInput));
        viewAliasToInput.put(getAliasId(alias,qb),viewInput);
        continue;
      }
      if (!InputFormat.class.isAssignableFrom(tab.getInputFormatClass())) {
        throw new SemanticException(generateErrorMessage(qb.getParseInfo().getSrcForAlias(alias),ErrorMsg.INVALID_INPUT_FORMAT_TYPE.getMsg()));
      }
      qb.getMetaData().setSrcForAlias(alias,tab);
      if (qb.getParseInfo().isAnalyzeCommand()) {
        tableSpec ts=new tableSpec(db,conf,(ASTNode)ast.getChild(0),true,this.noscan);
        if (ts.specType == SpecType.DYNAMIC_PARTITION) {
          try {
            ts.partitions=db.getPartitionsByNames(ts.tableHandle,ts.partSpec);
          }
 catch (          HiveException e) {
            throw new SemanticException(generateErrorMessage(qb.getParseInfo().getSrcForAlias(alias),"Cannot get partitions for " + ts.partSpec),e);
          }
        }
        qb.getParseInfo().addTableSpec(alias,ts);
      }
    }
    LOG.info("Get metadata for subqueries");
    for (    String alias : qb.getSubqAliases()) {
      boolean wasView=aliasToViewInfo.containsKey(alias);
      ReadEntity newParentInput=null;
      if (wasView) {
        viewsExpanded.add(aliasToViewInfo.get(alias).getFirst());
        newParentInput=aliasToViewInfo.get(alias).getSecond();
      }
      QBExpr qbexpr=qb.getSubqForAlias(alias);
      getMetaData(qbexpr,newParentInput);
      if (wasView) {
        viewsExpanded.remove(viewsExpanded.size() - 1);
      }
    }
    LOG.info("Get metadata for destination tables");
    QBParseInfo qbp=qb.getParseInfo();
    for (    String name : qbp.getClauseNamesForDest()) {
      ASTNode ast=qbp.getDestForClause(name);
switch (ast.getToken().getType()) {
case HiveParser.TOK_TAB:
{
          tableSpec ts=new tableSpec(db,conf,ast);
          if (ts.tableHandle.isView()) {
            throw new SemanticException(ErrorMsg.DML_AGAINST_VIEW.getMsg());
          }
          Class<?> outputFormatClass=ts.tableHandle.getOutputFormatClass();
          if (!HiveOutputFormat.class.isAssignableFrom(outputFormatClass)) {
            throw new SemanticException(ErrorMsg.INVALID_OUTPUT_FORMAT_TYPE.getMsg(ast,"The class is " + outputFormatClass.toString()));
          }
          if (ts.specType != SpecType.STATIC_PARTITION) {
            qb.getMetaData().setDestForAlias(name,ts.tableHandle);
            if (ts.partSpec != null && ts.partSpec.size() > 0) {
              qb.getMetaData().setPartSpecForAlias(name,ts.partSpec);
            }
          }
 else {
            qb.getMetaData().setDestForAlias(name,ts.partHandle);
          }
          if (HiveConf.getBoolVar(conf,HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {
            qb.getParseInfo().setIsInsertToTable(true);
            qb.getParseInfo().addTableSpec(ts.tableName.toLowerCase(),ts);
          }
          break;
        }
case HiveParser.TOK_LOCAL_DIR:
case HiveParser.TOK_DIR:
{
        String fname=stripQuotes(ast.getChild(0).getText());
        if ((!qb.getParseInfo().getIsSubQ()) && (((ASTNode)ast.getChild(0)).getToken().getType() == HiveParser.TOK_TMP_FILE)) {
          if (qb.isCTAS()) {
            qb.setIsQuery(false);
            ctx.setResDir(null);
            ctx.setResFile(null);
            String tableName=getUnescapedName((ASTNode)ast.getChild(0));
            Table newTable=db.newTable(tableName);
            Path location;
            try {
              Warehouse wh=new Warehouse(conf);
              location=wh.getDatabasePath(db.getDatabase(newTable.getDbName()));
            }
 catch (            MetaException e) {
              throw new SemanticException(e);
            }
            try {
              fname=ctx.getExternalTmpFileURI(FileUtils.makeQualified(location,conf).toUri());
            }
 catch (            Exception e) {
              throw new SemanticException(generateErrorMessage(ast,"Error creating temporary folder on: " + location.toString()),e);
            }
            if (HiveConf.getBoolVar(conf,HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {
              tableSpec ts=new tableSpec(db,conf,this.ast);
              qb.getParseInfo().setIsInsertToTable(true);
              qb.getParseInfo().addTableSpec(ts.tableName.toLowerCase(),ts);
            }
          }
 else {
            qb.setIsQuery(true);
            fname=ctx.getMRTmpFileURI();
            ctx.setResDir(new Path(fname));
          }
        }
        qb.getMetaData().setDestForAlias(name,fname,(ast.getToken().getType() == HiveParser.TOK_DIR));
        break;
      }
default :
    throw new SemanticException(generateErrorMessage(ast,"Unknown Token Type " + ast.getToken().getType()));
}
}
}
 catch (HiveException e) {
LOG.error(org.apache.hadoop.util.StringUtils.stringifyException(e));
throw new SemanticException(e.getMessage(),e);
}
}
