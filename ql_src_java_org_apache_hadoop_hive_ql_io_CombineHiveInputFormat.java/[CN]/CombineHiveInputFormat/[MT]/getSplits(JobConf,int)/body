{
  init(job);
  CombineFileInputFormatShim combine=ShimLoader.getHadoopShims().getCombineFileInputFormat();
  if (combine.getInputPathsShim(job).length == 0) {
    throw new IOException("No input paths specified in job");
  }
  ArrayList<InputSplit> result=new ArrayList<InputSplit>();
  Path[] paths=combine.getInputPathsShim(job);
  for (int i=0; i < paths.length; i++) {
    LOG.info("CombineHiveInputSplit creating pool for " + paths[i]);
    combine.createPool(job,new CombineFilter(paths[i]));
  }
  InputSplitShim[] iss=(InputSplitShim[])combine.getSplits(job,1);
  for (  InputSplitShim is : iss) {
    CombineHiveInputSplit csplit=new CombineHiveInputSplit(job,is);
    result.add(csplit);
  }
  LOG.info("number of splits " + result.size());
  return result.toArray(new CombineHiveInputSplit[result.size()]);
}
