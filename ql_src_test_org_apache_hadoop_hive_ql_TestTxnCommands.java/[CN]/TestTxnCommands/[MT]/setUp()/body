{
  tearDown();
  hiveConf=new HiveConf(this.getClass());
  hiveConf.set(HiveConf.ConfVars.PREEXECHOOKS.varname,"");
  hiveConf.set(HiveConf.ConfVars.POSTEXECHOOKS.varname,"");
  hiveConf.set(HiveConf.ConfVars.HIVE_SUPPORT_CONCURRENCY.varname,"false");
  hiveConf.set(HiveConf.ConfVars.METASTOREWAREHOUSE.varname,TEST_WAREHOUSE_DIR);
  hiveConf.setVar(HiveConf.ConfVars.HIVEMAPREDMODE,"nonstrict");
  hiveConf.setVar(HiveConf.ConfVars.HIVE_AUTHORIZATION_MANAGER,"org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory");
  TxnDbUtil.setConfValues(hiveConf);
  TxnDbUtil.prepDb();
  File f=new File(TEST_WAREHOUSE_DIR);
  if (f.exists()) {
    FileUtil.fullyDelete(f);
  }
  if (!(new File(TEST_WAREHOUSE_DIR).mkdirs())) {
    throw new RuntimeException("Could not create " + TEST_WAREHOUSE_DIR);
  }
  SessionState.start(new SessionState(hiveConf));
  d=new Driver(hiveConf);
  dropTables();
  runStatementOnDriver("create table " + Table.ACIDTBL + "(a int, b int) clustered by (a) into "+ BUCKET_COUNT+ " buckets stored as orc TBLPROPERTIES ('transactional'='true')");
  runStatementOnDriver("create table " + Table.NONACIDORCTBL + "(a int, b int) clustered by (a) into "+ BUCKET_COUNT+ " buckets stored as orc TBLPROPERTIES ('transactional'='false')");
  runStatementOnDriver("create table " + Table.NONACIDORCTBL2 + "(a int, b int) clustered by (a) into "+ BUCKET_COUNT+ " buckets stored as orc TBLPROPERTIES ('transactional'='false')");
  runStatementOnDriver("create temporary  table " + Table.ACIDTBL2 + "(a int, b int, c int) clustered by (c) into "+ BUCKET_COUNT+ " buckets stored as orc TBLPROPERTIES ('transactional'='true')");
}
