{
  try {
    Tree fromTree=ast.getChild(0);
    boolean isLocationSet=false;
    boolean isExternalSet=false;
    boolean isTableSet=false;
    boolean isDbNameSet=false;
    boolean isPartSpecSet=false;
    String parsedLocation=null;
    String parsedTableName=null;
    String parsedDbName=null;
    LinkedHashMap<String,String> parsedPartSpec=new LinkedHashMap<String,String>();
    for (int i=1; i < ast.getChildCount(); ++i) {
      ASTNode child=(ASTNode)ast.getChild(i);
switch (child.getToken().getType()) {
case HiveParser.KW_EXTERNAL:
        isExternalSet=true;
      break;
case HiveParser.TOK_TABLELOCATION:
    isLocationSet=true;
  parsedLocation=EximUtil.relativeToAbsolutePath(conf,unescapeSQLString(child.getChild(0).getText()));
break;
case HiveParser.TOK_TAB:
isTableSet=true;
ASTNode tableNameNode=(ASTNode)child.getChild(0);
Map.Entry<String,String> dbTablePair=getDbTableNamePair(tableNameNode);
parsedDbName=dbTablePair.getKey();
parsedTableName=dbTablePair.getValue();
if (parsedDbName != null) {
isDbNameSet=true;
}
if (child.getChildCount() == 2) {
ASTNode partspec=(ASTNode)child.getChild(1);
isPartSpecSet=true;
parsePartitionSpec(child,parsedPartSpec);
}
break;
}
}
URI fromURI=EximUtil.getValidatedURI(conf,stripQuotes(fromTree.getText()));
FileSystem fs=FileSystem.get(fromURI,conf);
Path fromPath=new Path(fromURI.getScheme(),fromURI.getAuthority(),fromURI.getPath());
inputs.add(toReadEntity(fromPath));
EximUtil.ReadMetaData rv=new EximUtil.ReadMetaData();
try {
rv=EximUtil.readMetaData(fs,new Path(fromPath,METADATA_NAME));
}
 catch (IOException e) {
throw new SemanticException(ErrorMsg.INVALID_PATH.getMsg(),e);
}
ReplicationSpec replicationSpec=rv.getReplicationSpec();
if (replicationSpec.isNoop()) {
return;
}
String dbname=SessionState.get().getCurrentDatabase();
if (isDbNameSet) {
dbname=parsedDbName;
}
CreateTableDesc tblDesc=getBaseCreateTableDescFromTable(dbname,rv.getTable());
if (isExternalSet) {
tblDesc.setExternal(isExternalSet);
}
if (isLocationSet) {
tblDesc.setLocation(parsedLocation);
inputs.add(toReadEntity(parsedLocation));
}
if (isTableSet) {
tblDesc.setTableName(parsedTableName);
}
List<AddPartitionDesc> partitionDescs=new ArrayList<AddPartitionDesc>();
Iterable<Partition> partitions=rv.getPartitions();
for (Partition partition : partitions) {
AddPartitionDesc partsDesc=getBaseAddPartitionDescFromPartition(fromPath,dbname,tblDesc,partition);
partitionDescs.add(partsDesc);
}
if (isPartSpecSet) {
boolean found=false;
for (Iterator<AddPartitionDesc> partnIter=partitionDescs.listIterator(); partnIter.hasNext(); ) {
AddPartitionDesc addPartitionDesc=partnIter.next();
if (!found && addPartitionDesc.getPartition(0).getPartSpec().equals(parsedPartSpec)) {
found=true;
}
 else {
partnIter.remove();
}
}
if (!found) {
throw new SemanticException(ErrorMsg.INVALID_PARTITION.getMsg(" - Specified partition not found in import directory"));
}
}
if (tblDesc.getTableName() == null) {
throw new SemanticException(ErrorMsg.NEED_TABLE_SPECIFICATION.getMsg());
}
 else {
conf.set("import.destination.table",tblDesc.getTableName());
for (AddPartitionDesc addPartitionDesc : partitionDescs) {
addPartitionDesc.setTableName(tblDesc.getTableName());
}
}
Warehouse wh=new Warehouse(conf);
Table table=tableIfExists(tblDesc);
if (table != null) {
checkTable(table,tblDesc,replicationSpec);
LOG.debug("table " + tblDesc.getTableName() + " exists: metadata checked");
tableExists=true;
}
if (!replicationSpec.isInReplicationScope()) {
createRegularImportTasks(rootTasks,tblDesc,partitionDescs,isPartSpecSet,replicationSpec,table,fromURI,fs,wh);
}
 else {
createReplImportTasks(rootTasks,tblDesc,partitionDescs,isPartSpecSet,replicationSpec,table,fromURI,fs,wh);
}
}
 catch (SemanticException e) {
throw e;
}
catch (Exception e) {
throw new SemanticException(ErrorMsg.IMPORT_SEMANTIC_ERROR.getMsg(),e);
}
}
