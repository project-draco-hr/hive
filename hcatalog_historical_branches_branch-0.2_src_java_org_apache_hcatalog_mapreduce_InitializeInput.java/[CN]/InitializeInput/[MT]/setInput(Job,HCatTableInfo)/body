{
  HiveMetaStoreClient client=null;
  try {
    client=createHiveMetaClient(job.getConfiguration(),inputInfo);
    Table table=client.getTable(inputInfo.getDatabaseName(),inputInfo.getTableName());
    HCatSchema tableSchema=HCatUtil.getTableSchemaWithPtnCols(table);
    List<PartInfo> partInfoList=new ArrayList<PartInfo>();
    if (table.getPartitionKeys().size() != 0) {
      List<Partition> parts=client.listPartitionsByFilter(inputInfo.getDatabaseName(),inputInfo.getTableName(),inputInfo.getFilter(),(short)-1);
      int maxPart=hiveConf.getInt("hcat.metastore.maxpartitions",100000);
      if (parts != null && parts.size() > maxPart) {
        throw new HCatException(ErrorType.ERROR_EXCEED_MAXPART,"total number of partitions is " + parts.size());
      }
      for (      Partition ptn : parts) {
        PartInfo partInfo=extractPartInfo(ptn.getSd(),ptn.getParameters());
        partInfo.setPartitionValues(createPtnKeyValueMap(table,ptn));
        partInfoList.add(partInfo);
      }
    }
 else {
      PartInfo partInfo=extractPartInfo(table.getSd(),table.getParameters());
      partInfo.setPartitionValues(new HashMap<String,String>());
      partInfoList.add(partInfo);
    }
    JobInfo hcatJobInfo=new JobInfo(inputInfo,tableSchema,partInfoList);
    inputInfo.setJobInfo(hcatJobInfo);
    job.getConfiguration().set(HCatConstants.HCAT_KEY_JOB_INFO,HCatUtil.serialize(hcatJobInfo));
  }
  finally {
    if (client != null) {
      client.close();
    }
  }
}
