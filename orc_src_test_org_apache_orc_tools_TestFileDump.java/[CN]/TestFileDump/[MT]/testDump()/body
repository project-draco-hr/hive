{
  TypeDescription schema=getMyRecordType();
  conf.set(OrcConf.ENCODING_STRATEGY.getAttribute(),"COMPRESSION");
  Writer writer=OrcFile.createWriter(testFilePath,OrcFile.writerOptions(conf).fileSystem(fs).setSchema(schema).compress(CompressionKind.ZLIB).stripeSize(100000).rowIndexStride(1000));
  Random r1=new Random(1);
  String[] words=new String[]{"It","was","the","best","of","times,","it","was","the","worst","of","times,","it","was","the","age","of","wisdom,","it","was","the","age","of","foolishness,","it","was","the","epoch","of","belief,","it","was","the","epoch","of","incredulity,","it","was","the","season","of","Light,","it","was","the","season","of","Darkness,","it","was","the","spring","of","hope,","it","was","the","winter","of","despair,","we","had","everything","before","us,","we","had","nothing","before","us,","we","were","all","going","direct","to","Heaven,","we","were","all","going","direct","the","other","way"};
  VectorizedRowBatch batch=schema.createRowBatch(1000);
  for (int i=0; i < 21000; ++i) {
    appendMyRecord(batch,r1.nextInt(),r1.nextLong(),words[r1.nextInt(words.length)]);
    if (batch.size == batch.getMaxSize()) {
      writer.addRowBatch(batch);
      batch.reset();
    }
  }
  if (batch.size > 0) {
    writer.addRowBatch(batch);
  }
  writer.close();
  PrintStream origOut=System.out;
  String outputFilename="orc-file-dump.out";
  FileOutputStream myOut=new FileOutputStream(workDir + File.separator + outputFilename);
  System.setOut(new PrintStream(myOut));
  FileDump.main(new String[]{testFilePath.toString(),"--rowindex=1,2,3"});
  System.out.flush();
  System.setOut(origOut);
  checkOutput(outputFilename,workDir + File.separator + outputFilename);
}
