{
  Map<String,String> sparkConf=new HashMap<String,String>();
  sparkConf.put("spark.master",SPARK_DEFAULT_MASTER);
  sparkConf.put("spark.app.name",SPARK_DEFAULT_APP_NAME);
  sparkConf.put("spark.serializer","org.apache.spark.serializer.KryoSerializer");
  InputStream inputStream=null;
  try {
    inputStream=HiveSparkClientFactory.class.getClassLoader().getResourceAsStream(SPARK_DEFAULT_CONF_FILE);
    if (inputStream != null) {
      LOG.info("loading spark properties from:" + SPARK_DEFAULT_CONF_FILE);
      Properties properties=new Properties();
      properties.load(new InputStreamReader(inputStream,CharsetNames.UTF_8));
      for (      String propertyName : properties.stringPropertyNames()) {
        if (propertyName.startsWith("spark")) {
          String value=properties.getProperty(propertyName);
          sparkConf.put(propertyName,properties.getProperty(propertyName));
          LOG.info(String.format("load spark configuration from %s (%s -> %s).",SPARK_DEFAULT_CONF_FILE,propertyName,value));
        }
      }
    }
  }
 catch (  IOException e) {
    LOG.info("Failed to open spark configuration file:" + SPARK_DEFAULT_CONF_FILE,e);
  }
 finally {
    if (inputStream != null) {
      try {
        inputStream.close();
      }
 catch (      IOException e) {
        LOG.debug("Failed to close inputstream.",e);
      }
    }
  }
  for (  Map.Entry<String,String> entry : hiveConf) {
    String propertyName=entry.getKey();
    if (propertyName.startsWith("spark")) {
      String value=hiveConf.get(propertyName);
      sparkConf.put(propertyName,value);
      LOG.info(String.format("load spark configuration from hive configuration (%s -> %s).",propertyName,value));
    }
  }
  return sparkConf;
}
