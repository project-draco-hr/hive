{
  String dbName="test_db2";
  String funcName="test_func";
  String className="org.apache.hadoop.hive.ql.udf.generic.GenericUDFUpper";
  String owner="test_owner";
  PrincipalType ownerType=PrincipalType.USER;
  int createTime=(int)(System.currentTimeMillis() / 1000);
  FunctionType funcType=FunctionType.JAVA;
  List<ResourceUri> resList=new ArrayList<ResourceUri>();
  resList.add(new ResourceUri(ResourceType.JAR,"hdfs:///tmp/jar1.jar"));
  resList.add(new ResourceUri(ResourceType.FILE,"hdfs:///tmp/file1.txt"));
  resList.add(new ResourceUri(ResourceType.ARCHIVE,"hdfs:///tmp/archive1.tgz"));
  try {
    cleanUp(dbName,null,null);
    createDb(dbName);
    createFunction(dbName,funcName,className,owner,ownerType,createTime,funcType,resList);
    Function func=client.getFunction(dbName,funcName);
    assertEquals("function db name",dbName,func.getDbName());
    assertEquals("function name",funcName,func.getFunctionName());
    assertEquals("function class name",className,func.getClassName());
    assertEquals("function owner name",owner,func.getOwnerName());
    assertEquals("function owner type",PrincipalType.USER,func.getOwnerType());
    assertEquals("function type",funcType,func.getFunctionType());
    List<ResourceUri> resources=func.getResourceUris();
    assertEquals("Resource list size",resList.size(),resources.size());
    for (    ResourceUri res : resources) {
      assertTrue("Matching resource " + res.getResourceType() + " "+ res.getUri(),resList.indexOf(res) >= 0);
    }
    client.dropFunction(dbName,funcName);
  }
 catch (  Exception e) {
    System.err.println(StringUtils.stringifyException(e));
    System.err.println("testConcurrentMetastores() failed.");
    throw e;
  }
 finally {
    silentDropDatabase(dbName);
  }
}
