{
  HiveConf conf=SessionState.get().getConf();
  String value=new VariableSubstitution(new HiveVariableSource(){
    @Override public Map<String,String> getHiveVariable(){
      return SessionState.get().getHiveVariables();
    }
  }
).substitute(conf,varvalue);
  if (conf.getBoolVar(HiveConf.ConfVars.HIVECONFVALIDATION)) {
    HiveConf.ConfVars confVars=HiveConf.getConfVars(key);
    if (confVars != null) {
      if (!confVars.isType(value)) {
        StringBuilder message=new StringBuilder();
        message.append("'SET ").append(varname).append('=').append(varvalue);
        message.append("' FAILED because ").append(key).append(" expects ");
        message.append(confVars.typeString()).append(" type value.");
        throw new IllegalArgumentException(message.toString());
      }
      String fail=confVars.validate(value);
      if (fail != null) {
        StringBuilder message=new StringBuilder();
        message.append("'SET ").append(varname).append('=').append(varvalue);
        message.append("' FAILED in validation : ").append(fail).append('.');
        throw new IllegalArgumentException(message.toString());
      }
    }
 else     if (key.startsWith("hive.")) {
      throw new IllegalArgumentException("hive configuration " + key + " does not exists.");
    }
  }
  conf.verifyAndSet(key,value);
  if (HiveConf.ConfVars.HIVE_EXECUTION_ENGINE.varname.equals(key) && !"spark".equals(value)) {
    SessionState.get().closeSparkSession();
  }
  if (register) {
    SessionState.get().getOverriddenConfigurations().put(key,value);
  }
}
