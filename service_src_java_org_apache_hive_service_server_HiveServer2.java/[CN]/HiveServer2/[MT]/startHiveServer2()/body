{
  long attempts=0, maxAttempts=1;
  while (true) {
    LOG.info("Starting HiveServer2");
    HiveConf hiveConf=new HiveConf();
    maxAttempts=hiveConf.getLongVar(HiveConf.ConfVars.HIVE_SERVER2_MAX_START_ATTEMPTS);
    HiveServer2 server=null;
    try {
      server=new HiveServer2();
      server.init(hiveConf);
      server.start();
      ShimLoader.getHadoopShims().startPauseMonitor(hiveConf);
      if (hiveConf.getBoolVar(ConfVars.HIVE_SERVER2_SUPPORT_DYNAMIC_SERVICE_DISCOVERY)) {
        server.addServerInstanceToZooKeeper(hiveConf);
      }
      if (hiveConf.getBoolVar(ConfVars.HIVE_SERVER2_TEZ_INITIALIZE_DEFAULT_SESSIONS)) {
        TezSessionPoolManager sessionPool=TezSessionPoolManager.getInstance();
        sessionPool.setupPool(hiveConf);
        sessionPool.startPool();
      }
      if (hiveConf.getVar(ConfVars.HIVE_EXECUTION_ENGINE).equals("spark")) {
        SparkSessionManagerImpl.getInstance().setup(hiveConf);
      }
      break;
    }
 catch (    Throwable throwable) {
      if (server != null) {
        try {
          server.stop();
        }
 catch (        Throwable t) {
          LOG.info("Exception caught when calling stop of HiveServer2 before retrying start",t);
        }
 finally {
          server=null;
        }
      }
      if (++attempts >= maxAttempts) {
        throw new Error("Max start attempts " + maxAttempts + " exhausted",throwable);
      }
 else {
        LOG.warn("Error starting HiveServer2 on attempt " + attempts + ", will retry in 60 seconds",throwable);
        try {
          Thread.sleep(60L * 1000L);
        }
 catch (        InterruptedException e) {
          Thread.currentThread().interrupt();
        }
      }
    }
  }
}
