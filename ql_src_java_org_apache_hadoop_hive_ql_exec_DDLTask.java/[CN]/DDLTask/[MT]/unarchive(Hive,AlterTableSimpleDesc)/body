{
  String dbName=simpleDesc.getDbName();
  String tblName=simpleDesc.getTableName();
  Table tbl=db.getTable(dbName,tblName);
  if (simpleDesc.getPartSpec() == null) {
    throw new HiveException("UNARCHIVE is for partitions only");
  }
  if (tbl.getTableType() != TableType.MANAGED_TABLE) {
    throw new HiveException("UNARCHIVE can only be performed on managed tables");
  }
  Map<String,String> partSpec=simpleDesc.getPartSpec();
  PartSpecInfo partSpecInfo=PartSpecInfo.create(tbl,partSpec);
  List<Partition> partitions=db.getPartitions(tbl,partSpec);
  int partSpecLevel=partSpec.size();
  Path originalDir=null;
  if (partitions.isEmpty()) {
    throw new HiveException("No partition matches the specification");
  }
 else   if (partSpecInfo.values.size() != tbl.getPartCols().size()) {
    for (    Partition p : partitions) {
      if (partitionInCustomLocation(tbl,p)) {
        String message=String.format("UNARCHIVE cannot run for partition " + "groups with custom locations like %s",p.getLocation());
        throw new HiveException(message);
      }
    }
    originalDir=partSpecInfo.createPath(tbl);
  }
 else {
    Partition p=partitions.get(0);
    if (ArchiveUtils.isArchived(p)) {
      originalDir=new Path(getOriginalLocation(p));
    }
 else {
      originalDir=new Path(p.getLocation());
    }
  }
  URI originalUri=ArchiveUtils.addSlash(originalDir.toUri());
  Path intermediateArchivedDir=new Path(originalDir.getParent(),originalDir.getName() + INTERMEDIATE_ARCHIVED_DIR_SUFFIX);
  Path intermediateExtractedDir=new Path(originalDir.getParent(),originalDir.getName() + INTERMEDIATE_EXTRACTED_DIR_SUFFIX);
  boolean recovery=false;
  if (pathExists(intermediateArchivedDir) || pathExists(intermediateExtractedDir)) {
    recovery=true;
    console.printInfo("Starting recovery after failed UNARCHIVE");
  }
  for (  Partition p : partitions) {
    checkArchiveProperty(partSpecLevel,recovery,p);
  }
  String archiveName="data.har";
  FileSystem fs=null;
  try {
    fs=originalDir.getFileSystem(conf);
  }
 catch (  IOException e) {
    throw new HiveException(e);
  }
  Path archivePath=new Path(originalDir,archiveName);
  URI archiveUri=archivePath.toUri();
  ArchiveUtils.HarPathHelper harHelper=new ArchiveUtils.HarPathHelper(conf,archiveUri,originalUri);
  HadoopShims shim=ShimLoader.getHadoopShims();
  URI sourceUri=harHelper.getHarUri(originalUri,shim);
  Path sourceDir=new Path(sourceUri.getScheme(),sourceUri.getAuthority(),sourceUri.getPath());
  if (!pathExists(intermediateArchivedDir) && !pathExists(archivePath)) {
    throw new HiveException("Haven't found any archive where it should be");
  }
  Path tmpPath=new Path(driverContext.getCtx().getExternalTmpFileURI(originalDir.toUri()));
  try {
    fs=tmpPath.getFileSystem(conf);
  }
 catch (  IOException e) {
    throw new HiveException(e);
  }
  if (originalDir == null) {
    throw new HiveException("Missing archive data in the partition");
  }
  if (!pathExists(intermediateExtractedDir) && !pathExists(intermediateArchivedDir)) {
    try {
      String copySource=sourceDir.toString();
      String copyDest=tmpPath.toString();
      List<String> args=new ArrayList<String>();
      args.add("-cp");
      args.add(copySource);
      args.add(copyDest);
      console.printInfo("Copying " + copySource + " to "+ copyDest);
      FileSystem srcFs=FileSystem.get(sourceDir.toUri(),conf);
      srcFs.initialize(sourceDir.toUri(),conf);
      FsShell fss=new FsShell(conf);
      int ret=0;
      try {
        ret=ToolRunner.run(fss,args.toArray(new String[0]));
      }
 catch (      Exception e) {
        e.printStackTrace();
        throw new HiveException(e);
      }
      if (ret != 0) {
        throw new HiveException("Error while copying files from archive, return code=" + ret);
      }
 else {
        console.printInfo("Succefully Copied " + copySource + " to "+ copyDest);
      }
      console.printInfo("Moving " + tmpPath + " to "+ intermediateExtractedDir);
      if (fs.exists(intermediateExtractedDir)) {
        throw new HiveException("Invalid state: the intermediate extracted " + "directory already exists.");
      }
      fs.rename(tmpPath,intermediateExtractedDir);
    }
 catch (    Exception e) {
      throw new HiveException(e);
    }
  }
  if (!pathExists(intermediateArchivedDir)) {
    try {
      console.printInfo("Moving " + originalDir + " to "+ intermediateArchivedDir);
      fs.rename(originalDir,intermediateArchivedDir);
    }
 catch (    IOException e) {
      throw new HiveException(e);
    }
  }
 else {
    console.printInfo(intermediateArchivedDir + " already exists. " + "Assuming it contains the archived version of the partition");
  }
  if (!pathExists(originalDir)) {
    try {
      console.printInfo("Moving " + intermediateExtractedDir + " to "+ originalDir);
      fs.rename(intermediateExtractedDir,originalDir);
    }
 catch (    IOException e) {
      throw new HiveException(e);
    }
  }
 else {
    console.printInfo(originalDir + " already exists. " + "Assuming it contains the extracted files in the partition");
  }
  for (  Partition p : partitions) {
    setUnArchived(p);
    try {
      db.alterPartition(tblName,p);
    }
 catch (    InvalidOperationException e) {
      throw new HiveException(e);
    }
  }
  if (pathExists(intermediateArchivedDir)) {
    deleteDir(intermediateArchivedDir);
  }
  if (recovery) {
    console.printInfo("Recovery after UNARCHIVE succeeded");
  }
  return 0;
}
