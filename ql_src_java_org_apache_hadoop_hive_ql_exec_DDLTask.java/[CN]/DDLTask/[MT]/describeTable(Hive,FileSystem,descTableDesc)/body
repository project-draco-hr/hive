{
  String colPath=descTbl.getTableName();
  String tableName=colPath.substring(0,colPath.indexOf('.') == -1 ? colPath.length() : colPath.indexOf('.'));
  Table tbl=db.getTable(MetaStoreUtils.DEFAULT_DATABASE_NAME,tableName,false);
  Partition part=null;
  try {
    if (tbl == null) {
      DataOutput outStream=(DataOutput)fs.open(descTbl.getResFile());
      String errMsg="Table " + tableName + " does not exist";
      outStream.write(errMsg.getBytes("UTF-8"));
      ((FSDataOutputStream)outStream).close();
      return 0;
    }
    if (descTbl.getPartSpec() != null) {
      part=db.getPartition(tbl,descTbl.getPartSpec(),false);
      if (part == null) {
        DataOutput outStream=(DataOutput)fs.open(descTbl.getResFile());
        String errMsg="Partition " + descTbl.getPartSpec() + " for table "+ tableName+ " does not exist";
        outStream.write(errMsg.getBytes("UTF-8"));
        ((FSDataOutputStream)outStream).close();
        return 0;
      }
      tbl=part.getTable();
    }
  }
 catch (  FileNotFoundException e) {
    LOG.info("describe table: " + StringUtils.stringifyException(e));
    return 1;
  }
catch (  IOException e) {
    LOG.info("describe table: " + StringUtils.stringifyException(e));
    return 1;
  }
  try {
    LOG.info("DDLTask: got data for " + tbl.getName());
    List<FieldSchema> cols=null;
    if (colPath.equals(tableName)) {
      cols=tbl.getCols();
      if (part != null) {
        cols=part.getTPartition().getSd().getCols();
      }
    }
 else {
      cols=Hive.getFieldsFromDeserializer(colPath,tbl.getDeserializer());
    }
    DataOutput outStream=(DataOutput)fs.create(descTbl.getResFile());
    Iterator<FieldSchema> iterCols=cols.iterator();
    while (iterCols.hasNext()) {
      FieldSchema col=iterCols.next();
      outStream.writeBytes(col.getName());
      outStream.write(separator);
      outStream.writeBytes(col.getType());
      outStream.write(separator);
      outStream.writeBytes(col.getComment() == null ? "" : col.getComment());
      outStream.write(terminator);
    }
    if (tableName.equals(colPath)) {
      List<FieldSchema> partCols=tbl.getPartCols();
      Iterator<FieldSchema> iterPartCols=partCols.iterator();
      while (iterPartCols.hasNext()) {
        FieldSchema col=iterPartCols.next();
        outStream.writeBytes(col.getName());
        outStream.write(separator);
        outStream.writeBytes(col.getType());
        outStream.write(separator);
        outStream.writeBytes(col.getComment() == null ? "" : col.getComment());
        outStream.write(terminator);
      }
      if (descTbl.isExt()) {
        outStream.write(terminator);
        if (part != null) {
          outStream.writeBytes("Detailed Partition Information");
          outStream.write(separator);
          outStream.writeBytes(part.getTPartition().toString());
          outStream.write(separator);
          outStream.write(terminator);
        }
 else {
          outStream.writeBytes("Detailed Table Information");
          outStream.write(separator);
          outStream.writeBytes(tbl.getTTable().toString());
          outStream.write(separator);
          outStream.write(terminator);
        }
      }
    }
    LOG.info("DDLTask: written data for " + tbl.getName());
    ((FSDataOutputStream)outStream).close();
  }
 catch (  FileNotFoundException e) {
    LOG.info("describe table: " + StringUtils.stringifyException(e));
    return 1;
  }
catch (  IOException e) {
    LOG.info("describe table: " + StringUtils.stringifyException(e));
    return 1;
  }
catch (  Exception e) {
    throw new HiveException(e.toString());
  }
  return 0;
}
