{
  statsMap.put(Counter.DESERIALIZE_ERRORS,deserialize_error_count);
  statsMap.put(Counter.SERIALIZE_ERRORS,serialize_error_count);
  try {
    this.hconf=hconf;
    scriptOutputDeserializer=conf.getScriptOutputInfo().getDeserializerClass().newInstance();
    scriptOutputDeserializer.initialize(hconf,conf.getScriptOutputInfo().getProperties());
    scriptInputSerializer=(Serializer)conf.getScriptInputInfo().getDeserializerClass().newInstance();
    scriptInputSerializer.initialize(hconf,conf.getScriptInputInfo().getProperties());
    outputObjInspector=scriptOutputDeserializer.getObjectInspector();
    String[] cmdArgs=splitArgs(conf.getScriptCmd());
    String prog=cmdArgs[0];
    File currentDir=new File(".").getAbsoluteFile();
    if (!new File(prog).isAbsolute()) {
      PathFinder finder=new PathFinder("PATH");
      finder.prependPathComponent(currentDir.toString());
      File f=finder.getAbsolutePath(prog);
      if (f != null) {
        cmdArgs[0]=f.getAbsolutePath();
      }
      f=null;
    }
    String[] wrappedCmdArgs=addWrapper(cmdArgs);
    LOG.info("Executing " + Arrays.asList(wrappedCmdArgs));
    LOG.info("tablename=" + hconf.get(HiveConf.ConfVars.HIVETABLENAME.varname));
    LOG.info("partname=" + hconf.get(HiveConf.ConfVars.HIVEPARTITIONNAME.varname));
    LOG.info("alias=" + alias);
    ProcessBuilder pb=new ProcessBuilder(wrappedCmdArgs);
    Map<String,String> env=pb.environment();
    addJobConfToEnvironment(hconf,env);
    env.put(safeEnvVarName(HiveConf.ConfVars.HIVEALIAS.varname),String.valueOf(alias));
    scriptPid=pb.start();
    scriptOut=new DataOutputStream(new BufferedOutputStream(scriptPid.getOutputStream()));
    scriptIn=new DataInputStream(new BufferedInputStream(scriptPid.getInputStream()));
    scriptErr=new DataInputStream(new BufferedInputStream(scriptPid.getErrorStream()));
    outThread=new StreamThread(scriptIn,new OutputStreamProcessor(scriptOutputDeserializer.getObjectInspector()),"OutputProcessor");
    errThread=new StreamThread(scriptErr,new ErrorStreamProcessor(HiveConf.getIntVar(hconf,HiveConf.ConfVars.SCRIPTERRORLIMIT)),"ErrorProcessor");
    Integer exp_interval=null;
    int exp_int;
    exp_interval=Integer.decode(hconf.get("mapred.tasktracker.expiry.interval"));
    if (exp_interval != null)     exp_int=exp_interval.intValue() / 2;
 else     exp_int=300000;
    rpTimer=new Timer(true);
    rpTimer.scheduleAtFixedRate(new ReporterTask(reporter),0,exp_interval);
    initializeChildren(hconf);
    outThread.start();
    errThread.start();
  }
 catch (  Exception e) {
    throw new HiveException("Cannot initialize ScriptOperator",e);
  }
}
