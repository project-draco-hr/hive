{
  batch.reset();
  VectorizedBatchUtil.addRowToBatchFrom(keyObject,keyStructInspector,0,0,batch,buffer);
  for (int i=0; i < keysColumnOffset; i++) {
    VectorizedBatchUtil.setRepeatingColumn(batch,i);
  }
  int rowIdx=0;
  try {
    for (    Object value : values) {
      BytesWritable valueWritable=(BytesWritable)value;
      Object valueObj=deserializeValue(valueWritable,tag);
      VectorizedBatchUtil.addRowToBatchFrom(valueObj,valueStructInspectors,rowIdx,keysColumnOffset,batch,buffer);
      rowIdx++;
      if (rowIdx >= BATCH_SIZE) {
        VectorizedBatchUtil.setBatchSize(batch,rowIdx);
        reducer.processOp(batch,tag);
        rowIdx=0;
      }
    }
    if (rowIdx > 0) {
      VectorizedBatchUtil.setBatchSize(batch,rowIdx);
      reducer.processOp(batch,tag);
    }
  }
 catch (  Exception e) {
    String rowString=null;
    try {
      batch.setValueWriters(valueStringWriters.toArray(new VectorExpressionWriter[0]));
      rowString=batch.toString();
    }
 catch (    Exception e2) {
      rowString="[Error getting row data with exception " + StringUtils.stringifyException(e2) + " ]";
    }
    throw new HiveException("Hive Runtime Error while processing vector batch (tag=" + tag + ") "+ rowString,e);
  }
}
