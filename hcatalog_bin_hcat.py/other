import os
import sys
import glob
import subprocess
this = os.path.realpath(sys.argv[0])
bindir = (os.path.dirname(this) + os.path.sep)
sys.path.append(os.path.join(bindir, os.path.pardir, 'libexec'))
import hcatcfg
hcatcfg.findCfgFile()
hcatcfg.findHadoop()
debug = 0
try:
    sys.argv.remove('-secretDebugCmd')
    debug = 1
except ValueError:
    pass
dumpClasspath = 0
try:
    sys.argv.remove('-classpath')
    dumpClasspath = 1
except ValueError:
    pass
hcatcfg.findHive()
if ('HIVE_HOME' not in os.environ):
    sys.exit('Hive not found.  Set HIVE_HOME to directory containing Hive.')
if ('HIVE_LIB_DIR' not in os.environ):
    sys.exit(('Cannot find lib dir within HIVE_HOME %s' % ((os.environ['HIVE_HOME'] + os.path.sep) + 'lib')))
if ('HIVE_CONF_DIR' not in os.environ):
    sys.exit(('Cannot find conf dir within HIVE_HOME %s' % ((os.environ['HIVE_HOME'] + os.path.sep) + 'conf')))
hcatPrefix = hcatcfg.findHCatPrefix(bindir)
hcatJars = glob.glob(os.path.join(hcatPrefix, 'share', 'hcatalog', 'hive-hcatalog-core-*.jar'))
if (len(hcatJars) > 1):
    sys.exit('Found more than one hcatalog jar in the prefix path')
if (len(hcatJars) < 1):
    sys.exit(('HCatalog jar not found in directory %s' % os.path.join(hcatPrefix, 'share', 'hcatalog', 'hive-hcatalog-core-*.jar')))
if ('HADOOP_CLASSPATH' not in os.environ):
    os.putenv('HADOOP_CLASSPATH', '')
    os.environ['HADOOP_CLASSPATH'] = ''
os.environ['HADOOP_CLASSPATH'] += (os.pathsep + hcatJars[0])
hbaseStorageJars = glob.glob(os.path.join(hcatPrefix, 'share', 'hcatalog', 'storage-handlers', 'hbase', 'lib', 'hbase-storage-handler-*.jar'))
if (len(hbaseStorageJars) == 1):
    os.environ['HADOOP_CLASSPATH'] += (os.pathsep + hbaseStorageJars[0])
hcatLibJarFiles = os.path.join(hcatPrefix, 'share', 'hcatalog', 'lib', '*')
os.environ['HADOOP_CLASSPATH'] += (os.pathsep + hcatLibJarFiles)
hiveJars = os.path.join(os.environ['HIVE_LIB_DIR'], '*')
os.environ['HADOOP_CLASSPATH'] += (os.pathsep + hiveJars)
os.environ['HADOOP_CLASSPATH'] += (os.pathsep + os.environ['HIVE_CONF_DIR'])
try:
    if (os.environ['HBASE_CONF_DIR'] != ''):
        os.environ['HADOOP_CLASSPATH'] += (os.pathsep + os.environ['HBASE_CONF_DIR'])
except:
    pass
sys.stdout.flush()
if (os.name == 'posix'):
    hadoopcmd = 'hadoop'
else:
    hadoopcmd = 'hadoop.cmd'
if ('HADOOP_OPTS' not in os.environ):
    os.environ['HADOOP_OPTS'] = ''
os.environ['HADOOP_OPTS'] += ((((' ' + '-Dhive.log.file=hcat.log') + ' ') + '-Dhive.log.dir=') + os.path.join(os.environ['HIVE_HOME'], 'logs'))
cmdLine = os.path.join(os.environ['HADOOP_PREFIX'], 'bin', hadoopcmd)
if (os.name == 'posix'):
    cmd = ([cmdLine, 'jar', hcatJars[0], 'org.apache.hive.hcatalog.cli.HCatCli'] + sys.argv[1:len(sys.argv)])
else:
    cmd = (['call', cmdLine, 'jar', hcatJars[0], 'org.apache.hive.hcatalog.cli.HCatCli'] + sys.argv[1:len(sys.argv)])
if (debug == 1):
    print 'Would run:'
    print ('exec ' + str(cmd))
    print (' with HADOOP_CLASSPATH set to %s' % os.environ['HADOOP_CLASSPATH'])
    try:
        print (' and HADOOP_OPTS set to %s' % os.environ['HADOOP_OPTS'])
    except:
        pass
elif (dumpClasspath == 1):
    print os.environ['HADOOP_CLASSPATH']
else:
    if (os.name == 'posix'):
        retval = subprocess.call(cmd)
    else:
        retval = subprocess.call(cmd, stdin=None, stdout=None, stderr=None, shell=True)
    os.environ['errorlevel'] = str(retval)
    sys.exit(retval)
