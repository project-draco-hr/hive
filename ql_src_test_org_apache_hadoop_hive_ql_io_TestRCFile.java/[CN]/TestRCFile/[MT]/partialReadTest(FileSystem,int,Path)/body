{
  LOG.debug("reading " + count + " records");
  long start=System.currentTimeMillis();
  java.util.ArrayList<Integer> readCols=new java.util.ArrayList<Integer>();
  readCols.add(Integer.valueOf(2));
  readCols.add(Integer.valueOf(3));
  HiveFileFormatUtils.setReadColumnIDs(conf,readCols);
  RCFile.Reader reader=new RCFile.Reader(fs,file,conf);
  LongWritable rowID=new LongWritable();
  BytesRefArrayWritable cols=new BytesRefArrayWritable();
  while (reader.next(rowID)) {
    reader.getCurrentRow(cols);
    Object row=serDe.deserialize(cols);
    StructObjectInspector oi=(StructObjectInspector)serDe.getObjectInspector();
    List<? extends StructField> fieldRefs=oi.getAllStructFieldRefs();
    assertEquals("Field size should be 8",8,fieldRefs.size());
    for (    int i : readCols) {
      Object fieldData=oi.getStructFieldData(row,fieldRefs.get(i));
      Object standardWritableData=ObjectInspectorUtils.copyToStandardObject(fieldData,fieldRefs.get(i).getFieldObjectInspector(),ObjectInspectorCopyOption.WRITABLE);
      assertEquals("Field " + i,standardWritableData,expectedPartitalFieldsData[i]);
    }
    assertEquals("Class of the serialized object should be BytesRefArrayWritable",BytesRefArrayWritable.class,serDe.getSerializedClass());
    BytesRefArrayWritable serializedBytes=(BytesRefArrayWritable)serDe.serialize(row,oi);
    assertEquals("Serialized data",patialS,serializedBytes);
  }
  reader.close();
  long cost=System.currentTimeMillis() - start;
  LOG.debug("reading fully costs:" + cost + " milliseconds");
}
