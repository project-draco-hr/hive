{
  cleanup();
  byte[][] record={null,null,null,null,null,null,null,null};
  RCFileOutputFormat.setColumnNumber(conf,expectedFieldsData.length);
  RCFile.Writer writer=new RCFile.Writer(fs,conf,file,null,new DefaultCodec());
  BytesRefArrayWritable bytes=new BytesRefArrayWritable(record.length);
  final int recCount=100;
  Random rand=new Random();
  for (int recIdx=0; recIdx < recCount; recIdx++) {
    for (int i=0; i < record.length; i++) {
      record[i]=new Integer(rand.nextInt()).toString().getBytes("UTF-8");
    }
    for (int i=0; i < record.length; i++) {
      BytesRefWritable cu=new BytesRefWritable(record[i],0,record[i].length);
      bytes.set(i,cu);
    }
    writer.append(bytes);
    bytes.clear();
  }
  writer.close();
  RandomAccessFile raf=new RandomAccessFile(file.toUri().getPath(),"rw");
  long corruptOffset=raf.length() / 2;
  LOG.info("corrupting " + raf + " at offset "+ corruptOffset);
  raf.seek(corruptOffset);
  raf.writeBytes("junkjunkjunkjunkjunkjunkjunkjunk");
  raf.close();
  Configuration tmpConf=new Configuration(conf);
  tmpConf.setBoolean("hive.io.rcfile.tolerate.corruptions",true);
  RCFile.Reader reader=new RCFile.Reader(fs,file,tmpConf);
  LongWritable rowID=new LongWritable();
  while (true) {
    boolean more=reader.next(rowID);
    if (!more) {
      break;
    }
    BytesRefArrayWritable cols=new BytesRefArrayWritable();
    reader.getCurrentRow(cols);
    cols.resetValid(8);
  }
  reader.close();
}
