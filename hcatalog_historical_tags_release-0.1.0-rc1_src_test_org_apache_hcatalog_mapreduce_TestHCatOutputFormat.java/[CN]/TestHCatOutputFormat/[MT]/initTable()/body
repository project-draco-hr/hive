{
  try {
    client.dropTable(dbName,tblName);
  }
 catch (  Exception e) {
  }
  try {
    client.dropDatabase(dbName);
  }
 catch (  Exception e) {
  }
  client.createDatabase(new Database(dbName,"",null,null));
  assertNotNull((client.getDatabase(dbName).getLocationUri()));
  List<FieldSchema> fields=new ArrayList<FieldSchema>();
  fields.add(new FieldSchema("colname",Constants.STRING_TYPE_NAME,""));
  Table tbl=new Table();
  tbl.setDbName(dbName);
  tbl.setTableName(tblName);
  StorageDescriptor sd=new StorageDescriptor();
  sd.setCols(fields);
  tbl.setSd(sd);
  sd.setParameters(new HashMap<String,String>());
  sd.getParameters().put("test_param_1","Use this for comments etc");
  sd.setBucketCols(new ArrayList<String>(2));
  sd.getBucketCols().add("name");
  sd.setSerdeInfo(new SerDeInfo());
  sd.getSerdeInfo().setName(tbl.getTableName());
  sd.getSerdeInfo().setParameters(new HashMap<String,String>());
  sd.getSerdeInfo().getParameters().put(org.apache.hadoop.hive.serde.Constants.SERIALIZATION_FORMAT,"1");
  sd.getSerdeInfo().setSerializationLib(org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe.class.getName());
  tbl.setPartitionKeys(fields);
  Map<String,String> tableParams=new HashMap<String,String>();
  tableParams.put(HCatConstants.HCAT_OSD_CLASS,RCFileOutputDriver.class.getName());
  tableParams.put(HCatConstants.HCAT_ISD_CLASS,"testInputClass");
  tableParams.put("hcat.testarg","testArgValue");
  tbl.setParameters(tableParams);
  client.createTable(tbl);
  Path tblPath=new Path(client.getTable(dbName,tblName).getSd().getLocation());
  assertTrue(tblPath.getFileSystem(hiveConf).mkdirs(new Path(tblPath,"colname=p1")));
}
