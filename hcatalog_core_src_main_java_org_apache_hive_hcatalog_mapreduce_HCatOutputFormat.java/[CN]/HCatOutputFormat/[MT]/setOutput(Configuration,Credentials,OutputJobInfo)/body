{
  HiveMetaStoreClient client=null;
  try {
    HiveConf hiveConf=HCatUtil.getHiveConf(conf);
    client=HCatUtil.getHiveClient(hiveConf);
    Table table=HCatUtil.getTable(client,outputJobInfo.getDatabaseName(),outputJobInfo.getTableName());
    List<String> indexList=client.listIndexNames(outputJobInfo.getDatabaseName(),outputJobInfo.getTableName(),Short.MAX_VALUE);
    for (    String indexName : indexList) {
      Index index=client.getIndex(outputJobInfo.getDatabaseName(),outputJobInfo.getTableName(),indexName);
      if (!index.isDeferredRebuild()) {
        throw new HCatException(ErrorType.ERROR_NOT_SUPPORTED,"Store into a table with an automatic index from Pig/Mapreduce is not supported");
      }
    }
    StorageDescriptor sd=table.getTTable().getSd();
    if (sd.isCompressed()) {
      throw new HCatException(ErrorType.ERROR_NOT_SUPPORTED,"Store into a compressed partition from Pig/Mapreduce is not supported");
    }
    if (sd.getBucketCols() != null && !sd.getBucketCols().isEmpty()) {
      throw new HCatException(ErrorType.ERROR_NOT_SUPPORTED,"Store into a partition with bucket definition from Pig/Mapreduce is not supported");
    }
    if (sd.getSortCols() != null && !sd.getSortCols().isEmpty()) {
      throw new HCatException(ErrorType.ERROR_NOT_SUPPORTED,"Store into a partition with sorted column definition from Pig/Mapreduce is not supported");
    }
    if (table.getTTable().getPartitionKeysSize() == 0) {
      if ((outputJobInfo.getPartitionValues() != null) && (!outputJobInfo.getPartitionValues().isEmpty())) {
        throw new HCatException(ErrorType.ERROR_INVALID_PARTITION_VALUES,"Partition values specified for non-partitioned table");
      }
      outputJobInfo.setPartitionValues(new HashMap<String,String>());
    }
 else {
      Map<String,String> valueMap=new HashMap<String,String>();
      if (outputJobInfo.getPartitionValues() != null) {
        for (        Map.Entry<String,String> entry : outputJobInfo.getPartitionValues().entrySet()) {
          valueMap.put(entry.getKey().toLowerCase(),entry.getValue());
        }
      }
      if ((outputJobInfo.getPartitionValues() == null) || (outputJobInfo.getPartitionValues().size() < table.getTTable().getPartitionKeysSize())) {
        List<String> dynamicPartitioningKeys=new ArrayList<String>();
        boolean firstItem=true;
        for (        FieldSchema fs : table.getPartitionKeys()) {
          if (!valueMap.containsKey(fs.getName().toLowerCase())) {
            dynamicPartitioningKeys.add(fs.getName().toLowerCase());
          }
        }
        if (valueMap.size() + dynamicPartitioningKeys.size() != table.getTTable().getPartitionKeysSize()) {
          throw new HCatException(ErrorType.ERROR_INVALID_PARTITION_VALUES,"Invalid partition keys specified");
        }
        outputJobInfo.setDynamicPartitioningKeys(dynamicPartitioningKeys);
        String dynHash;
        if ((dynHash=conf.get(HCatConstants.HCAT_DYNAMIC_PTN_JOBID)) == null) {
          dynHash=String.valueOf(Math.random());
        }
        conf.set(HCatConstants.HCAT_DYNAMIC_PTN_JOBID,dynHash);
        String customPattern=conf.get(HCatConstants.HCAT_DYNAMIC_CUSTOM_PATTERN);
        if (customPattern != null) {
          HCatFileUtil.setCustomPath(customPattern,outputJobInfo);
        }
      }
      outputJobInfo.setPartitionValues(valueMap);
    }
    conf.set("dfs.client.read.shortcircuit","false");
    HCatSchema tableSchema=HCatUtil.extractSchema(table);
    StorerInfo storerInfo=InternalUtil.extractStorerInfo(table.getTTable().getSd(),table.getParameters());
    List<String> partitionCols=new ArrayList<String>();
    for (    FieldSchema schema : table.getPartitionKeys()) {
      partitionCols.add(schema.getName());
    }
    HiveStorageHandler storageHandler=HCatUtil.getStorageHandler(conf,storerInfo);
    outputJobInfo.setTableInfo(HCatTableInfo.valueOf(table.getTTable()));
    outputJobInfo.setOutputSchema(tableSchema);
    harRequested=getHarRequested(hiveConf);
    outputJobInfo.setHarRequested(harRequested);
    maxDynamicPartitions=getMaxDynamicPartitions(hiveConf);
    outputJobInfo.setMaximumDynamicPartitions(maxDynamicPartitions);
    HCatUtil.configureOutputStorageHandler(storageHandler,conf,outputJobInfo);
    Path tblPath=new Path(table.getTTable().getSd().getLocation());
    FsPermission.setUMask(conf,FsPermission.getDefault().applyUMask(tblPath.getFileSystem(conf).getFileStatus(tblPath).getPermission()));
    if (Security.getInstance().isSecurityEnabled()) {
      Security.getInstance().handleSecurity(credentials,outputJobInfo,client,conf,harRequested);
    }
  }
 catch (  Exception e) {
    if (e instanceof HCatException) {
      throw (HCatException)e;
    }
 else {
      throw new HCatException(ErrorType.ERROR_SET_OUTPUT,e);
    }
  }
 finally {
    HCatUtil.closeHiveClientQuietly(client);
  }
}
