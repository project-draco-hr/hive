{
  try {
    String tableName="table_for_testtable";
    try {
      hm.dropTable(MetaStoreUtils.DEFAULT_DATABASE_NAME,tableName);
    }
 catch (    HiveException e1) {
      e1.printStackTrace();
      assertTrue("Unable to drop table",false);
    }
    Table tbl=new Table(MetaStoreUtils.DEFAULT_DATABASE_NAME,tableName);
    List<FieldSchema> fields=tbl.getCols();
    fields.add(new FieldSchema("col1",Constants.INT_TYPE_NAME,"int -- first column"));
    fields.add(new FieldSchema("col2",Constants.STRING_TYPE_NAME,"string -- second column"));
    fields.add(new FieldSchema("col3",Constants.DOUBLE_TYPE_NAME,"double -- thrift column"));
    tbl.setFields(fields);
    tbl.setOutputFormatClass(HiveIgnoreKeyTextOutputFormat.class);
    tbl.setInputFormatClass(SequenceFileInputFormat.class);
    tbl.setProperty("comment","this is a test table created as part junit tests");
    List<String> bucketCols=tbl.getBucketCols();
    bucketCols.add("col1");
    try {
      tbl.setBucketCols(bucketCols);
    }
 catch (    HiveException e) {
      e.printStackTrace();
      assertTrue("Unable to set bucket column for table: " + tableName,false);
    }
    List<FieldSchema> partCols=new ArrayList<FieldSchema>();
    partCols.add(new FieldSchema("ds",Constants.STRING_TYPE_NAME,"partition column, date but in string format as date type is not yet supported in QL"));
    tbl.setPartCols(partCols);
    tbl.setNumBuckets((short)512);
    tbl.setOwner("pchakka");
    tbl.setRetention(10);
    tbl.setSerdeParam(Constants.FIELD_DELIM,"1");
    tbl.setSerdeParam(Constants.LINE_DELIM,"\n");
    tbl.setSerdeParam(Constants.MAPKEY_DELIM,"3");
    tbl.setSerdeParam(Constants.COLLECTION_DELIM,"2");
    tbl.setSerdeParam(Constants.FIELD_DELIM,"1");
    tbl.setSerializationLib(LazySimpleSerDe.class.getName());
    tbl.getTTable().getSd().setPrimaryRegionName(HiveConf.ConfVars.HIVE_DEFAULT_REGION_NAME.defaultVal);
    tbl.getTTable().getSd().setSecondaryRegions(new ArrayList<RegionStorageDescriptor>());
    try {
      hm.createTable(tbl);
    }
 catch (    HiveException e) {
      e.printStackTrace();
      assertTrue("Unable to create table: " + tableName,false);
    }
    Table ft=null;
    Warehouse wh=new Warehouse(hiveConf);
    try {
      ft=hm.getTable(MetaStoreUtils.DEFAULT_DATABASE_NAME,tableName);
      ft.checkValidity();
      assertEquals("Table names didn't match for table: " + tableName,tbl.getTableName(),ft.getTableName());
      assertEquals("Table owners didn't match for table: " + tableName,tbl.getOwner(),ft.getOwner());
      assertEquals("Table retention didn't match for table: " + tableName,tbl.getRetention(),ft.getRetention());
      assertEquals("Data location is not set correctly",wh.getTablePath(hm.getDatabase(DEFAULT_DATABASE_NAME),tableName).toString(),ft.getDataLocation().toString());
      tbl.setDataLocation(ft.getDataLocation());
      assertTrue("Tables doesn't match: " + tableName,ft.getTTable().equals(tbl.getTTable()));
      assertEquals("Serde is not set correctly",tbl.getDeserializer().getClass().getName(),ft.getDeserializer().getClass().getName());
      assertEquals("SerializationLib is not set correctly",tbl.getSerializationLib(),LazySimpleSerDe.class.getName());
    }
 catch (    HiveException e) {
      e.printStackTrace();
      assertTrue("Unable to fetch table correctly: " + tableName,false);
    }
    try {
      hm.dropTable(MetaStoreUtils.DEFAULT_DATABASE_NAME,tableName,true,false);
      Table ft2=hm.getTable(MetaStoreUtils.DEFAULT_DATABASE_NAME,tableName,false);
      assertNull("Unable to drop table ",ft2);
    }
 catch (    HiveException e) {
      assertTrue("Unable to drop table: " + tableName,false);
    }
  }
 catch (  Throwable e) {
    System.err.println(StringUtils.stringifyException(e));
    System.err.println("testTable failed");
    throw e;
  }
}
