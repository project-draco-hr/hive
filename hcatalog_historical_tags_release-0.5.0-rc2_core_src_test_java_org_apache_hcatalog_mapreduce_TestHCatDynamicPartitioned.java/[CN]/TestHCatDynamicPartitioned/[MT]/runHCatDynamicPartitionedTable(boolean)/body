{
  generateWriteRecords(NUM_RECORDS,NUM_PARTITIONS,0);
  runMRCreate(null,dataColumns,writeRecords,NUM_RECORDS,true,asSingleMapTask);
  runMRRead(NUM_RECORDS);
  runMRRead(4,"p1 = \"0\"");
  runMRRead(8,"p1 = \"1\" or p1 = \"3\"");
  runMRRead(4,"p1 = \"4\"");
  String query="select * from " + tableName;
  int retCode=driver.run(query).getResponseCode();
  if (retCode != 0) {
    throw new Exception("Error " + retCode + " running query "+ query);
  }
  ArrayList<String> res=new ArrayList<String>();
  driver.getResults(res);
  assertEquals(NUM_RECORDS,res.size());
  IOException exc=null;
  try {
    generateWriteRecords(NUM_RECORDS,NUM_PARTITIONS,0);
    Job job=runMRCreate(null,dataColumns,writeRecords,NUM_RECORDS,false);
    if (HcatTestUtils.isHadoop23()) {
      new FileOutputCommitterContainer(job,null).cleanupJob(job);
    }
  }
 catch (  IOException e) {
    exc=e;
  }
  assertTrue(exc != null);
  assertTrue(exc instanceof HCatException);
  assertTrue("Got exception of type [" + ((HCatException)exc).getErrorType().toString() + "] Expected ERROR_PUBLISHING_PARTITION or ERROR_MOVE_FAILED",(ErrorType.ERROR_PUBLISHING_PARTITION == ((HCatException)exc).getErrorType()) || (ErrorType.ERROR_MOVE_FAILED == ((HCatException)exc).getErrorType()));
}
