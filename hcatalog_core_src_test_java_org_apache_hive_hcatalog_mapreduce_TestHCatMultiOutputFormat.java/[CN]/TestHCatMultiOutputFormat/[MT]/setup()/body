{
  System.clearProperty("mapred.job.tracker");
  String testDir=System.getProperty("test.tmp.dir","./");
  testDir=testDir + "/test_multitable_" + Math.abs(new Random().nextLong())+ "/";
  workDir=new File(new File(testDir).getCanonicalPath());
  FileUtil.fullyDelete(workDir);
  workDir.mkdirs();
  warehousedir=new Path(System.getProperty("test.warehouse.dir"));
  HiveConf metastoreConf=new HiveConf();
  metastoreConf.setVar(HiveConf.ConfVars.METASTOREWAREHOUSE,warehousedir.toString());
  msPort=MetaStoreUtils.startMetaStore(metastoreConf);
  Configuration conf=new Configuration(true);
  conf.set("yarn.scheduler.capacity.root.queues","default");
  conf.set("yarn.scheduler.capacity.root.default.capacity","100");
  FileSystem fs=FileSystem.get(conf);
  System.setProperty("hadoop.log.dir",new File(workDir,"/logs").getAbsolutePath());
  mrCluster=new MiniMRCluster(1,fs.getUri().toString(),1,null,null,new JobConf(conf));
  mrConf=mrCluster.createJobConf();
  initializeSetup();
  warehousedir.getFileSystem(conf).mkdirs(warehousedir);
}
