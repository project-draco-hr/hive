{
  Utilities.setMapWork(jobConf,work);
  try {
    boolean sendSerializedEvents=conf.getBoolean("mapreduce.tez.input.initializer.serialize.event.payload",true);
    if (pruner != null) {
      pruner.prune();
    }
    InputSplitInfoMem inputSplitInfo=null;
    boolean generateConsistentSplits=HiveConf.getBoolVar(conf,HiveConf.ConfVars.HIVE_TEZ_GENERATE_CONSISTENT_SPLITS);
    LOG.info("GenerateConsistentSplitsInHive=" + generateConsistentSplits);
    String realInputFormatName=conf.get("mapred.input.format.class");
    boolean groupingEnabled=userPayloadProto.getGroupingEnabled();
    if (groupingEnabled) {
      InputFormat<?,?> inputFormat=(InputFormat<?,?>)ReflectionUtils.newInstance(JavaUtils.loadClass(realInputFormatName),jobConf);
      int totalResource=0;
      int taskResource=0;
      int availableSlots=0;
      if (getContext() == null) {
        availableSlots=1;
      }
      if (getContext() != null) {
        totalResource=getContext().getTotalAvailableResource().getMemory();
        taskResource=getContext().getVertexTaskResource().getMemory();
        availableSlots=totalResource / taskResource;
      }
      if (HiveConf.getLongVar(conf,HiveConf.ConfVars.MAPREDMINSPLITSIZE,1) <= 1) {
        final long blockSize=conf.getLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,DFSConfigKeys.DFS_BLOCK_SIZE_DEFAULT);
        final long minGrouping=conf.getLong(TezMapReduceSplitsGrouper.TEZ_GROUPING_SPLIT_MIN_SIZE,TezMapReduceSplitsGrouper.TEZ_GROUPING_SPLIT_MIN_SIZE_DEFAULT);
        final long preferredSplitSize=Math.min(blockSize / 2,minGrouping);
        HiveConf.setLongVar(jobConf,HiveConf.ConfVars.MAPREDMINSPLITSIZE,preferredSplitSize);
        LOG.info("The preferred split size is " + preferredSplitSize);
      }
      float waves=conf.getFloat(TezMapReduceSplitsGrouper.TEZ_GROUPING_SPLIT_WAVES,TezMapReduceSplitsGrouper.TEZ_GROUPING_SPLIT_WAVES_DEFAULT);
      InputSplit[] splits=inputFormat.getSplits(jobConf,(int)(availableSlots * waves));
      Arrays.sort(splits,new InputSplitComparator());
      LOG.info("Number of input splits: " + splits.length + ". "+ availableSlots+ " available slots, "+ waves+ " waves. Input format is: "+ realInputFormatName);
      if (work.getIncludedBuckets() != null) {
        splits=pruneBuckets(work,splits);
      }
      Multimap<Integer,InputSplit> groupedSplits=splitGrouper.generateGroupedSplits(jobConf,conf,splits,waves,availableSlots,splitLocationProvider);
      InputSplit[] flatSplits=groupedSplits.values().toArray(new InputSplit[0]);
      LOG.info("Number of split groups: " + flatSplits.length);
      List<TaskLocationHint> locationHints=splitGrouper.createTaskLocationHints(flatSplits,generateConsistentSplits);
      inputSplitInfo=new InputSplitInfoMem(flatSplits,locationHints,flatSplits.length,null,jobConf);
    }
 else {
      throw new RuntimeException("HiveInputFormat does not support non-grouped splits, InputFormatName is: " + realInputFormatName);
    }
    return createEventList(sendSerializedEvents,inputSplitInfo);
  }
  finally {
    Utilities.clearWork(jobConf);
  }
}
