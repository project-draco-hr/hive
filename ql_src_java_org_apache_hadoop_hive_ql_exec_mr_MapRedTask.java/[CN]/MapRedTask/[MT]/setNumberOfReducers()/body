{
  ReduceWork rWork=work.getReduceWork();
  Integer numReducersFromWork=rWork == null ? 0 : rWork.getNumReduceTasks();
  if (rWork == null) {
    console.printInfo("Number of reduce tasks is set to 0 since there's no reduce operator");
  }
 else {
    if (numReducersFromWork >= 0) {
      console.printInfo("Number of reduce tasks determined at compile time: " + rWork.getNumReduceTasks());
    }
 else     if (job.getNumReduceTasks() > 0) {
      int reducers=job.getNumReduceTasks();
      rWork.setNumReduceTasks(reducers);
      console.printInfo("Number of reduce tasks not specified. Defaulting to jobconf value of: " + reducers);
    }
 else {
      if (inputSummary == null) {
        inputSummary=Utilities.getInputSummary(driverContext.getCtx(),work.getMapWork(),null);
      }
      int reducers=Utilities.estimateNumberOfReducers(conf,inputSummary,work.getMapWork(),work.isFinalMapRed());
      rWork.setNumReduceTasks(reducers);
      console.printInfo("Number of reduce tasks not specified. Estimated from input data size: " + reducers);
    }
    console.printInfo("In order to change the average load for a reducer (in bytes):");
    console.printInfo("  set " + HiveConf.ConfVars.BYTESPERREDUCER.varname + "=<number>");
    console.printInfo("In order to limit the maximum number of reducers:");
    console.printInfo("  set " + HiveConf.ConfVars.MAXREDUCERS.varname + "=<number>");
    console.printInfo("In order to set a constant number of reducers:");
    console.printInfo("  set " + HiveConf.ConfVars.HADOOPNUMREDUCERS + "=<number>");
  }
}
