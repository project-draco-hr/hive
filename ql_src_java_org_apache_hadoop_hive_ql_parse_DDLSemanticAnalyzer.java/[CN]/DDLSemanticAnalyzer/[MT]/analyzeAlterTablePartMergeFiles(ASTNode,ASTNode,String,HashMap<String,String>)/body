{
  AlterTablePartMergeFilesDesc mergeDesc=new AlterTablePartMergeFilesDesc(tableName,partSpec);
  List<String> inputDir=new ArrayList<String>();
  Path oldTblPartLoc=null;
  Path newTblPartLoc=null;
  Table tblObj=null;
  ListBucketingCtx lbCtx=null;
  try {
    tblObj=getTable(tableName);
    List<String> bucketCols=null;
    Class<? extends InputFormat> inputFormatClass=null;
    boolean isArchived=false;
    boolean checkIndex=HiveConf.getBoolVar(conf,HiveConf.ConfVars.HIVE_CONCATENATE_CHECK_INDEX);
    if (checkIndex) {
      List<Index> indexes=db.getIndexes(tblObj.getDbName(),tableName,Short.MAX_VALUE);
      if (indexes != null && indexes.size() > 0) {
        throw new SemanticException("can not do merge because source table " + tableName + " is indexed.");
      }
    }
    if (tblObj.isPartitioned()) {
      if (partSpec == null) {
        throw new SemanticException("source table " + tableName + " is partitioned but no partition desc found.");
      }
 else {
        Partition part=getPartition(tblObj,partSpec,false);
        if (part == null) {
          throw new SemanticException("source table " + tableName + " is partitioned but partition not found.");
        }
        bucketCols=part.getBucketCols();
        inputFormatClass=part.getInputFormatClass();
        isArchived=ArchiveUtils.isArchived(part);
        Path tabPath=tblObj.getPath();
        Path partPath=part.getPartitionPath();
        newTblPartLoc=new Path(tabPath.toUri().getScheme(),tabPath.toUri().getAuthority(),partPath.toUri().getPath());
        oldTblPartLoc=partPath;
        lbCtx=constructListBucketingCtx(part.getSkewedColNames(),part.getSkewedColValues(),part.getSkewedColValueLocationMaps(),part.isStoredAsSubDirectories(),conf);
      }
    }
 else {
      inputFormatClass=tblObj.getInputFormatClass();
      bucketCols=tblObj.getBucketCols();
      oldTblPartLoc=tblObj.getPath();
      newTblPartLoc=tblObj.getPath();
      lbCtx=constructListBucketingCtx(tblObj.getSkewedColNames(),tblObj.getSkewedColValues(),tblObj.getSkewedColValueLocationMaps(),tblObj.isStoredAsSubDirectories(),conf);
    }
    if (!inputFormatClass.equals(RCFileInputFormat.class)) {
      throw new SemanticException("Only RCFileFormat is supportted right now.");
    }
    if (bucketCols != null && bucketCols.size() > 0) {
      throw new SemanticException("Merge can not perform on bucketized partition/table.");
    }
    if (isArchived) {
      throw new SemanticException("Merge can not perform on archived partitions.");
    }
    inputDir.add(oldTblPartLoc.toString());
    mergeDesc.setInputDir(inputDir);
    mergeDesc.setLbCtx(lbCtx);
    addInputsOutputsAlterTable(tableName,partSpec);
    DDLWork ddlWork=new DDLWork(getInputs(),getOutputs(),mergeDesc);
    ddlWork.setNeedLock(true);
    Task<? extends Serializable> mergeTask=TaskFactory.get(ddlWork,conf);
    TableDesc tblDesc=Utilities.getTableDesc(tblObj);
    String queryTmpdir=ctx.getExternalTmpFileURI(newTblPartLoc.toUri());
    mergeDesc.setOutputDir(queryTmpdir);
    LoadTableDesc ltd=new LoadTableDesc(new Path(queryTmpdir),queryTmpdir,tblDesc,partSpec == null ? new HashMap<String,String>() : partSpec);
    ltd.setLbCtx(lbCtx);
    Task<MoveWork> moveTsk=TaskFactory.get(new MoveWork(null,null,ltd,null,false),conf);
    mergeTask.addDependentTask(moveTsk);
    if (conf.getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {
      StatsWork statDesc;
      if (oldTblPartLoc.equals(newTblPartLoc)) {
        tableSpec tablepart=new tableSpec(this.db,conf,tablePartAST);
        statDesc=new StatsWork(tablepart);
      }
 else {
        statDesc=new StatsWork(ltd);
      }
      statDesc.setNoStatsAggregator(true);
      statDesc.setClearAggregatorStats(true);
      statDesc.setStatsReliable(conf.getBoolVar(HiveConf.ConfVars.HIVE_STATS_RELIABLE));
      Task<? extends Serializable> statTask=TaskFactory.get(statDesc,conf);
      moveTsk.addDependentTask(statTask);
    }
    rootTasks.add(mergeTask);
  }
 catch (  Exception e) {
    throw new SemanticException(e);
  }
}
