{
  AlterTablePartMergeFilesDesc mergeDesc=new AlterTablePartMergeFilesDesc(tableName,partSpec);
  List<String> inputDir=new ArrayList<String>();
  String tblPartLoc=null;
  Table tblObj=null;
  try {
    tblObj=db.getTable(tableName);
    List<String> bucketCols=null;
    Class<? extends InputFormat> inputFormatClass=null;
    boolean isArchived=false;
    boolean checkIndex=HiveConf.getBoolVar(conf,HiveConf.ConfVars.HIVE_CONCATENATE_CHECK_INDEX);
    if (checkIndex) {
      List<Index> indexes=db.getIndexes(tblObj.getDbName(),tableName,Short.MAX_VALUE);
      if (indexes != null && indexes.size() > 0) {
        throw new SemanticException("can not do merge because source table " + tableName + " is indexed.");
      }
    }
    if (tblObj.isPartitioned()) {
      if (partSpec == null) {
        throw new SemanticException("source table " + tableName + " is partitioned but no partition desc found.");
      }
 else {
        Partition part=db.getPartition(tblObj,partSpec,false);
        if (part == null) {
          throw new SemanticException("source table " + tableName + " is partitioned but partition not found.");
        }
        bucketCols=part.getBucketCols();
        inputFormatClass=part.getInputFormatClass();
        isArchived=ArchiveUtils.isArchived(part);
        tblPartLoc=part.getDataLocation().toString();
      }
    }
 else {
      inputFormatClass=tblObj.getInputFormatClass();
      bucketCols=tblObj.getBucketCols();
      tblPartLoc=tblObj.getDataLocation().toString();
    }
    if (!inputFormatClass.equals(RCFileInputFormat.class)) {
      throw new SemanticException("Only RCFileFormat is supportted right now.");
    }
    if (bucketCols != null && bucketCols.size() > 0) {
      throw new SemanticException("Merge can not perform on bucketized partition/table.");
    }
    if (isArchived) {
      throw new SemanticException("Merge can not perform on archived partitions.");
    }
    inputDir.add(tblPartLoc);
    mergeDesc.setInputDir(inputDir);
    addInputsOutputsAlterTable(tableName,partSpec);
    DDLWork ddlWork=new DDLWork(getInputs(),getOutputs(),mergeDesc);
    ddlWork.setNeedLock(true);
    Task<? extends Serializable> mergeTask=TaskFactory.get(ddlWork,conf);
    TableDesc tblDesc=Utilities.getTableDesc(tblObj);
    String queryTmpdir=ctx.getExternalTmpFileURI(new URI(tblPartLoc));
    mergeDesc.setOutputDir(queryTmpdir);
    LoadTableDesc ltd=new LoadTableDesc(queryTmpdir,queryTmpdir,tblDesc,partSpec == null ? new HashMap<String,String>() : partSpec);
    Task<MoveWork> moveTsk=TaskFactory.get(new MoveWork(null,null,ltd,null,false),conf);
    mergeTask.addDependentTask(moveTsk);
    tableSpec tablepart=new tableSpec(this.db,conf,tablePartAST);
    StatsWork statDesc=new StatsWork(tablepart);
    statDesc.setNoStatsAggregator(true);
    Task<? extends Serializable> statTask=TaskFactory.get(statDesc,conf);
    moveTsk.addDependentTask(statTask);
    rootTasks.add(mergeTask);
  }
 catch (  Exception e) {
    throw new SemanticException(e);
  }
}
