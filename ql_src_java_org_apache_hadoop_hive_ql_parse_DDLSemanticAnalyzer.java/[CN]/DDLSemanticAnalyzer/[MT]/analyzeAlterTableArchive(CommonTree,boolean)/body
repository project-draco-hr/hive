{
  if (!conf.getBoolVar(HiveConf.ConfVars.HIVEARCHIVEENABLED)) {
    throw new SemanticException(ErrorMsg.ARCHIVE_METHODS_DISABLED.getMsg());
  }
  String tblName=unescapeIdentifier(ast.getChild(0).getText());
  List<Map<String,String>> partSpecs=getPartitionSpecs(ast);
  try {
    Table tab=db.getTable(MetaStoreUtils.DEFAULT_DATABASE_NAME,tblName,false);
    if (tab != null) {
      inputs.add(new ReadEntity(tab));
    }
  }
 catch (  HiveException e) {
    throw new SemanticException(ErrorMsg.INVALID_TABLE.getMsg(tblName));
  }
  addTablePartsOutputs(tblName,partSpecs);
  if (partSpecs.size() > 1) {
    throw new SemanticException(isUnArchive ? ErrorMsg.UNARCHIVE_ON_MULI_PARTS.getMsg() : ErrorMsg.ARCHIVE_ON_MULI_PARTS.getMsg());
  }
  if (partSpecs.size() == 0) {
    throw new SemanticException(ErrorMsg.ARCHIVE_ON_TABLE.getMsg());
  }
  Map<String,String> partSpec=partSpecs.get(0);
  AlterTableSimpleDesc archiveDesc=new AlterTableSimpleDesc(MetaStoreUtils.DEFAULT_DATABASE_NAME,tblName,partSpec,(isUnArchive ? AlterTableTypes.UNARCHIVE : AlterTableTypes.ARCHIVE));
  rootTasks.add(TaskFactory.get(new DDLWork(getInputs(),getOutputs(),archiveDesc),conf));
}
