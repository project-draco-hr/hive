{
  boolean ifExists=(ast.getFirstChildWithType(HiveParser.TOK_IFEXISTS) != null) || HiveConf.getBoolVar(conf,ConfVars.DROPIGNORESNONEXISTENT);
  boolean canGroupExprs=ifExists;
  boolean mustPurge=(ast.getFirstChildWithType(HiveParser.KW_PURGE) != null);
  ReplicationSpec replicationSpec=new ReplicationSpec(ast);
  Table tab=null;
  try {
    tab=getTable(qualified);
  }
 catch (  SemanticException se) {
    if (replicationSpec.isInReplicationScope() && ((se.getCause() instanceof InvalidTableException) || (se.getMessage().contains(ErrorMsg.INVALID_TABLE.getMsg())))) {
      return;
    }
 else {
      throw se;
    }
  }
  Map<Integer,List<ExprNodeGenericFuncDesc>> partSpecs=getFullPartitionSpecs(ast,tab,canGroupExprs);
  if (partSpecs.isEmpty())   return;
  validateAlterTableType(tab,AlterTableTypes.DROPPARTITION,expectView);
  ReadEntity re=new ReadEntity(tab);
  re.noLockNeeded();
  inputs.add(re);
  addTableDropPartsOutputs(tab,partSpecs.values(),!ifExists);
  DropTableDesc dropTblDesc=new DropTableDesc(getDotName(qualified),partSpecs,expectView ? TableType.VIRTUAL_VIEW : null,mustPurge,replicationSpec);
  rootTasks.add(TaskFactory.get(new DDLWork(getInputs(),getOutputs(),dropTblDesc),conf));
}
