{
  String inputFormat=null;
  String outputFormat=null;
  String storageHandler=null;
  String serde=null;
  ASTNode child=(ASTNode)ast.getChild(0);
switch (child.getToken().getType()) {
case HiveParser.TOK_TABLEFILEFORMAT:
    inputFormat=unescapeSQLString(((ASTNode)child.getChild(0)).getToken().getText());
  outputFormat=unescapeSQLString(((ASTNode)child.getChild(1)).getToken().getText());
try {
  Class.forName(inputFormat);
  Class.forName(outputFormat);
}
 catch (ClassNotFoundException e) {
  throw new SemanticException(e);
}
break;
case HiveParser.TOK_STORAGEHANDLER:
storageHandler=unescapeSQLString(((ASTNode)child.getChild(1)).getToken().getText());
try {
Class.forName(storageHandler);
}
 catch (ClassNotFoundException e) {
throw new SemanticException(e);
}
break;
case HiveParser.TOK_TBLSEQUENCEFILE:
inputFormat=SEQUENCEFILE_INPUT;
outputFormat=SEQUENCEFILE_OUTPUT;
break;
case HiveParser.TOK_TBLTEXTFILE:
inputFormat=TEXTFILE_INPUT;
outputFormat=TEXTFILE_OUTPUT;
break;
case HiveParser.TOK_TBLRCFILE:
inputFormat=RCFILE_INPUT;
outputFormat=RCFILE_OUTPUT;
serde=COLUMNAR_SERDE;
break;
}
AlterTableDesc alterTblDesc=new AlterTableDesc(tableName,inputFormat,outputFormat,serde,storageHandler,partSpec);
rootTasks.add(TaskFactory.get(new DDLWork(getInputs(),getOutputs(),alterTblDesc),conf));
}
