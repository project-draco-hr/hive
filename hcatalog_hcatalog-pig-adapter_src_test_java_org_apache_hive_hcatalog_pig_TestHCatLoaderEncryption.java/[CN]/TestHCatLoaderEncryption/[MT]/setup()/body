{
  File f=new File(TEST_WAREHOUSE_DIR);
  if (f.exists()) {
    FileUtil.fullyDelete(f);
  }
  if (!(new File(TEST_WAREHOUSE_DIR).mkdirs())) {
    throw new RuntimeException("Could not create " + TEST_WAREHOUSE_DIR);
  }
  HiveConf hiveConf=new HiveConf(this.getClass());
  hiveConf.set(HiveConf.ConfVars.PREEXECHOOKS.varname,"");
  hiveConf.set(HiveConf.ConfVars.POSTEXECHOOKS.varname,"");
  hiveConf.set(HiveConf.ConfVars.HIVE_SUPPORT_CONCURRENCY.varname,"false");
  hiveConf.set(HiveConf.ConfVars.METASTOREWAREHOUSE.varname,TEST_WAREHOUSE_DIR);
  hiveConf.setVar(HiveConf.ConfVars.HIVE_AUTHORIZATION_MANAGER,"org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory");
  String s=hiveConf.get("hdfs.minidfs.basedir");
  if (s == null || s.length() <= 0) {
    hiveConf.set("hdfs.minidfs.basedir",System.getProperty("test.build.data","build/test/data") + "_" + System.currentTimeMillis()+ "_"+ salt.getAndIncrement()+ "/dfs/");
  }
  if (Shell.WINDOWS) {
    WindowsPathUtil.convertPathsFromWindowsToHdfs(hiveConf);
  }
  driver=new Driver(hiveConf);
  initEncryptionShim(hiveConf);
  String encryptedTablePath=TEST_WAREHOUSE_DIR + "/encryptedTable";
  SessionState.start(new CliSessionState(hiveConf));
  SessionState.get().out=System.out;
  createTable(BASIC_TABLE,"a int, b string");
  createTableInSpecifiedPath(ENCRYPTED_TABLE,"a int, b string",WindowsPathUtil.getHdfsUriString(encryptedTablePath),driver);
  associateEncryptionZoneWithPath(WindowsPathUtil.getHdfsUriString(encryptedTablePath));
  int LOOP_SIZE=3;
  String[] input=new String[LOOP_SIZE * LOOP_SIZE];
  basicInputData=new HashMap<Integer,Pair<Integer,String>>();
  int k=0;
  for (int i=1; i <= LOOP_SIZE; i++) {
    String si=i + "";
    for (int j=1; j <= LOOP_SIZE; j++) {
      String sj="S" + j + "S";
      input[k]=si + "\t" + sj;
      basicInputData.put(k,new Pair<Integer,String>(i,sj));
      k++;
    }
  }
  HcatTestUtils.createTestDataFile(BASIC_FILE_NAME,input);
  PigServer server=new PigServer(ExecType.LOCAL);
  server.setBatchOn();
  int i=0;
  server.registerQuery("A = load '" + BASIC_FILE_NAME + "' as (a:int, b:chararray);",++i);
  server.registerQuery("store A into '" + ENCRYPTED_TABLE + "' using org.apache.hive.hcatalog.pig.HCatStorer();",++i);
  server.executeBatch();
}
