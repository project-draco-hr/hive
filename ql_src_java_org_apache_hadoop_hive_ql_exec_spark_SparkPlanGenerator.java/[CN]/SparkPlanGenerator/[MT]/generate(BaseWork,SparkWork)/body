{
  initStatsPublisher(work);
  JobConf newJobConf=cloneJobConf(work);
  checkSpecs(work,newJobConf);
  byte[] confBytes=KryoSerializer.serializeJobConf(newJobConf);
  boolean caching=isCachingWork(work,sparkWork);
  if (work instanceof MapWork) {
    if (work instanceof MergeFileWork) {
      Path outputPath=((MergeFileWork)work).getOutputDir();
      Path tempOutPath=Utilities.toTempPath(outputPath);
      FileSystem fs=outputPath.getFileSystem(jobConf);
      try {
        if (!fs.exists(tempOutPath)) {
          fs.mkdirs(tempOutPath);
        }
      }
 catch (      IOException e) {
        throw new RuntimeException("Can't make path " + outputPath + " : "+ e.getMessage());
      }
    }
    MapTran mapTran=new MapTran(caching);
    HiveMapFunction mapFunc=new HiveMapFunction(confBytes,sparkReporter);
    mapTran.setMapFunction(mapFunc);
    return mapTran;
  }
 else   if (work instanceof ReduceWork) {
    ReduceTran reduceTran=new ReduceTran(caching);
    HiveReduceFunction reduceFunc=new HiveReduceFunction(confBytes,sparkReporter);
    reduceTran.setReduceFunction(reduceFunc);
    return reduceTran;
  }
 else {
    throw new IllegalStateException("AssertionError: expected either MapWork or ReduceWork, " + "but found " + work.getClass().getName());
  }
}
