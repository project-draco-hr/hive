{
  SignalHandler oldSignal=null;
  Signal interupSignal=null;
  if (allowInterupting) {
    interupSignal=new Signal("INT");
    oldSignal=Signal.handle(interupSignal,new SignalHandler(){
      private final Thread cliThread=Thread.currentThread();
      private boolean interruptRequested;
      @Override public void handle(      Signal signal){
        boolean initialRequest=!interruptRequested;
        interruptRequested=true;
        if (!initialRequest) {
          console.printInfo("Exiting the JVM");
          System.exit(127);
        }
        console.printInfo("Interrupting... Be patient, this might take some time.");
        console.printInfo("Press Ctrl+C again to kill JVM");
        HadoopJobExecHelper.killRunningJobs();
        HiveInterruptUtils.interrupt();
        this.cliThread.interrupt();
      }
    }
);
  }
  try {
    int lastRet=0, ret=0;
    String command="";
    for (    String oneCmd : line.split(";")) {
      if (StringUtils.endsWith(oneCmd,"\\")) {
        command+=StringUtils.chop(oneCmd) + ";";
        continue;
      }
 else {
        command+=oneCmd;
      }
      if (StringUtils.isBlank(command)) {
        continue;
      }
      ret=processCmd(command);
      SessionState ss=SessionState.get();
      ss.setCommandType(null);
      command="";
      lastRet=ret;
      boolean ignoreErrors=HiveConf.getBoolVar(conf,HiveConf.ConfVars.CLIIGNOREERRORS);
      if (ret != 0 && !ignoreErrors) {
        CommandProcessorFactory.clean((HiveConf)conf);
        return ret;
      }
    }
    CommandProcessorFactory.clean((HiveConf)conf);
    return lastRet;
  }
  finally {
    if (oldSignal != null && interupSignal != null) {
      Signal.handle(interupSignal,oldSignal);
    }
  }
}
