{
  LOG.info("Stats Aggregator for key " + fileID);
  if (statType != StatsSetupConst.ROW_COUNT) {
    LOG.warn("Warning. Invalid statistic. Currently " + "row count is the only supported statistic");
    return null;
  }
  Utilities.SQLCommand<ResultSet> execQuery=new Utilities.SQLCommand<ResultSet>(){
    @Override public ResultSet run(    PreparedStatement stmt) throws SQLException {
      return stmt.executeQuery();
    }
  }
;
  Utilities.SQLCommand<Void> execUpdate=new Utilities.SQLCommand<Void>(){
    @Override public Void run(    PreparedStatement stmt) throws SQLException {
      stmt.executeUpdate();
      return null;
    }
  }
;
  String keyPrefix=Utilities.escapeSqlLike(fileID) + "%";
  for (int failures=0; ; failures++) {
    try {
      long retval=0;
      selStmt.setString(1,keyPrefix);
      selStmt.setString(2,Character.toString(Utilities.sqlEscapeChar));
      ResultSet result=Utilities.executeWithRetry(execQuery,selStmt,waitWindow,maxRetries);
      if (result.next()) {
        retval=result.getLong(1);
      }
 else {
        LOG.warn("Warning. Nothing published. Nothing aggregated.");
        return "";
      }
      delStmt.setString(1,keyPrefix);
      delStmt.setString(2,Character.toString(Utilities.sqlEscapeChar));
      Utilities.executeWithRetry(execUpdate,delStmt,waitWindow,maxRetries);
      LOG.info("Stats aggregator got " + retval);
      return Long.toString(retval);
    }
 catch (    SQLRecoverableException e) {
      if (failures >= maxRetries) {
        return null;
      }
      closeConnection();
      long waitTime=Utilities.getRandomWaitTime(waitWindow,failures,r);
      try {
        Thread.sleep(waitTime);
      }
 catch (      InterruptedException iex) {
      }
      if (!connect(hiveconf)) {
        LOG.error("Error during publishing aggregation. " + e);
        return null;
      }
    }
catch (    SQLException e) {
      LOG.error("Error during publishing aggregation. " + e);
      return null;
    }
  }
}
