{
  int rc=1;
  SparkSession sparkSession=null;
  SparkSessionManager sparkSessionManager=null;
  try {
    printConfigInfo();
    sparkSessionManager=SparkSessionManagerImpl.getInstance();
    sparkSession=SessionState.get().getSparkSession();
    if (conf.getSparkConfigUpdated()) {
      sparkSessionManager.closeSession(sparkSession);
      sparkSession=null;
      conf.setSparkConfigUpdated(false);
    }
    sparkSession=sparkSessionManager.getSession(sparkSession,conf,true);
    SessionState.get().setSparkSession(sparkSession);
    SparkWork sparkWork=getWork();
    String statsImpl=HiveConf.getVar(conf,HiveConf.ConfVars.HIVESTATSDBCLASS);
    StatsTask statsTask=getStatsTaskInChildTasks(this);
    if (statsImpl.equalsIgnoreCase("counter") && statsTask != null) {
      sparkWork.setRequiredCounterPrefix(getRequiredCounterPrefix(statsTask));
    }
    SparkJobRef jobRef=sparkSession.submit(driverContext,sparkWork);
    sparkCounters=jobRef.getSparkJobStatus().getCounter();
    SparkJobMonitor monitor=new SparkJobMonitor(jobRef.getSparkJobStatus());
    monitor.startMonitor();
    console.printInfo(sparkCounters.toString());
    rc=0;
  }
 catch (  Exception e) {
    LOG.error("Failed to execute spark task.",e);
    return 1;
  }
 finally {
    if (sparkSession != null && sparkSessionManager != null) {
      rc=close(rc);
      try {
        sparkSessionManager.returnSession(sparkSession);
      }
 catch (      HiveException ex) {
        LOG.error("Failed to return the session to SessionManager",ex);
      }
    }
  }
  return rc;
}
