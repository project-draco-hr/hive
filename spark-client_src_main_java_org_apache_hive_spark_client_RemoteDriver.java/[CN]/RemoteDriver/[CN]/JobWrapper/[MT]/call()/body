{
  protocol.jobStarted(req.id);
  try {
    jc.setMonitorCb(new MonitorCallback(){
      @Override public void call(      JavaFutureAction<?> future,      SparkCounters sparkCounters,      Set<Integer> cachedRDDIds){
        monitorJob(future,sparkCounters,cachedRDDIds);
      }
    }
);
    T result=req.job.call(jc);
    for (    JavaFutureAction<?> future : jobs) {
      future.get();
      completed++;
      LOG.debug("Client job {}: {} of {} Spark jobs finished.",req.id,completed,jobs.size());
    }
    if (sparkJobId != null) {
      SparkJobInfo sparkJobInfo=jc.sc().statusTracker().getJobInfo(sparkJobId);
      if (sparkJobInfo != null && sparkJobInfo.stageIds() != null && sparkJobInfo.stageIds().length > 0) {
synchronized (jobEndReceived) {
          while (jobEndReceived.get() < jobs.size()) {
            jobEndReceived.wait();
          }
        }
      }
    }
    SparkCounters counters=null;
    if (sparkCounters != null) {
      counters=sparkCounters.snapshot();
    }
    protocol.jobFinished(req.id,result,null,counters);
  }
 catch (  Throwable t) {
    LOG.info("Failed to run job " + req.id,t);
    protocol.jobFinished(req.id,null,t,sparkCounters != null ? sparkCounters.snapshot() : null);
    throw new ExecutionException(t);
  }
 finally {
    jc.setMonitorCb(null);
    activeJobs.remove(req.id);
    releaseCache();
  }
  return null;
}
