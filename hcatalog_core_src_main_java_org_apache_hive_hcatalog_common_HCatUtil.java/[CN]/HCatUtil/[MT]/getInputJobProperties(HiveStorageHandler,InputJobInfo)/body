{
  Properties props=inputJobInfo.getTableInfo().getStorerInfo().getProperties();
  props.put(serdeConstants.SERIALIZATION_LIB,storageHandler.getSerDeClass().getName());
  TableDesc tableDesc=new TableDesc(storageHandler.getInputFormatClass(),storageHandler.getOutputFormatClass(),props);
  if (tableDesc.getJobProperties() == null) {
    tableDesc.setJobProperties(new HashMap<String,String>());
  }
  Properties mytableProperties=tableDesc.getProperties();
  mytableProperties.setProperty(org.apache.hadoop.hive.metastore.api.hive_metastoreConstants.META_TABLE_NAME,inputJobInfo.getDatabaseName() + "." + inputJobInfo.getTableName());
  Map<String,String> jobProperties=new HashMap<String,String>();
  try {
    tableDesc.getJobProperties().put(HCatConstants.HCAT_KEY_JOB_INFO,HCatUtil.serialize(inputJobInfo));
    storageHandler.configureInputJobProperties(tableDesc,jobProperties);
  }
 catch (  IOException e) {
    throw new IllegalStateException("Failed to configure StorageHandler",e);
  }
  return jobProperties;
}
