{
  PERF_LOGGER.PerfLogBegin(CLASS_NAME,PerfLogger.SPARK_GENERATE_TASK_TREE);
  GenSparkUtils utils=GenSparkUtils.getUtils();
  utils.resetSequenceNumber();
  ParseContext tempParseContext=getParseContext(pCtx,rootTasks);
  GenSparkProcContext procCtx=new GenSparkProcContext(conf,tempParseContext,mvTask,rootTasks,inputs,outputs,pCtx.getTopOps());
  Map<Rule,NodeProcessor> opRules=new LinkedHashMap<Rule,NodeProcessor>();
  opRules.put(new RuleRegExp("Clone OP tree for PartitionPruningSink",SparkPartitionPruningSinkOperator.getOperatorName() + "%"),new SplitOpTreeForDPP());
  Dispatcher disp=new DefaultRuleDispatcher(null,opRules,procCtx);
  GraphWalker ogw=new GenSparkWorkWalker(disp,procCtx);
  List<Node> topNodes=new ArrayList<Node>();
  topNodes.addAll(pCtx.getTopOps().values());
  ogw.startWalking(topNodes,null);
  topNodes.clear();
  topNodes.addAll(procCtx.topOps.values());
  generateTaskTreeHelper(procCtx,topNodes);
  if (!procCtx.clonedPruningTableScanSet.isEmpty()) {
    SparkTask pruningTask=SparkUtilities.createSparkTask(conf);
    SparkTask mainTask=procCtx.currentTask;
    pruningTask.addDependentTask(procCtx.currentTask);
    procCtx.rootTasks.remove(procCtx.currentTask);
    procCtx.rootTasks.add(pruningTask);
    procCtx.currentTask=pruningTask;
    topNodes.clear();
    topNodes.addAll(procCtx.clonedPruningTableScanSet);
    generateTaskTreeHelper(procCtx,topNodes);
    procCtx.currentTask=mainTask;
  }
  for (  BaseWork w : procCtx.workWithUnionOperators) {
    GenSparkUtils.getUtils().removeUnionOperators(procCtx,w);
  }
  GenSparkUtils.getUtils().annotateMapWork(procCtx);
  for (  FileSinkOperator fileSink : procCtx.fileSinkSet) {
    GenSparkUtils.getUtils().processFileSink(procCtx,fileSink);
  }
  for (  Operator<?> prunerSink : procCtx.pruningSinkSet) {
    utils.processPartitionPruningSink(procCtx,(SparkPartitionPruningSinkOperator)prunerSink);
  }
  PERF_LOGGER.PerfLogEnd(CLASS_NAME,PerfLogger.SPARK_GENERATE_TASK_TREE);
}
