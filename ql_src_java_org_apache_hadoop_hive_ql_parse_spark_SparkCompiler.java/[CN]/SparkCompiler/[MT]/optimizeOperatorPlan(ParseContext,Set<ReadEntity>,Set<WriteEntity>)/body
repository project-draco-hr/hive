{
  PERF_LOGGER.PerfLogBegin(CLASS_NAME,PerfLogger.SPARK_OPTIMIZE_OPERATOR_TREE);
  Deque<Operator<? extends OperatorDesc>> deque=new LinkedList<Operator<? extends OperatorDesc>>();
  deque.addAll(pCtx.getTopOps().values());
  OptimizeSparkProcContext procCtx=new OptimizeSparkProcContext(conf,pCtx,inputs,outputs,deque);
  Map<Rule,NodeProcessor> opRules=new LinkedHashMap<Rule,NodeProcessor>();
  opRules.put(new RuleRegExp("Set parallelism - ReduceSink",ReduceSinkOperator.getOperatorName() + "%"),new SetSparkReducerParallelism());
  opRules.put(new TypeRule(JoinOperator.class),new SparkJoinOptimizer(pCtx));
  opRules.put(new TypeRule(MapJoinOperator.class),new SparkJoinHintOptimizer(pCtx));
  Dispatcher disp=new DefaultRuleDispatcher(null,opRules,procCtx);
  GraphWalker ogw=new DefaultGraphWalker(disp);
  ArrayList<Node> topNodes=new ArrayList<Node>();
  topNodes.addAll(pCtx.getTopOps().values());
  ogw.startWalking(topNodes,null);
  PERF_LOGGER.PerfLogEnd(CLASS_NAME,PerfLogger.SPARK_OPTIMIZE_OPERATOR_TREE);
}
