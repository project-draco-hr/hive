{
  String testName="bulkModeAbortTest";
  Path methodTestDir=new Path(getTestDir(),testName);
  String databaseName=testName.toLowerCase();
  String dbDir=new Path(methodTestDir,"DB_" + testName).toString();
  String tableName=newTableName(testName).toLowerCase();
  String familyName="my_family";
  Configuration conf=new Configuration(allConf);
  conf.set(HCatConstants.HCAT_KEY_HIVE_CONF,HCatUtil.serialize(allConf.getAllProperties()));
  String dbquery="CREATE DATABASE IF NOT EXISTS " + databaseName + " LOCATION '"+ dbDir+ "'";
  String tableQuery="CREATE TABLE " + databaseName + "."+ tableName+ "(key int, english string, spanish string) STORED BY "+ "'org.apache.hcatalog.hbase.HBaseHCatStorageHandler'"+ "TBLPROPERTIES ('"+ HBaseConstants.PROPERTY_BULK_OUTPUT_MODE_KEY+ "'='true',"+ "'hbase.columns.mapping'=':key,"+ familyName+ ":english,"+ familyName+ ":spanish')";
  assertEquals(0,hcatDriver.run(dbquery).getResponseCode());
  assertEquals(0,hcatDriver.run(tableQuery).getResponseCode());
  String data[]={"1,english:ONE,spanish:UNO","2,english:TWO,spanish:DOS","3,english:THREE,spanish:TRES"};
  Path inputPath=new Path(methodTestDir,"mr_input");
  getFileSystem().mkdirs(inputPath);
  for (int i=0; i < data.length; i++) {
    FSDataOutputStream os=getFileSystem().create(new Path(inputPath,"inputFile" + i + ".txt"));
    os.write(Bytes.toBytes(data[i] + "\n"));
    os.close();
  }
  Path workingDir=new Path(methodTestDir,"mr_abort");
  OutputJobInfo outputJobInfo=OutputJobInfo.create(databaseName,tableName,null);
  Job job=configureJob(testName,conf,workingDir,MapWriteAbortTransaction.class,outputJobInfo,inputPath);
  assertFalse(job.waitForCompletion(true));
  RevisionManager rm=HBaseRevisionManagerUtil.getOpenedRevisionManager(conf);
  try {
    TableSnapshot snapshot=rm.createSnapshot(databaseName + "." + tableName);
    for (    String family : snapshot.getColumnFamilies()) {
      assertEquals(1,snapshot.getRevision(family));
      List<FamilyRevision> abortedWriteTransactions=rm.getAbortedWriteTransactions(databaseName + "." + tableName,family);
      assertEquals(1,abortedWriteTransactions.size());
      assertEquals(1,abortedWriteTransactions.get(0).getRevision());
    }
  }
  finally {
    rm.close();
  }
  HTable table=new HTable(conf,databaseName + "." + tableName);
  Scan scan=new Scan();
  scan.addFamily(Bytes.toBytes(familyName));
  ResultScanner scanner=table.getScanner(scan);
  assertFalse(scanner.iterator().hasNext());
  Path outputDir=new Path(getTestDir(),"mapred/testHBaseTableBulkIgnoreAbortedTransactions");
  FileSystem fs=getFileSystem();
  if (fs.exists(outputDir)) {
    fs.delete(outputDir,true);
  }
  job=new Job(conf,"hbase-bulk-aborted-transaction");
  job.setJarByClass(this.getClass());
  job.setMapperClass(MapReadAbortedTransaction.class);
  job.setInputFormatClass(HCatInputFormat.class);
  InputJobInfo inputJobInfo=InputJobInfo.create(databaseName,tableName,null);
  HCatInputFormat.setInput(job,inputJobInfo);
  job.setOutputFormatClass(TextOutputFormat.class);
  TextOutputFormat.setOutputPath(job,outputDir);
  job.setMapOutputKeyClass(BytesWritable.class);
  job.setMapOutputValueClass(Text.class);
  job.setOutputKeyClass(BytesWritable.class);
  job.setOutputValueClass(Text.class);
  job.setNumReduceTasks(0);
  assertTrue(job.waitForCompletion(true));
}
