{
  initFields();
  int mutable_bitField0_=0;
  com.google.protobuf.UnknownFieldSet.Builder unknownFields=com.google.protobuf.UnknownFieldSet.newBuilder();
  try {
    boolean done=false;
    while (!done) {
      int tag=input.readTag();
switch (tag) {
case 0:
        done=true;
      break;
default :
{
      if (!parseUnknownField(input,unknownFields,extensionRegistry,tag)) {
        done=true;
      }
      break;
    }
case 10:
{
    bitField0_|=0x00000001;
    user_=input.readBytes();
    break;
  }
case 16:
{
  bitField0_|=0x00000002;
  signatureKeyId_=input.readInt64();
  break;
}
case 26:
{
org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.VertexIdentifier.Builder subBuilder=null;
if (((bitField0_ & 0x00000004) == 0x00000004)) {
  subBuilder=vertexIdentifier_.toBuilder();
}
vertexIdentifier_=input.readMessage(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.VertexIdentifier.PARSER,extensionRegistry);
if (subBuilder != null) {
  subBuilder.mergeFrom(vertexIdentifier_);
  vertexIdentifier_=subBuilder.buildPartial();
}
bitField0_|=0x00000004;
break;
}
case 34:
{
bitField0_|=0x00000008;
dagName_=input.readBytes();
break;
}
case 42:
{
bitField0_|=0x00000010;
vertexName_=input.readBytes();
break;
}
case 50:
{
bitField0_|=0x00000020;
tokenIdentifier_=input.readBytes();
break;
}
case 58:
{
org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.EntityDescriptorProto.Builder subBuilder=null;
if (((bitField0_ & 0x00000040) == 0x00000040)) {
subBuilder=processorDescriptor_.toBuilder();
}
processorDescriptor_=input.readMessage(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.EntityDescriptorProto.PARSER,extensionRegistry);
if (subBuilder != null) {
subBuilder.mergeFrom(processorDescriptor_);
processorDescriptor_=subBuilder.buildPartial();
}
bitField0_|=0x00000040;
break;
}
case 66:
{
if (!((mutable_bitField0_ & 0x00000080) == 0x00000080)) {
inputSpecs_=new java.util.ArrayList<org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.IOSpecProto>();
mutable_bitField0_|=0x00000080;
}
inputSpecs_.add(input.readMessage(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.IOSpecProto.PARSER,extensionRegistry));
break;
}
case 74:
{
if (!((mutable_bitField0_ & 0x00000100) == 0x00000100)) {
outputSpecs_=new java.util.ArrayList<org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.IOSpecProto>();
mutable_bitField0_|=0x00000100;
}
outputSpecs_.add(input.readMessage(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.IOSpecProto.PARSER,extensionRegistry));
break;
}
case 82:
{
if (!((mutable_bitField0_ & 0x00000200) == 0x00000200)) {
groupedInputSpecs_=new java.util.ArrayList<org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.GroupInputSpecProto>();
mutable_bitField0_|=0x00000200;
}
groupedInputSpecs_.add(input.readMessage(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.GroupInputSpecProto.PARSER,extensionRegistry));
break;
}
case 88:
{
bitField0_|=0x00000080;
vertexParallelism_=input.readInt32();
break;
}
}
}
}
 catch (com.google.protobuf.InvalidProtocolBufferException e) {
throw e.setUnfinishedMessage(this);
}
catch (java.io.IOException e) {
throw new com.google.protobuf.InvalidProtocolBufferException(e.getMessage()).setUnfinishedMessage(this);
}
 finally {
if (((mutable_bitField0_ & 0x00000080) == 0x00000080)) {
inputSpecs_=java.util.Collections.unmodifiableList(inputSpecs_);
}
if (((mutable_bitField0_ & 0x00000100) == 0x00000100)) {
outputSpecs_=java.util.Collections.unmodifiableList(outputSpecs_);
}
if (((mutable_bitField0_ & 0x00000200) == 0x00000200)) {
groupedInputSpecs_=java.util.Collections.unmodifiableList(groupedInputSpecs_);
}
this.unknownFields=unknownFields.build();
makeExtensionsImmutable();
}
}
