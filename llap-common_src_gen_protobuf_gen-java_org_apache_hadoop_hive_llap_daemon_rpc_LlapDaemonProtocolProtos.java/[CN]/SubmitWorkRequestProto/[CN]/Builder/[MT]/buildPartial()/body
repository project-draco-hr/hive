{
  org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.SubmitWorkRequestProto result=new org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.SubmitWorkRequestProto(this);
  int from_bitField0_=bitField0_;
  int to_bitField0_=0;
  if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
    to_bitField0_|=0x00000001;
  }
  result.containerIdString_=containerIdString_;
  if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
    to_bitField0_|=0x00000002;
  }
  result.amHost_=amHost_;
  if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
    to_bitField0_|=0x00000004;
  }
  result.amPort_=amPort_;
  if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
    to_bitField0_|=0x00000008;
  }
  result.tokenIdentifier_=tokenIdentifier_;
  if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
    to_bitField0_|=0x00000010;
  }
  result.credentialsBinary_=credentialsBinary_;
  if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
    to_bitField0_|=0x00000020;
  }
  result.user_=user_;
  if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
    to_bitField0_|=0x00000040;
  }
  result.applicationIdString_=applicationIdString_;
  if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
    to_bitField0_|=0x00000080;
  }
  result.appAttemptNumber_=appAttemptNumber_;
  if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
    to_bitField0_|=0x00000100;
  }
  if (fragmentSpecBuilder_ == null) {
    result.fragmentSpec_=fragmentSpec_;
  }
 else {
    result.fragmentSpec_=fragmentSpecBuilder_.build();
  }
  if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
    to_bitField0_|=0x00000200;
  }
  if (fragmentRuntimeInfoBuilder_ == null) {
    result.fragmentRuntimeInfo_=fragmentRuntimeInfo_;
  }
 else {
    result.fragmentRuntimeInfo_=fragmentRuntimeInfoBuilder_.build();
  }
  if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
    to_bitField0_|=0x00000400;
  }
  result.usingTezAm_=usingTezAm_;
  result.bitField0_=to_bitField0_;
  onBuilt();
  return result;
}
