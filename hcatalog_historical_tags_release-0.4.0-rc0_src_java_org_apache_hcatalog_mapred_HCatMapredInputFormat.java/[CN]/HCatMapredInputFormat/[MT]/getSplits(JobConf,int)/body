{
  try {
    List<InputSplit> hsplits=new ArrayList<InputSplit>();
    for (    org.apache.hadoop.mapreduce.InputSplit hs : hci.getSplits(HCatHadoopShims.Instance.get().createJobContext(job,new JobID()))) {
      HiveHCatSplitWrapper hwrapper=new HiveHCatSplitWrapper((HCatSplit)hs);
      String hwrapperPath=hwrapper.getPath().toString();
      String mapredInputDir=job.get("mapred.input.dir","null");
      if (hwrapperPath.startsWith(mapredInputDir)) {
        hsplits.add(hwrapper);
      }
    }
    InputSplit[] splits=new InputSplit[hsplits.size()];
    for (int i=0; i < hsplits.size(); i++) {
      splits[i]=hsplits.get(i);
    }
    return splits;
  }
 catch (  java.lang.InterruptedException e) {
    throw new IOException(e);
  }
}
