{
  Runnable runnable;
  final String serverAddress=rpcServer.getAddress();
  final String serverPort=String.valueOf(rpcServer.getPort());
  if (conf.containsKey(SparkClientFactory.CONF_KEY_IN_PROCESS)) {
    LOG.warn("!!!! Running remote driver in-process. !!!!");
    runnable=new Runnable(){
      @Override public void run(){
        List<String> args=Lists.newArrayList();
        args.add("--remote-host");
        args.add(serverAddress);
        args.add("--remote-port");
        args.add(serverPort);
        args.add("--client-id");
        args.add(clientId);
        args.add("--secret");
        args.add(secret);
        for (        Map.Entry<String,String> e : conf.entrySet()) {
          args.add("--conf");
          args.add(String.format("%s=%s",e.getKey(),conf.get(e.getKey())));
        }
        try {
          RemoteDriver.main(args.toArray(new String[args.size()]));
        }
 catch (        Exception e) {
          LOG.error("Error running driver.",e);
        }
      }
    }
;
  }
 else {
    String sparkHome=conf.get("spark.home");
    if (sparkHome == null) {
      sparkHome=System.getProperty("spark.home");
    }
    String sparkLogDir=conf.get("hive.spark.log.dir");
    if (sparkLogDir == null) {
      if (sparkHome == null) {
        sparkLogDir="./target/";
      }
 else {
        sparkLogDir=sparkHome + "/logs/";
      }
    }
    String osxTestOpts="";
    if (Strings.nullToEmpty(System.getProperty("os.name")).toLowerCase().contains("mac")) {
      osxTestOpts=Strings.nullToEmpty(System.getenv(OSX_TEST_OPTS));
    }
    String driverJavaOpts=Joiner.on(" ").skipNulls().join("-Dhive.spark.log.dir=" + sparkLogDir,osxTestOpts,conf.get(DRIVER_OPTS_KEY));
    String executorJavaOpts=Joiner.on(" ").skipNulls().join("-Dhive.spark.log.dir=" + sparkLogDir,osxTestOpts,conf.get(EXECUTOR_OPTS_KEY));
    File properties=File.createTempFile("spark-submit.",".properties");
    if (!properties.setReadable(false) || !properties.setReadable(true,true)) {
      throw new IOException("Cannot change permissions of job properties file.");
    }
    Properties allProps=new Properties();
    for (    Map.Entry<String,String> e : conf.entrySet()) {
      allProps.put(e.getKey(),conf.get(e.getKey()));
    }
    allProps.put(SparkClientFactory.CONF_CLIENT_ID,clientId);
    allProps.put(SparkClientFactory.CONF_KEY_SECRET,secret);
    allProps.put(DRIVER_OPTS_KEY,driverJavaOpts);
    allProps.put(EXECUTOR_OPTS_KEY,executorJavaOpts);
    String hiveHadoopTestClasspath=Strings.nullToEmpty(System.getenv("HIVE_HADOOP_TEST_CLASSPATH"));
    if (!hiveHadoopTestClasspath.isEmpty()) {
      String extraClasspath=Strings.nullToEmpty((String)allProps.get(DRIVER_EXTRA_CLASSPATH));
      if (extraClasspath.isEmpty()) {
        allProps.put(DRIVER_EXTRA_CLASSPATH,hiveHadoopTestClasspath);
      }
 else {
        extraClasspath=extraClasspath.endsWith(File.pathSeparator) ? extraClasspath : extraClasspath + File.pathSeparator;
        allProps.put(DRIVER_EXTRA_CLASSPATH,extraClasspath + hiveHadoopTestClasspath);
      }
    }
    Writer writer=new OutputStreamWriter(new FileOutputStream(properties),Charsets.UTF_8);
    try {
      allProps.store(writer,"Spark Context configuration");
    }
  finally {
      writer.close();
    }
    String master=conf.get("spark.master");
    Preconditions.checkArgument(master != null,"spark.master is not defined.");
    List<String> argv=Lists.newArrayList();
    if (sparkHome != null) {
      argv.add(new File(sparkHome,"bin/spark-submit").getAbsolutePath());
    }
 else {
      LOG.info("No spark.home provided, calling SparkSubmit directly.");
      argv.add(new File(System.getProperty("java.home"),"bin/java").getAbsolutePath());
      if (master.startsWith("local") || master.startsWith("mesos") || master.endsWith("-client")|| master.startsWith("spark")) {
        String mem=conf.get("spark.driver.memory");
        if (mem != null) {
          argv.add("-Xms" + mem);
          argv.add("-Xmx" + mem);
        }
        String cp=conf.get("spark.driver.extraClassPath");
        if (cp != null) {
          argv.add("-classpath");
          argv.add(cp);
        }
        String libPath=conf.get("spark.driver.extraLibPath");
        if (libPath != null) {
          argv.add("-Djava.library.path=" + libPath);
        }
        String extra=conf.get(DRIVER_OPTS_KEY);
        if (extra != null) {
          for (          String opt : extra.split("[ ]")) {
            if (!opt.trim().isEmpty()) {
              argv.add(opt.trim());
            }
          }
        }
      }
      argv.add("org.apache.spark.deploy.SparkSubmit");
    }
    if (master.equals("yarn-cluster")) {
      String executorCores=conf.get("spark.executor.cores");
      if (executorCores != null) {
        argv.add("--executor-cores");
        argv.add(executorCores);
      }
      String executorMemory=conf.get("spark.executor.memory");
      if (executorMemory != null) {
        argv.add("--executor-memory");
        argv.add(executorMemory);
      }
      String numOfExecutors=conf.get("spark.executor.instances");
      if (numOfExecutors != null) {
        argv.add("--num-executors");
        argv.add(numOfExecutors);
      }
    }
    argv.add("--properties-file");
    argv.add(properties.getAbsolutePath());
    argv.add("--class");
    argv.add(RemoteDriver.class.getName());
    String jar="spark-internal";
    if (SparkContext.jarOfClass(this.getClass()).isDefined()) {
      jar=SparkContext.jarOfClass(this.getClass()).get();
    }
    argv.add(jar);
    argv.add("--remote-host");
    argv.add(serverAddress);
    argv.add("--remote-port");
    argv.add(serverPort);
    for (    String hiveSparkConfKey : RpcConfiguration.HIVE_SPARK_RSC_CONFIGS) {
      String value=RpcConfiguration.getValue(hiveConf,hiveSparkConfKey);
      argv.add("--conf");
      argv.add(String.format("%s=%s",hiveSparkConfKey,value));
    }
    LOG.debug("Running client driver with argv: {}",Joiner.on(" ").join(argv));
    ProcessBuilder pb=new ProcessBuilder(argv.toArray(new String[argv.size()]));
    final Process child=pb.start();
    int childId=childIdGenerator.incrementAndGet();
    redirect("stdout-redir-" + childId,child.getInputStream());
    redirect("stderr-redir-" + childId,child.getErrorStream());
    runnable=new Runnable(){
      @Override public void run(){
        try {
          int exitCode=child.waitFor();
          if (exitCode != 0) {
            LOG.warn("Child process exited with code {}.",exitCode);
          }
        }
 catch (        InterruptedException ie) {
          LOG.warn("Waiting thread interrupted, killing child process.");
          Thread.interrupted();
          child.destroy();
        }
catch (        Exception e) {
          LOG.warn("Exception while waiting for child process.",e);
        }
      }
    }
;
  }
  Thread thread=new Thread(runnable);
  thread.setDaemon(true);
  thread.setName("Driver");
  thread.start();
  return thread;
}
