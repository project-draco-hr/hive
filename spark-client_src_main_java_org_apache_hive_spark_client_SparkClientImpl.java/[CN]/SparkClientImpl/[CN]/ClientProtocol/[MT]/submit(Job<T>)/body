{
  final String jobId=UUID.randomUUID().toString();
  final Promise<T> promise=driverRpc.createPromise();
  final JobHandleImpl<T> handle=new JobHandleImpl<T>(SparkClientImpl.this,promise,jobId);
  jobs.put(jobId,handle);
  final io.netty.util.concurrent.Future<Void> rpc=driverRpc.call(new JobRequest(jobId,job));
  LOG.debug("Send JobRequest[{}].",jobId);
  rpc.addListener(new GenericFutureListener<io.netty.util.concurrent.Future<Void>>(){
    @Override public void operationComplete(    io.netty.util.concurrent.Future<Void> f){
      if (f.isSuccess()) {
        handle.changeState(JobHandle.State.QUEUED);
      }
 else       if (!promise.isDone()) {
        promise.setFailure(f.cause());
      }
    }
  }
);
  promise.addListener(new GenericFutureListener<Promise<T>>(){
    @Override public void operationComplete(    Promise<T> p){
      if (jobId != null) {
        jobs.remove(jobId);
      }
      if (p.isCancelled() && !rpc.isDone()) {
        rpc.cancel(true);
      }
    }
  }
);
  return handle;
}
