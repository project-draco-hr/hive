{
  super.setUp();
  System.setProperty("hive.metastore.event.listeners",DummyListener.class.getName());
  int port=MetaStoreUtils.findFreePort();
  MetaStoreUtils.startMetaStore(port,ShimLoader.getHadoopThriftAuthBridge());
  hiveConf=new HiveConf(this.getClass());
  hiveConf.setVar(HiveConf.ConfVars.METASTOREURIS,"thrift://localhost:" + port);
  hiveConf.setIntVar(HiveConf.ConfVars.METASTORETHRIFTCONNECTIONRETRIES,3);
  hiveConf.set(HiveConf.ConfVars.PREEXECHOOKS.varname,"");
  hiveConf.set(HiveConf.ConfVars.POSTEXECHOOKS.varname,"");
  hiveConf.set(HiveConf.ConfVars.HIVE_SUPPORT_CONCURRENCY.varname,"false");
  SessionState.start(new CliSessionState(hiveConf));
  msc=new HiveMetaStoreClient(hiveConf);
  msc.dropDatabase(dbName,true,true);
  db.setName(dbName);
  Map<String,String> tableParams=new HashMap<String,String>();
  tableParams.put("a","string");
  List<FieldSchema> cols=new ArrayList<FieldSchema>();
  cols.add(new FieldSchema("a","string",""));
  StorageDescriptor sd=new StorageDescriptor();
  sd.setCols(cols);
  sd.setCompressed(false);
  sd.setParameters(tableParams);
  sd.setSerdeInfo(new SerDeInfo());
  sd.getSerdeInfo().setName(tblName);
  sd.getSerdeInfo().setParameters(new HashMap<String,String>());
  sd.getSerdeInfo().getParameters().put(serdeConstants.SERIALIZATION_FORMAT,"1");
  sd.getSerdeInfo().setSerializationLib(LazySimpleSerDe.class.getName());
  sd.setInputFormat(HiveInputFormat.class.getName());
  sd.setOutputFormat(HiveOutputFormat.class.getName());
  table.setDbName(dbName);
  table.setTableName(tblName);
  table.setParameters(tableParams);
  table.setSd(sd);
  DummyListener.notifyList.clear();
}
