{
  Assert.assertEquals(0,driver.run("drop table if exists test_thrift").getResponseCode());
  Assert.assertEquals(0,driver.run("create external table test_thrift " + "partitioned by (year string) " + "row format serde 'org.apache.hadoop.hive.serde2.thrift.ThriftDeserializer' "+ "with serdeproperties ( "+ "  'serialization.class'='org.apache.hadoop.hive.serde2.thrift.test.IntString', "+ "  'serialization.format'='org.apache.thrift.protocol.TBinaryProtocol') "+ "stored as"+ "  inputformat 'org.apache.hadoop.mapred.SequenceFileInputFormat'"+ "  outputformat 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'").getResponseCode());
  Assert.assertEquals(0,driver.run("alter table test_thrift add partition (year = '2012') location '" + intStringSeq.getParent() + "'").getResponseCode());
  PigServer pigServer=new PigServer(ExecType.LOCAL);
  pigServer.registerQuery("A = load 'test_thrift' using org.apache.hive.hcatalog.pig.HCatLoader();");
  Schema expectedSchema=new Schema();
  expectedSchema.add(new Schema.FieldSchema("myint",DataType.INTEGER));
  expectedSchema.add(new Schema.FieldSchema("mystring",DataType.CHARARRAY));
  expectedSchema.add(new Schema.FieldSchema("underscore_int",DataType.INTEGER));
  expectedSchema.add(new Schema.FieldSchema("year",DataType.CHARARRAY));
  Assert.assertEquals(expectedSchema,pigServer.dumpSchema("A"));
  Iterator<Tuple> iterator=pigServer.openIterator("A");
  Tuple t=iterator.next();
  Assert.assertEquals(1,t.get(0));
  Assert.assertEquals("one",t.get(1));
  Assert.assertEquals(1,t.get(2));
  Assert.assertEquals("2012",t.get(3));
  Assert.assertFalse(iterator.hasNext());
}
