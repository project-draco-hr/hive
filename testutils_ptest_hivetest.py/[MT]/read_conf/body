def read_conf(config_file):
    global local, qfile_set, other_set, remote_set, all_set
    global master_base_path, host_base_path
    global ant_path, arc_path, phutil_path, code_path, report_path, host_code_path
    if (config_file is not None):
        config.load(config_file)
    else:
        config.load()
    local = config.local
    qfile_set = config.qfile_set
    other_set = config.other_set
    remote_set = config.remote_set
    all_set = config.all_set
    master_base_path = config.master_base_path
    host_base_path = config.host_base_path
    if ('HIVE_PTEST_SUFFIX' in os.environ):
        suffix = os.environ['HIVE_PTEST_SUFFIX']
        master_base_path += ('-' + suffix)
        host_base_path += ('-' + suffix)
    ant_path = (master_base_path + '/apache-ant-1.8.2')
    arc_path = (master_base_path + '/arcanist')
    phutil_path = (master_base_path + '/libphutil')
    code_path = (master_base_path + '/trunk')
    report_path = ((master_base_path + '/report/') + time.strftime('%m.%d.%Y_%H:%M:%S'))
    host_code_path = (host_base_path + '/trunk-{host}')
    all_set.add_path((ant_path + '/bin'))
    all_set.add_path((arc_path + '/bin'))
    all_set.export('JAVA_HOME', config.java_home)
    all_set.add_path((config.java_home + '/bin'))
    remote_set.export('HIVE_HOME', (host_code_path + '/build/dist'))
    remote_set.add_path((host_code_path + '/build/dist/bin'))
    remote_set.export('HADOOP_HOME', (host_code_path + '/build/hadoopcore/hadoop-0.20.1'))
