{
  this.endPoint=endPoint;
  this.conf=conf != null ? conf : HiveEndPoint.createHiveConf(DelimitedInputWriter.class,endPoint.metaStoreUri);
  try {
    msClient=HCatUtil.getHiveMetastoreClient(this.conf);
    this.tbl=msClient.getTable(endPoint.database,endPoint.table);
    this.partitionPath=getPathForEndPoint(msClient,endPoint);
    this.totalBuckets=tbl.getSd().getNumBuckets();
    if (totalBuckets <= 0) {
      throw new StreamingException("Cannot stream to table that has not been bucketed : " + endPoint);
    }
    this.bucketIds=getBucketColIDs(tbl.getSd().getBucketCols(),tbl.getSd().getCols());
    this.bucketFieldData=new Object[bucketIds.size()];
    String outFormatName=this.tbl.getSd().getOutputFormat();
    outf=(AcidOutputFormat<?,?>)ReflectionUtils.newInstance(JavaUtils.loadClass(outFormatName),conf);
    bucketFieldData=new Object[bucketIds.size()];
  }
 catch (  MetaException e) {
    throw new ConnectionError(endPoint,e);
  }
catch (  NoSuchObjectException e) {
    throw new ConnectionError(endPoint,e);
  }
catch (  TException e) {
    throw new StreamingException(e.getMessage(),e);
  }
catch (  ClassNotFoundException e) {
    throw new StreamingException(e.getMessage(),e);
  }
catch (  IOException e) {
    throw new StreamingException(e.getMessage(),e);
  }
}
