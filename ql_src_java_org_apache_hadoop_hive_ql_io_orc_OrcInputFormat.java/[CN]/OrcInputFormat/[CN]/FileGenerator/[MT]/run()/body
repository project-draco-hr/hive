{
  try {
    AcidUtils.Directory dirInfo=AcidUtils.getAcidState(dir,context.conf,context.transactionList,useFileIds);
    List<Long> deltas=AcidUtils.serializeDeltas(dirInfo.getCurrentDirectories());
    Path base=dirInfo.getBaseDirectory();
    List<HdfsFileStatusWithId> original=dirInfo.getOriginalFiles();
    boolean[] covered=new boolean[context.numBuckets];
    boolean isOriginal=base == null;
    if (base != null || !original.isEmpty()) {
      List<HdfsFileStatusWithId> children=original;
      if (base != null) {
        children=findBaseFiles(base,useFileIds);
      }
      for (      HdfsFileStatusWithId child : children) {
        AcidOutputFormat.Options opts=AcidUtils.parseBaseBucketFilename(child.getFileStatus().getPath(),context.conf);
        scheduleSplits(child,isOriginal,true,deltas);
        int b=opts.getBucket();
        if (b >= 0 && b < covered.length) {
          covered[b]=true;
        }
      }
    }
    if (!deltas.isEmpty()) {
      for (int b=0; b < context.numBuckets; ++b) {
        if (!covered[b]) {
synchronized (context.splits) {
            context.splits.add(new OrcSplit(dir,null,b,0,new String[0],null,false,false,deltas));
          }
        }
      }
    }
  }
 catch (  Throwable th) {
    if (!(th instanceof IOException)) {
      LOG.error("Unexpected Exception",th);
    }
synchronized (context.errors) {
      context.errors.add(th);
    }
    if (!(th instanceof IOException)) {
      context.notifyOnNonIOException(th);
    }
  }
 finally {
    context.decrementSchedulers();
  }
}
