{
  job=conf;
  bytesRef[0]=new BytesRefWritable();
  bytesRef[1]=new BytesRefWritable();
  ignoreHdfsLoc=HiveConf.getBoolVar(conf,HiveConf.ConfVars.HIVE_INDEX_IGNORE_HDFS_LOC);
  if (indexFile != null) {
    Path indexFilePath=new Path(indexFile);
    FileSystem fs=FileSystem.get(conf);
    FileStatus indexStat=fs.getFileStatus(indexFilePath);
    List<Path> paths=new ArrayList<Path>();
    if (indexStat.isDir()) {
      FileStatus[] fss=fs.listStatus(indexFilePath);
      for (      FileStatus f : fss) {
        paths.add(f.getPath());
      }
    }
 else {
      paths.add(indexFilePath);
    }
    long maxEntriesToLoad=HiveConf.getLongVar(conf,HiveConf.ConfVars.HIVE_INDEX_COMPACT_QUERY_MAX_ENTRIES);
    if (maxEntriesToLoad < 0) {
      maxEntriesToLoad=Long.MAX_VALUE;
    }
    long lineCounter=0;
    for (    Path indexFinalPath : paths) {
      FSDataInputStream ifile=fs.open(indexFinalPath);
      LineReader lr=new LineReader(ifile,conf);
      try {
        Text line=new Text();
        while (lr.readLine(line) > 0) {
          if (++lineCounter > maxEntriesToLoad) {
            throw new HiveException("Number of compact index entries loaded during the query exceeded the maximum of " + maxEntriesToLoad + " set in "+ HiveConf.ConfVars.HIVE_INDEX_COMPACT_QUERY_MAX_ENTRIES.varname);
          }
          add(line);
        }
      }
  finally {
        lr.close();
      }
    }
  }
}
