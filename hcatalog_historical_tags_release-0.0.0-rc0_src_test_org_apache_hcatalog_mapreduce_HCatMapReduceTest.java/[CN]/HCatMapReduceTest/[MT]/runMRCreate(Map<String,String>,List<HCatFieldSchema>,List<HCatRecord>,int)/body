{
  writeRecords=records;
  MapCreate.writeCount=0;
  Configuration conf=new Configuration();
  Job job=new Job(conf,"howl mapreduce write test");
  job.setJarByClass(this.getClass());
  job.setMapperClass(HCatMapReduceTest.MapCreate.class);
  job.setInputFormatClass(TextInputFormat.class);
  Path path=new Path(fs.getWorkingDirectory(),"mapred/testHowlMapReduceInput");
  createInputFile(path,writeCount);
  TextInputFormat.setInputPaths(job,path);
  job.setOutputFormatClass(HCatOutputFormat.class);
  HCatTableInfo outputInfo=HCatTableInfo.getOutputTableInfo(thriftUri,null,dbName,tableName,partitionValues);
  HCatOutputFormat.setOutput(job,outputInfo);
  job.setMapOutputKeyClass(BytesWritable.class);
  job.setMapOutputValueClass(DefaultHCatRecord.class);
  job.setNumReduceTasks(0);
  HCatOutputFormat.setSchema(job,new HCatSchema(partitionColumns));
  job.waitForCompletion(true);
  new HCatOutputCommitter(null).cleanupJob(job);
  Assert.assertEquals(writeCount,MapCreate.writeCount);
}
