{
  TypeDescription schema=TypeDescription.createLong();
  long[] inp=new long[]{1,1,1,1,1,1,1,1,1,1,1,2,3,4,5,6,7,8,9,10,1,1,1,1,1,1,10,9,7,6,5,4,3,2,1,1,1,1,1,2,5,1,3,7,1,9,2,6,3,7,1,9,2,6,3,7,1,9,2,6,3,7,1,9,2,6,3,7,1,9,2,6,2000,2,1,1,1,1,1,3,7,1,9,2,6,1,1,1,1,1};
  List<Long> input=Lists.newArrayList(Longs.asList(inp));
  Writer writer=OrcFile.createWriter(testFilePath,OrcFile.writerOptions(conf).setSchema(schema).stripeSize(100000).compress(CompressionKind.NONE).bufferSize(10000).encodingStrategy(encodingStrategy));
  VectorizedRowBatch batch=schema.createRowBatch();
  for (  Long l : input) {
    appendLong(batch,l);
  }
  writer.addRowBatch(batch);
  writer.close();
  Reader reader=OrcFile.createReader(testFilePath,OrcFile.readerOptions(conf).filesystem(fs));
  RecordReader rows=reader.rows();
  int idx=0;
  batch=reader.getSchema().createRowBatch();
  while (rows.nextBatch(batch)) {
    for (int r=0; r < batch.size; ++r) {
      assertEquals(input.get(idx++).longValue(),((LongColumnVector)batch.cols[0]).vector[r]);
    }
  }
}
