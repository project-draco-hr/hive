{
  setWorkOutputPath(context);
  context.getConfiguration().set("mapred.output.key.class",NullWritable.class.getName());
  String jobInfoString=context.getConfiguration().get(HCatConstants.HCAT_KEY_OUTPUT_INFO);
  OutputJobInfo jobInfo=(OutputJobInfo)HCatUtil.deserialize(jobInfoString);
  StorerInfo storeInfo=jobInfo.getTableInfo().getStorerInfo();
  HiveStorageHandler storageHandler=HCatUtil.getStorageHandler(context.getConfiguration(),storeInfo);
  Class<? extends SerDe> serde=storageHandler.getSerDeClass();
  SerDe sd=(SerDe)ReflectionUtils.newInstance(serde,context.getConfiguration());
  context.getConfiguration().set("mapred.output.value.class",sd.getSerializedClass().getName());
  RecordWriter<WritableComparable<?>,HCatRecord> rw;
  if (HCatBaseOutputFormat.getJobInfo(context.getConfiguration()).isDynamicPartitioningUsed()) {
    rw=new DynamicPartitionFileRecordWriterContainer((org.apache.hadoop.mapred.RecordWriter)null,context);
  }
 else {
    Path parentDir=new Path(context.getConfiguration().get("mapred.work.output.dir"));
    Path childPath=new Path(parentDir,FileOutputFormat.getUniqueName(new JobConf(context.getConfiguration()),context.getConfiguration().get("mapreduce.output.basename","part")));
    rw=new StaticPartitionFileRecordWriterContainer(getBaseOutputFormat().getRecordWriter(parentDir.getFileSystem(context.getConfiguration()),new JobConf(context.getConfiguration()),childPath.toString(),InternalUtil.createReporter(context)),context);
  }
  return rw;
}
