{
  Multimap<Integer,Integer> bucketToTaskMap=HashMultimap.<Integer,Integer>create();
  List<InputSplit> finalSplits=Lists.newLinkedList();
  int taskCount=0;
  for (  Entry<Integer,Collection<InputSplit>> entry : bucketToGroupedSplitMap.asMap().entrySet()) {
    int bucketNum=entry.getKey();
    Collection<InputSplit> initialSplits=entry.getValue();
    finalSplits.addAll(initialSplits);
    for (int i=0; i < initialSplits.size(); i++) {
      bucketToTaskMap.put(bucketNum,taskCount);
      taskCount++;
    }
  }
  EdgeManagerDescriptor hiveEdgeManagerDesc=new EdgeManagerDescriptor(CustomPartitionEdge.class.getName());
  byte[] payload=getBytePayload(bucketToTaskMap);
  hiveEdgeManagerDesc.setUserPayload(payload);
  Map<String,EdgeManagerDescriptor> emMap=Maps.newHashMap();
  for (  Entry<String,EdgeProperty> edgeEntry : context.getInputVertexEdgeProperties().entrySet()) {
    if (edgeEntry.getValue().getDataMovementType() == DataMovementType.CUSTOM && edgeEntry.getValue().getEdgeManagerDescriptor().getClassName().equals(CustomPartitionEdge.class.getName())) {
      emMap.put(edgeEntry.getKey(),hiveEdgeManagerDesc);
    }
  }
  LOG.info("Task count is " + taskCount);
  List<RootInputDataInformationEvent> taskEvents=Lists.newArrayListWithCapacity(finalSplits.size());
  int count=0;
  for (  InputSplit inputSplit : finalSplits) {
    MRSplitProto serializedSplit=MRHelpers.createSplitProto(inputSplit);
    RootInputDataInformationEvent diEvent=new RootInputDataInformationEvent(count,serializedSplit.toByteArray());
    diEvent.setTargetIndex(count);
    count++;
    taskEvents.add(diEvent);
  }
  context.setVertexParallelism(taskCount,new VertexLocationHint(grouper.createTaskLocationHints(finalSplits.toArray(new InputSplit[finalSplits.size()]))),emMap);
  context.addRootInputEvents(inputName,taskEvents);
}
