{
  this.conf=conf;
  this.parseContext=parseContext;
  this.moveTask=moveTask;
  this.rootTasks=rootTasks;
  this.inputs=inputs;
  this.outputs=outputs;
  this.defaultTask=(SparkTask)TaskFactory.get(new SparkWork(conf.getVar(HiveConf.ConfVars.HIVEQUERYID)),conf);
  this.rootTasks.add(defaultTask);
  this.currentTask=null;
  this.leafOperatorToFollowingWork=new LinkedHashMap<Operator<?>,BaseWork>();
  this.linkOpWithWorkMap=new LinkedHashMap<Operator<?>,Map<BaseWork,SparkEdgeProperty>>();
  this.linkWorkWithReduceSinkMap=new LinkedHashMap<BaseWork,List<ReduceSinkOperator>>();
  this.mapJoinWorkMap=new LinkedHashMap<MapJoinOperator,List<BaseWork>>();
  this.rootToWorkMap=new LinkedHashMap<Operator<?>,BaseWork>();
  this.childToWorkMap=new LinkedHashMap<Operator<?>,List<BaseWork>>();
  this.mapJoinParentMap=new LinkedHashMap<MapJoinOperator,List<Operator<?>>>();
  this.currentMapJoinOperators=new LinkedHashSet<MapJoinOperator>();
  this.linkChildOpWithDummyOp=new LinkedHashMap<Operator<?>,List<Operator<?>>>();
  this.dependencyTask=(DependencyCollectionTask)TaskFactory.get(new DependencyCollectionWork(),conf);
  this.unionWorkMap=new LinkedHashMap<Operator<?>,BaseWork>();
  this.currentUnionOperators=new LinkedList<UnionOperator>();
  this.workWithUnionOperators=new LinkedHashSet<BaseWork>();
  this.clonedReduceSinks=new LinkedHashSet<ReduceSinkOperator>();
  this.fileSinkSet=new LinkedHashSet<FileSinkOperator>();
  this.connectedReduceSinks=new LinkedHashSet<ReduceSinkOperator>();
  this.opToParentMap=new LinkedHashMap<Operator<?>,Operator<?>>();
  this.opToTaskMap=new LinkedHashMap<Operator<?>,SparkTask>();
  this.tempTS=new LinkedHashSet<TableScanOperator>();
}
