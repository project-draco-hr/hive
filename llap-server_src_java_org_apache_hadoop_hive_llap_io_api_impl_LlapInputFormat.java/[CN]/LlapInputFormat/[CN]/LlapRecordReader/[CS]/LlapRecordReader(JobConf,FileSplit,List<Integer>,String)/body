{
  this.jobConf=job;
  this.split=split;
  this.columnIds=includedCols;
  this.sarg=ConvertAstToSearchArg.createFromConf(job);
  this.columnNames=ColumnProjectionUtils.getReadColumnNames(job);
  final String fragmentId=LlapTezUtils.getFragmentId(job);
  final String dagId=LlapTezUtils.getDagId(job);
  final String queryId=HiveConf.getVar(job,HiveConf.ConfVars.HIVEQUERYID);
  MDC.put("dagId",dagId);
  MDC.put("queryId",queryId);
  TezCounters taskCounters=null;
  if (fragmentId != null) {
    MDC.put("fragmentId",fragmentId);
    taskCounters=FragmentCountersMap.getCountersForFragment(fragmentId);
    LOG.info("Received fragment id: {}",fragmentId);
  }
 else {
    LOG.warn("Not using tez counters as fragment id string is null");
  }
  this.counters=new QueryFragmentCounters(job,taskCounters);
  this.counters.setDesc(QueryFragmentCounters.Desc.MACHINE,hostName);
  MapWork mapWork=Utilities.getMapWork(job);
  VectorizedRowBatchCtx ctx=mapWork.getVectorizedRowBatchCtx();
  rbCtx=ctx != null ? ctx : createFakeVrbCtx(mapWork);
  int partitionColumnCount=rbCtx.getPartitionColumnCount();
  if (partitionColumnCount > 0) {
    partitionValues=new Object[partitionColumnCount];
    VectorizedRowBatchCtx.getPartitionValues(rbCtx,job,split,partitionValues);
  }
 else {
    partitionValues=null;
  }
  rp=cvp.createReadPipeline(this,split,columnIds,sarg,columnNames,counters);
  feedback=rp;
  fileSchema=rp.getFileSchema();
  includedColumns=rp.getIncludedColumns();
}
